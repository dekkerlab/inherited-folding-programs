import warnings
from cytoolz import merge
import bioframe
import pandas as pd
import numpy as np
from itertools import combinations
from functools import partial
from scipy.linalg import toeplitz
import pandas as pd
from cooltools.lib.checks import (
    is_compatible_viewframe,
    is_valid_expected,
    is_cooler_balanced,
    is_track,
)
from cooltools.lib.common import view_from_track, align_track_with_cooler
from cooltools.api.saddle import digitize, _make_cis_obsexp_fetcher, _make_trans_obsexp_fetcher
import warnings


# S, C now have to be a 3-dimensional arrays of n_bins X n_bins X max_dist
# S(D,n,n) - first dim correspond to a certain distance (in bins) and the latter 2 are the typical saddles n*n
# C(D,n,n) - same thing here as well ...

# # some testing here
# _num = 50
# mmm = np.random.rand(_num, _num)
# vvv = np.random.choice([False,True],_num)
# _dist = np.abs(np.arange(_num)[None,:] - np.arange(_num)[:,None])
# mmm.shape
# plt.imshow(mmm)
# plt.imshow(
#     _dist,
#     cmap="pink_r",
# )
# plt.plot(vvv.astype(int))
# # mask of what we take in for averaging for a given saddle category ...
# plt.imshow(np.outer(vvv,vvv))
# plt.imshow(mmm[~vvv,:][:,~vvv])
# plt.imshow(mmm[vvv,:][:,vvv])
# plt.imshow(
#     _dist[~vvv,:][:,~vvv],
#     cmap="pink_r",
# )
# mv = mmm[vvv,:][:,vvv]
# mv.shape
# dv = _dist[vvv,:][:,vvv]
# dv.shape
# mv[np.isfinite(mv)]
# # real deal here !
# np.bincount(dv[np.isfinite(mv)], weights=mv[np.isfinite(mv)])
# np.bincount(dv[np.isfinite(mv)])


# # checking 3D S and C ...
# ttt = np.random.rand(100,10,10)
# ttt[:,0,0]-= np.ones(1,dtype=float)
# ttt[:,2,2]-= np.ones(1,dtype=float)
# ttt[:,4,4]-= np.ones(1,dtype=float)
# ttt[:,8,8]+= np.ones(1,dtype=float)
# plt.imshow(np.mean(ttt,axis=0))
# plt.plot(ttt[:,0,0])


def _accumulate_dist(
    S, C, getmatrix, digitized, reg1, reg2, max_dist, verbose=False
):
    """
    Helper function to aggregate across region pairs.
    If regions are identical does it by distance !

    """

    if reg1 != reg2:
        raise ValueError("this is special version of accumulate for cis data only ...")

    n_bins = S.shape[-1]
    matrix = getmatrix(reg1, reg2)

    if verbose:
        print("regions {} vs {}".format(reg1, reg2))

    # Toeplitz matrix with distance for every pixel ...
    _dist_vec = np.arange(matrix.shape[0])
    dist_mat = np.abs(_dist_vec[None,:] - _dist_vec[:,None])

    for i in range(n_bins):
        row_mask = digitized[reg1] == i
        for j in range(n_bins):
            col_mask = digitized[reg2] == j
            data = matrix[row_mask, :][:, col_mask]
            dist = dist_mat[row_mask, :][:, col_mask]
            is_finite_mask = np.isfinite(data)
            data = data[is_finite_mask]
            dist = dist[is_finite_mask]
            # S unrolled by distances - inefficient memory access - isn't it ?
            S[:, i, j] += np.bincount(dist, weights=data, minlength=max_dist)
            # C unrolled by distances
            C[:, i, j] += np.bincount(dist, minlength=max_dist).astype(float)


def saddle_dist(
    clr,
    expected,
    track,
    contact_type,
    n_bins,
    vrange=None,
    qrange=None,
    view_df=None,
    clr_weight_name="weight",
    expected_value_col="balanced.avg",
    view_name_col="name",
    # min_diag=3,
    max_dist=100,
    # max_diag=-1,
    trim_outliers=False,
    verbose=False,
    drop_track_na=False,
):
    """
    Get a matrix of average interactions between genomic bin
    pairs as a function of a specified genomic track.

    The provided genomic track is either:
    (a) digitized inside this function by passing 'n_bins', and one of 'v_range' or 'q_range'
    (b) passed as a pre-digitized track with a categorical value column as generated by `get_digitized()`.

    Parameters
    ----------
    clr : cooler.Cooler
        Observed matrix.
    expected : DataFrame in expected format
        Diagonal summary statistics for each chromosome, and name of the column
        with the values of expected to use.
    contact_type : str
        If 'cis' then only cis interactions are used to build the matrix.
        If 'trans', only trans interactions are used.
    track : DataFrame
        A track, i.e. BedGraph-like dataframe, which is digitized with
        the options n_bins, vrange and qrange. Can optionally be passed
        as a pre-digitized dataFrame with a categorical value column,
        as generated by get_digitzied(), also passing n_bins as None.
    n_bins : int or None
        number of bins for signal quantization. If None, then track must
        be passed as a pre-digitized track.
    vrange : tuple
        Low and high values used for binning track values.
        See get_digitized().
    qrange : tuple
        Low and high values for quantile binning track values.
        Low must be 0.0 or more, high must be 1.0 or less.
        Only one of vrange or qrange can be passed. See get_digitzed().
    view_df: viewframe
        Viewframe with genomic regions. If none, generate from track chromosomes.
    clr_weight_name : str
        Name of the column in the clr.bins to use as balancing weights.
        Using raw unbalanced data is not supported for saddles.
    expected_value_col : str
        Name of the column in expected used for normalizing.
    view_name_col : str
        Name of column in view_df with region names.
    min_diag : int
        Smallest diagonal to include in computation. Ignored with
        contact_type=trans.
    max_diag : int
        Biggest diagonal to include in computation. Ignored with
        contact_type=trans.
    trim_outliers : bool, optional
        Remove first and last row and column from the output matrix.
    verbose : bool, optional
        If True then reports progress.
    drop_track_na : bool, optional
        If True then drops NaNs in input track (as if they were missing),
        If False then counts NaNs as present in dataframe.
        In general, this only adds check form chromosomes that have all missing values, but does not affect the results.
    Returns
    -------
    interaction_sum : 2D array
        The matrix of summed interaction probability between two genomic bins
        given their values of the provided genomic track.
    interaction_count : 2D array
        The matrix of the number of genomic bin pairs that contributed to the
        corresponding pixel of ``interaction_sum``.
    """

    if type(n_bins) is int:
        # perform digitization
        track = align_track_with_cooler(
            track,
            clr,
            view_df=view_df,
            clr_weight_name=clr_weight_name,
            mask_clr_bad_bins=True,
            drop_track_na=drop_track_na,  # this adds check for chromosomes that have all missing values
        )
        digitized_track, binedges = digitize(
            track.iloc[:, :4],
            n_bins,
            vrange=vrange,
            qrange=qrange,
            digitized_suffix=".d",
        )
        digitized_col = digitized_track.columns[3]

    elif n_bins is None:
        # assume and test if track is pre-digitized
        digitized_track = track
        digitized_col = digitized_track.columns[3]
        is_track(track.astype({digitized_col: "float"}), raise_errors=True)
        if (
            type(digitized_track.dtypes[3])
            is not pd.core.dtypes.dtypes.CategoricalDtype
        ):
            raise ValueError(
                "when n_bins=None, saddle assumes the track has been "
                + "pre-digitized and the value column is a "
                + "pandas categorical. See get_digitized()."
            )
        cats = digitized_track[digitized_col].dtype.categories.values
        # cats has two additional categories, 0 and n_bins+1, for values
        # falling outside range, as well as -1 for NAs.
        n_bins = len(cats[cats > -1]) - 2
    else:
        raise ValueError("n_bins must be provided as int or None")

    if view_df is None:
        view_df = view_from_track(digitized_track)
    else:
        # Make sure view_df is a proper viewframe
        try:
            _ = is_compatible_viewframe(
                view_df,
                clr,
                check_sorting=True,  # just in case
                raise_errors=True,
            )
        except Exception as e:
            raise ValueError("view_df is not a valid viewframe or incompatible") from e

    # make sure provided expected is compatible
    try:
        _ = is_valid_expected(
            expected,
            contact_type,
            view_df,
            verify_cooler=clr,
            expected_value_cols=[
                expected_value_col,
            ],
            raise_errors=True,
        )
    except Exception as e:
        raise ValueError("provided expected is not compatible") from e

    # check if cooler is balanced
    if clr_weight_name:
        try:
            _ = is_cooler_balanced(clr, clr_weight_name, raise_errors=True)
        except Exception as e:
            raise ValueError(
                f"provided cooler is not balanced or {clr_weight_name} is missing"
            ) from e

    digitized_tracks = {}
    for num, reg in view_df.iterrows():
        digitized_reg = bioframe.select(digitized_track, reg)
        digitized_tracks[reg[view_name_col]] = digitized_reg[digitized_col]

    # set "cis" or "trans" for supports (regions to iterate over) and matrix fetcher
    if contact_type == "cis":
        # only symmetric intra-chromosomal regions :
        supports = list(zip(view_df[view_name_col], view_df[view_name_col]))
        getmatrix = _make_cis_obsexp_fetcher(
            clr,
            expected,
            view_df,
            view_name_col=view_name_col,
            expected_value_col=expected_value_col,
            clr_weight_name=clr_weight_name,
        )
        # n_bins here includes 2 open bins for values <lo and >hi.
        interaction_sum = np.zeros((max_dist, n_bins + 2, n_bins + 2))
        interaction_count = np.zeros((max_dist, n_bins + 2, n_bins + 2))
        for reg1, reg2 in supports:
            _accumulate_dist(
                interaction_sum,
                interaction_count,
                getmatrix,
                digitized_tracks,
                reg1,
                reg2,
                max_dist,
                verbose=verbose
            )
        # symmetrise by adding transpose "saddle"
        # transpose 2nd and 3rd coords by leaving the 1st alone
        interaction_sum += interaction_sum.transpose(0,2,1)
        interaction_count += interaction_count.transpose(0,2,1)
        if trim_outliers:
            interaction_sum = interaction_sum[:, 1:-1, 1:-1]
            interaction_count = interaction_count[:, 1:-1, 1:-1]
        return interaction_sum, interaction_count
    elif contact_type == "trans":
        # asymmetric inter-chromosomal regions :
        supports = list(combinations(view_df[view_name_col], 2))
        supports = [
            i
            for i in supports
            if (
                view_df["chrom"].loc[view_df[view_name_col] == i[0]].values
                != view_df["chrom"].loc[view_df[view_name_col] == i[1]].values
            )
        ]
        getmatrix = _make_trans_obsexp_fetcher(
            clr,
            expected,
            view_df,
            view_name_col=view_name_col,
            expected_value_col=expected_value_col,
            clr_weight_name=clr_weight_name,
        )
        # n_bins here includes 2 open bins for values <lo and >hi.
        interaction_sum = np.zeros((n_bins + 2, n_bins + 2))
        interaction_count = np.zeros((n_bins + 2, n_bins + 2))
        for reg1, reg2 in supports:
            _accumulate(
                interaction_sum,
                interaction_count,
                getmatrix,
                digitized_tracks,
                reg1,
                reg2,
                min_diag=min_diag,
                max_diag=max_diag,
                verbose=verbose,
            )
        # symmetrise by adding transpose "saddle"
        interaction_sum += interaction_sum.T
        interaction_count += interaction_count.T
        if trim_outliers:
            interaction_sum = interaction_sum[:, 1:-1, 1:-1]
            interaction_count = interaction_count[:, 1:-1, 1:-1]
        return interaction_sum, interaction_count
    else:
        raise ValueError("Allowed values for contact_type are 'cis' or 'trans'.")




def saddleplot(
    track,
    saddledata,
    n_bins,
    vrange=None,
    qrange=(0.0, 1.0),
    bar_type="hist",
    cmap="coolwarm",
    scale="log",
    vmin=0.5,
    vmax=2,
    color=None,
    title=None,
    xlabel=None,
    ylabel=None,
    clabel=None,
    fig=None,
    fig_kws=None,
    heatmap_kws=None,
    margin_kws=None,
    cbar_kws=None,
    subplot_spec=None,
):
    """
    Generate a saddle plot.
    Parameters
    ----------
    track : pd.DataFrame
        See cooltools.digitize() for details.
    saddledata : 2D array-like
        Saddle matrix produced by `make_saddle`. It will include 2 flanking
        rows/columns for outlier signal values, thus the shape should be
        `(n+2, n+2)`.
    cmap : str or matplotlib colormap
        Colormap to use for plotting the saddle heatmap
    scale : str
        Color scaling to use for plotting the saddle heatmap: log or linear
    vmin, vmax : float
        Value limits for coloring the saddle heatmap
    color : matplotlib color value
        Face color for margin bar plots
    fig : matplotlib Figure, optional
        Specified figure to plot on. A new figure is created if none is
        provided.
    fig_kws : dict, optional
        Passed on to `plt.Figure()`
    heatmap_kws : dict, optional
        Passed on to `ax.imshow()`
    margin_kws : dict, optional
        Passed on to `ax.bar()` and `ax.barh()`
    cbar_kws : dict, optional
        Passed on to `plt.colorbar()`
    subplot_spec : GridSpec object
        Specify a subregion of a figure to using a GridSpec.
    Returns
    -------
    Dictionary of axes objects.
    """

#     warnings.warn(
#         "Generating a saddleplot will be deprecated in future versions, "
#         + "please see https://github.com/open2c_examples for examples on how to plot saddles.",
#         DeprecationWarning,
#     )

    from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec
    from matplotlib.colors import Normalize, LogNorm
    from matplotlib import ticker
    import matplotlib.pyplot as plt
    import cooltools
    import numpy as np

    class MinOneMaxFormatter(ticker.LogFormatter):
        def set_locs(self, locs=None):
            self._sublabels = set([vmin % 10 * 10, vmax % 10, 1])

        def __call__(self, x, pos=None):
            if x not in [vmin, 1, vmax]:
                return ""
            else:
                return "{x:g}".format(x=x)

    track_value_col = track.columns[3]
    track_values = track[track_value_col]

    digitized_track, binedges = cooltools.digitize(track, n_bins, vrange=vrange, qrange=qrange )
    digitized_value_col = digitized_track.columns[3]
    digitized_values = digitized_track[digitized_value_col]

    # vrange - case
    lo, *_, hi = binedges
    # n_bins = len(binedges) - 1 -> must hold true
    if qrange is not None:
        lo, hi = qrange
        binedges = np.linspace(lo, hi, n_bins + 1)

    # what to show on V and H bars - hist or mean of the values:
    hist = digitized_values.value_counts().sort_index().loc[0:].to_numpy()
    # New version - show values
    groupmean = track_values.groupby(digitized_values).mean().sort_index().loc[0:].to_numpy()

    # Barplot of mean values and saddledata are flanked by outlier bins
    n = saddledata.shape[0]
    X, Y = np.meshgrid(binedges, binedges)
    C = saddledata
    if (n - n_bins) == 2:
        C = C[1:-1, 1:-1]
        if bar_type == "hist":
            bar_data = hist[1:-1]
        elif bar_type == "mean":
            bar_data = groupmean[1:-1]
        else:
            raise ValueError(f"bar_type can be only hist or mean, {bar_type} provided")

    # Layout
    if subplot_spec is not None:
        GridSpec = partial(GridSpecFromSubplotSpec, subplot_spec=subplot_spec)
    grid = {}
    gs = GridSpec(
        nrows=3,
        ncols=3,
        width_ratios=[0.2, 1, 0.1],
        height_ratios=[0.2, 1, 0.1],
        wspace=0.05,
        hspace=0.05,
    )

    # Figure
    if fig is None:
        fig_kws_default = dict(figsize=(5, 5))
        fig_kws = merge(fig_kws_default, fig_kws if fig_kws is not None else {})
        fig = plt.figure(**fig_kws)

    # Heatmap
    if scale == "log":
        norm = LogNorm(vmin=vmin, vmax=vmax)
    elif scale == "linear":
        norm = Normalize(vmin=vmin, vmax=vmax)
    else:
        raise ValueError("Only linear and log color scaling is supported")

    grid["ax_heatmap"] = ax = plt.subplot(gs[4])
    heatmap_kws_default = dict(cmap="coolwarm", rasterized=True)
    heatmap_kws = merge(
        heatmap_kws_default, heatmap_kws if heatmap_kws is not None else {}
    )
    img = ax.pcolormesh(X, Y, C, norm=norm, **heatmap_kws)
    plt.gca().yaxis.set_visible(False)

    # Margins
    margin_kws_default = dict(edgecolor="k", facecolor=color, linewidth=1)
    margin_kws = merge(margin_kws_default, margin_kws if margin_kws is not None else {})
    # left margin hist
    grid["ax_margin_y"] = plt.subplot(gs[3], sharey=grid["ax_heatmap"])
    
    plt.barh(
        binedges[:-1], height=np.diff(binedges), width=bar_data, align="edge", **margin_kws
    )
    
    plt.xlim(plt.xlim()[1], plt.xlim()[0])  # fliplr
    plt.ylim(hi, lo)
    plt.gca().spines["top"].set_visible(False)
    plt.gca().spines["bottom"].set_visible(False)
    plt.gca().spines["left"].set_visible(False)
    plt.gca().xaxis.set_visible(False)
    # top margin hist
    grid["ax_margin_x"] = plt.subplot(gs[1], sharex=grid["ax_heatmap"])
    
    plt.bar(
        binedges[:-1], width=np.diff(binedges), height=bar_data, align="edge", **margin_kws
    )
    
    plt.xlim(lo, hi)
    # plt.ylim(plt.ylim())  # correct
    plt.gca().spines["top"].set_visible(False)
    plt.gca().spines["right"].set_visible(False)
    plt.gca().spines["left"].set_visible(False)
    plt.gca().xaxis.set_visible(False)
    plt.gca().yaxis.set_visible(False)

    # Colorbar
    grid["ax_cbar"] = plt.subplot(gs[5])
    cbar_kws_default = dict(fraction=0.8, label=clabel or "")
    cbar_kws = merge(cbar_kws_default, cbar_kws if cbar_kws is not None else {})
    if scale == "linear" and vmin is not None and vmax is not None:
        grid["cbar"] = cb = plt.colorbar(img, **cbar_kws)
        # cb.set_ticks(np.arange(vmin, vmax + 0.001, 0.5))
        # # do linspace between vmin and vmax of 5 segments and trunc to 1 decimal:
        decimal = 10
        nsegments = 5
        cd_ticks = np.trunc(np.linspace(vmin, vmax, nsegments) * decimal) / decimal
        cb.set_ticks(cd_ticks)
    else:
        grid["cbar"] = cb = plt.colorbar(img, format=MinOneMaxFormatter(), **cbar_kws)
        cb.ax.yaxis.set_minor_formatter(MinOneMaxFormatter())

    # extra settings
    grid["ax_heatmap"].set_xlim(lo, hi)
    grid["ax_heatmap"].set_ylim(hi, lo)
    plt.grid(False)
    plt.axis("off")
    if title is not None:
        grid["ax_margin_x"].set_title(title)
    if xlabel is not None:
        grid["ax_heatmap"].set_xlabel(xlabel)
    if ylabel is not None:
        grid["ax_margin_y"].set_ylabel(ylabel)

    return grid