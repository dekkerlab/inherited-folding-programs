{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compartments & Saddleplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the compartments and saddleplot notebook! \n",
    "\n",
    "This notebook illustrates cooltools functions used for investigating chromosomal compartments, visible as plaid patterns in mammalian interphase contact frequency maps.\n",
    "\n",
    "These plaid patterns reflect tendencies of chromosome regions to make more frequent contacts with regions of the same type: active regions have increased contact frequency with other active regions, and intactive regions tend to contact other inactive regions more frequently. The strength of compartmentalization has been show to vary through the cell cycle, across cell types, and after degredation of components of the cohesin complex. \n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "* obtain compartment profiles using eigendecomposition\n",
    "* calculate and visualize strength of compartmentalization using saddleplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the number of threads for many common libraries\n",
    "from os import environ\n",
    "N_THREADS = '1'\n",
    "environ['OMP_NUM_THREADS'] = N_THREADS\n",
    "environ['OPENBLAS_NUM_THREADS'] = N_THREADS\n",
    "environ['MKL_NUM_THREADS'] = N_THREADS\n",
    "environ['VECLIB_MAXIMUM_THREADS'] = N_THREADS\n",
    "environ['NUMEXPR_NUM_THREADS'] = N_THREADS\n",
    "\n",
    "# https://superfastpython.com/numpy-number-blas-threads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os, subprocess\n",
    "import seaborn as sns\n",
    "import multiprocess as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python package for working with cooler files and tools for analysis\n",
    "import cooler\n",
    "import cooltools.lib.plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from saddle import saddleplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test data\n",
    "# this file is 145 Mb, and may take a few seconds to download\n",
    "import cooltools\n",
    "import bioframe\n",
    "from matplotlib.colors import LogNorm\n",
    "from helper_func import saddleplot\n",
    "from data_catalog import bws, bws_vlim, telo_dict\n",
    "from helper_func import get_stack, show_stacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import warnings\n",
    "\n",
    "import datashader as ds, xarray as xr\n",
    "from datashader import transfer_functions as tf, reductions as rd\n",
    "from datashader.mpl_ext import dsshow, alpha_colormap\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import itertools\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating per-chromosome compartmentalization\n",
    "\n",
    "We first load the Hi-C data at 100 kbp resolution. \n",
    "\n",
    "Note that the current implementation of eigendecomposition in cooltools assumes that individual regions can be held in memory-- for hg38 at 100kb this is either a 2422x2422 matrix for chr2, or a 3255x3255 matrix for the full cooler here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define genomic view that will be used to call dots and pre-compute expected\n",
    "\n",
    "# Use bioframe to fetch the genomic features from the UCSC.\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "hg38_arms_full = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "# # remove \"bad\" chromosomes and near-empty arms ...\n",
    "included_arms = hg38_arms_full[\"name\"].to_list()[:44] # all autosomal ones ...\n",
    "hg38_arms = hg38_arms_full[hg38_arms_full[\"name\"].isin(included_arms)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpire import WorkerPool\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cooler files that we'll work on :\n",
    "binsize = 25_000\n",
    "telo_clrs = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize}\") for _k, _path in telo_dict.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-load pre-calculated EV1s - for whatever resolution ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telo_cis_evs = {}\n",
    "for k, _fname in telo_dict.items():\n",
    "    # derive output name\n",
    "    _fname = f\"ev_bedraph/{k}.{binsize//1_000}kb.bed\"\n",
    "    print(f\"reading {_fname} ...\")\n",
    "    telo_cis_evs[k] = bioframe.read_table(_fname, schema=\"bedGraph\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _job(packed_data, sample):\n",
    "    # packed data -> exp_kwargs and a dict with coolers for each sample\n",
    "    exp_kwargs, clr_dict = packed_data\n",
    "    _clr = clr_dict[sample]\n",
    "    # in order to use spawn/forkserver we have to import for worker\n",
    "    from cooltools import expected_cis\n",
    "    _exp = expected_cis( _clr, **exp_kwargs)\n",
    "    return (sample, _exp)\n",
    "\n",
    "# define expected parameters in the form of kwargs-dict:\n",
    "exp_kwargs = dict(\n",
    "    view_df=hg38_arms,\n",
    "    intra_only=False,\n",
    "    nproc=12\n",
    ")\n",
    "\n",
    "# have to use daemon=False, because _job is multiprocessing-based already ...\n",
    "with WorkerPool(\n",
    "    n_jobs=8,\n",
    "    daemon=False,\n",
    "    shared_objects=( exp_kwargs, telo_clrs ),\n",
    "    start_method=\"forkserver\",  # little faster than spawn, fork is the fastest\n",
    "    use_dill=True,\n",
    ") as wpool:\n",
    "    results = wpool.map(_job, telo_clrs, progress_bar=True)\n",
    "\n",
    "# sort out the results ...\n",
    "telo_exps_cis = {sample: _exp for sample, _exp in results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the orientation of eigenvectors is determined up to a sign, the convention for Hi-C data anaylsis is to orient eigenvectors to be positively correlated with a binned profile of GC content as a 'phasing track'. \n",
    "\n",
    "In humans and mice, GC content is useful for phasing because it typically has a strong correlation at the 100kb-1Mb bin level with the eigenvector. In other organisms, other phasing tracks have been used to orient\n",
    "eigenvectors from Hi-C data. \n",
    "\n",
    "For other data analyses, different conventions are used to consistently orient eigenvectors. For example, spectral clustering as implemented in [scikit-learn](\n",
    "https://github.com/scikit-learn/scikit-learn/blob/03245ee3afe5ee9e2ff626e2290f02748d95e497/sklearn/utils/extmath.py#L1041) orients vectors such that the absolute maximum element of each vector is positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _job(packed_data, sample):\n",
    "#     # unpack data\n",
    "#     clr_dict, = packed_data\n",
    "#     exp_kwargs = dict(chunksize=1000000, nproc=12)\n",
    "#     from cooltools import expected_trans\n",
    "#     _clr = clr_dict[sample]\n",
    "#     _exp = expected_trans( _clr, **exp_kwargs).set_index([\"region1\", \"region2\"]).sort_index()\n",
    "#     return (sample, _exp)\n",
    "\n",
    "# # have to use daemon=False, because _job is multiprocessing-based already ...\n",
    "# with WorkerPool(\n",
    "#     n_jobs=8,\n",
    "#     daemon=False,\n",
    "#     shared_objects=(telo_clrs, ),\n",
    "#     start_method=\"forkserver\",\n",
    "#     use_dill=True,\n",
    "# ) as wpool:\n",
    "#     results = wpool.map(_job, telo_clrs, progress_bar=True)\n",
    "\n",
    "# # sort out the results ...\n",
    "# telo_exps_trans = {sample: _exp for sample, _exp in results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saddles for regular EVs ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to visualize preferences captured by the eigenvector is by using saddleplots.\n",
    "\n",
    "To generate a saddleplot, we first use the eigenvector to stratify genomic regions into groups with similar values of the eigenvector. These groups are then averaged over to create the saddleplot.\n",
    "This process is called \"digitizing\".\n",
    "\n",
    "Cooltools will operate with `digitized` bedgraph-like track with four columns. The fourth, or value, column is a categorical, as shown above for the first three bins. Categories have the following encoding:\n",
    "\n",
    "    - `1..n` <-> values assigned to bins defined by vrange or qrange\n",
    "    - `0` <-> left outlier values\n",
    "    - `n+1` <-> right outlier values\n",
    "    - `-1` <-> missing data (NaNs)\n",
    "    \n",
    "Track values can either be digitized by numeric values, by passing `vrange`, or by quantiles, by passing `qrange`, as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create saddles in cis with `saddle`, cooltools requires: a cooler, a table with expected as function of distance, and parameters for digitizing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`saddle` then returns two matrices: one with the sum for each pair of categories, `interaction_sum`, and the other with the number of bins for each pair of categories, `interaction_count`. Typically, `interaction_sum`/`interaction_count` is visualized.\n",
    "\n",
    "### We'll mostly run saddles by matching the contact map with the EV1 produced from that contact map, except for the Mito, Telo and Cyto samples ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in telo_cis_evs.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thids isd how we match contact map samples and track samples ...\n",
    "def get_track_sample(_sample):\n",
    "    if any( (_ in _sample) for _ in [\"Mito\", \"Telo\", \"Cyto\"] ):\n",
    "        if _sample.startswith(\"m\"):\n",
    "            return \"m5hR1R2\"\n",
    "        elif _sample.startswith(\"p\"):\n",
    "            return \"p5hR1R2\"\n",
    "        else:\n",
    "            print(\"what da heck ?!\")\n",
    "    else:\n",
    "        return _sample\n",
    "\n",
    "\n",
    "# thids isd how we match contact map samples and track samples ...\n",
    "def get_ctrl_track_sample(_sample):\n",
    "    if _sample.startswith(\"N\"):\n",
    "        return \"N93m5\"\n",
    "    else:\n",
    "        return \"m5hR1R2\"\n",
    "\n",
    "\n",
    "# create a track sample map to pass to the multiprocessing job ...\n",
    "track_sample_map = {}\n",
    "for _sample in telo_dict:\n",
    "    _track_sample = get_track_sample(_sample)\n",
    "    # create a map ...\n",
    "    track_sample_map[_sample] = telo_cis_evs[_track_sample]\n",
    "    # ...\n",
    "    print(f\"contact map: {_sample} using EV1 from {_track_sample}\")\n",
    "\n",
    "\n",
    "print(\"\\ncontrol tracks ...\")\n",
    "# create a track sample map - to one ctrl sample\n",
    "track_sample_ctrl_map = {}\n",
    "for _sample in telo_dict:\n",
    "    _track_ctrl_sample = get_ctrl_track_sample(_sample)\n",
    "    # create a map ...\n",
    "    track_sample_ctrl_map[_sample] = telo_cis_evs[_track_ctrl_sample]\n",
    "    # ...\n",
    "    print(f\"contact map: {_sample} using ctrl EV1 from {_track_ctrl_sample}\")\n",
    "\n",
    "\n",
    "saddle_kwargs = {\n",
    "    \"Q_LO\" : 0.025,  # ignore 2.5% of genomic bins with the lowest E1 values\n",
    "    \"Q_HI\" : 0.975,  # ignore 2.5% of genomic bins with the highest E1 values\n",
    "    \"N_GROUPS\" : 38,  # divide remaining 95% of the genome into 38 equisized groups, 2.5% each\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _job(packed_data, sample):\n",
    "    # packed data -> exp_kwargs and a dict with coolers for each sample\n",
    "    clr_dict, exp_dict, track_map, view_df, params = packed_data\n",
    "    _clr = clr_dict[sample]\n",
    "    _exp = exp_dict[sample]\n",
    "    _track = track_map[sample]\n",
    "    # # in order to use spawn/forkserver we have to import for worker\n",
    "    # # from cooltools import saddle\n",
    "    from cooltools.api.saddle import saddle_stack\n",
    "    _sum, _count = saddle_stack(\n",
    "        _clr,\n",
    "        _exp,\n",
    "        _track,\n",
    "        'cis',\n",
    "        view_df=view_df,\n",
    "        n_bins=params[\"N_GROUPS\"],\n",
    "        qrange=(params[\"Q_LO\"], params[\"Q_HI\"]),\n",
    "    )\n",
    "    return sample, _sum, _count\n",
    "\n",
    "# have to use daemon=False, because _job is multiprocessing-based already ...\n",
    "print(\"running saddles using their own EV, well, ... mostly ... \")\n",
    "with WorkerPool(\n",
    "    n_jobs=16,\n",
    "    daemon=True,\n",
    "    shared_objects=( telo_clrs, telo_exps_cis, track_sample_map, hg38_arms, saddle_kwargs),\n",
    "    start_method=\"fork\",  # little faster than spawn, fork is the fastest\n",
    "    use_dill=True,\n",
    ") as wpool:\n",
    "    results = wpool.map(_job, telo_clrs, progress_bar=True)\n",
    "\n",
    "# sort out the results ...\n",
    "interaction_sums = {}\n",
    "interaction_counts = {}\n",
    "for sample, _sum, _counts in results:\n",
    "    interaction_sums[sample] = _sum\n",
    "    interaction_counts[sample] = _counts\n",
    "\n",
    "########################################################################\n",
    "# Now repeat the same, but using 1 ctrl EV1 for all of the samples ...\n",
    "########################################################################\n",
    "# have to use daemon=False, because _job is multiprocessing-based already ...\n",
    "print(\"running saddles using ctrl 5hr EV across all samples:\")\n",
    "with WorkerPool(\n",
    "    n_jobs=16,\n",
    "    daemon=True,\n",
    "    shared_objects=( telo_clrs, telo_exps_cis, track_sample_ctrl_map, hg38_arms, saddle_kwargs ),\n",
    "    start_method=\"fork\",  # little faster than spawn, fork is the fastest\n",
    "    use_dill=True,\n",
    ") as wpool:\n",
    "    results = wpool.map(_job, telo_clrs, progress_bar=True)\n",
    "\n",
    "# sort out the results ...\n",
    "interaction_ctrl_sums = {}\n",
    "interaction_ctrl_counts = {}\n",
    "for sample, _sum, _counts in results:\n",
    "    interaction_ctrl_sums[sample] = _sum\n",
    "    interaction_ctrl_counts[sample] = _counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skipping trans saddles for now ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    telo_trans_filt_exps = {}\n",
    "    for _k, _clr in tqdm(telo_clrs.items()):\n",
    "        _df = telo_exps_trans[_k].reset_index()\n",
    "        m2 = _df[\"region2\"].isin([\"chrX\",\"chrY\",\"chrM\"])\n",
    "        m1 = _df[\"region1\"].isin([\"chrX\",\"chrY\",\"chrM\"])\n",
    "        telo_trans_filt_exps[_k] = _df[~(m1 | m2)]\n",
    "\n",
    "    # a view without M,X and Y chromosomes ...\n",
    "    sub_chrom_view = bioframe.make_viewframe(hg38_chromsizes)\n",
    "    bad_chroms = [\"chrX\",\"chrY\",\"chrM\"]\n",
    "    sub_chrom_view = sub_chrom_view[~sub_chrom_view[\"name\"].isin(bad_chroms)]\n",
    "\n",
    "    def _job(packed_data, sample):\n",
    "        # packed data -> exp_kwargs and a dict with coolers for each sample\n",
    "        clr_dict, exp_dict, track_map, view_df, params = packed_data\n",
    "        _clr = clr_dict[sample]\n",
    "        _exp = exp_dict[sample]\n",
    "        _track = track_map[sample]\n",
    "        # # in order to use spawn/forkserver we have to import for worker\n",
    "        from cooltools.api.saddle import saddle_stack\n",
    "        _sum, _count = saddle_stack(\n",
    "            _clr,\n",
    "            _exp,\n",
    "            _track,\n",
    "            'trans',\n",
    "            view_df=view_df,\n",
    "            n_bins=params[\"N_GROUPS\"],\n",
    "            qrange=(params[\"Q_LO\"], params[\"Q_HI\"]),\n",
    "        )\n",
    "        return sample, _sum, _count\n",
    "\n",
    "    # have to use daemon=False, because _job is multiprocessing-based already ...\n",
    "    with WorkerPool(\n",
    "        n_jobs=16,\n",
    "        daemon=True,\n",
    "        shared_objects=( telo_clrs, telo_trans_filt_exps, track_sample_map, sub_chrom_view, saddle_kwargs),\n",
    "        start_method=\"fork\",  # little faster than spawn, fork is the fastest\n",
    "        use_dill=True,\n",
    "    ) as wpool:\n",
    "        results = wpool.map(_job, telo_clrs, progress_bar=True)\n",
    "\n",
    "    # sort out the results ...\n",
    "    interaction_sums_trans = {}\n",
    "    interaction_counts_trans = {}\n",
    "    for sample, _sum, _counts in results:\n",
    "        interaction_sums_trans[sample] = _sum\n",
    "        interaction_counts_trans[sample] = _counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to plot saddle data, one useful way is shown below. \n",
    "This visualization includes histograms of the number of bins contributing to each row/column of the saddleplot.\n",
    "\n",
    "The saddle below shows average observed/expected contact frequency between regions grouped according to their digitized eigenvector values with a blue-to-white-to-red colormap. Inactive regions (i.e. low digitized values) are on the top and left, and active regions (i.e. high digitized values) are on the bottom and right. \n",
    "\n",
    "The saddleplot shows that inactive regions are enriched for contact frequency with other inactive regions (red area in the upper left), and active regions are enriched for contact frequency with other active regions (red area in the lower right). In contrast, active regions are depleted for contact frequency with inactive regions (blue area in top right and bottom left). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm saddles_EV_by_distance.hdf5\n",
    "# ! rm saddles_ctrlEV_by_distance.hdf5\n",
    "! ls -lah saddles*.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"saddles_EV_by_distance.hdf5\", 'x') as f:\n",
    "    # add metadata just in case\n",
    "    f.attrs[\"cis_binsize\"] = binsize\n",
    "    # f.attrs[\"trans_binsize\"] = binsize25\n",
    "    f.attrs.update(saddle_kwargs)\n",
    "    # CIS ...\n",
    "    # interaction_sums ...\n",
    "    _sums_grp = f.create_group(\"sums\")\n",
    "    # create subgroups per sample\n",
    "    for _sample, _arr in interaction_sums.items():\n",
    "        _ds = _sums_grp.create_dataset(_sample, data=_arr)\n",
    "        _ds.attrs[\"track\"] = get_track_sample(_sample)\n",
    "    # interaction_counts ...\n",
    "    _sums_grp = f.create_group(\"counts\")\n",
    "    # create subgroups per sample\n",
    "    for _sample, _arr in interaction_counts.items():\n",
    "        _ds = _sums_grp.create_dataset(_sample, data=_arr)\n",
    "        _ds.attrs[\"track\"] = get_track_sample(_sample)\n",
    "    # # TRANS ...\n",
    "    # # interaction_sums ...\n",
    "    # _sums_grp = f.create_group(\"sums_trans\")\n",
    "    # # create subgroups per sample\n",
    "    # for _sample, _arr in interaction_sums_trans.items():\n",
    "    #     _sums_grp.create_dataset(_sample, data=_arr)\n",
    "    # # interaction_counts ...\n",
    "    # _sums_grp = f.create_group(\"counts_trans\")\n",
    "    # # create subgroups per sample\n",
    "    # for _sample, _arr in interaction_counts_trans.items():\n",
    "    #     _sums_grp.create_dataset(_sample, data=_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"saddles_ctrlEV_by_distance.hdf5\", 'x') as f:\n",
    "    # add metadata just in case\n",
    "    f.attrs[\"cis_binsize\"] = binsize\n",
    "    f.attrs.update(saddle_kwargs)\n",
    "    # CIS ...\n",
    "    # interaction_ctrl_sums ...\n",
    "    _sums_grp = f.create_group(\"sums\")\n",
    "    # create subgroups per sample\n",
    "    for _sample, _arr in interaction_ctrl_sums.items():\n",
    "        _ds = _sums_grp.create_dataset(_sample, data=_arr)\n",
    "        _ds.attrs[\"track\"] = get_ctrl_track_sample(_sample)\n",
    "    # interaction_ctrl_counts ...\n",
    "    _sums_grp = f.create_group(\"counts\")\n",
    "    # create subgroups per sample\n",
    "    for _sample, _arr in interaction_ctrl_counts.items():\n",
    "        _ds = _sums_grp.create_dataset(_sample, data=_arr)\n",
    "        _ds.attrs[\"track\"] = get_ctrl_track_sample(_sample)\n",
    "    # # TRANS ...\n",
    "    # # interaction_ctrl_sums ...\n",
    "    # _sums_grp = f.create_group(\"sums_trans\")\n",
    "    # # create subgroups per sample\n",
    "    # for _sample, _arr in interaction_sums_trans.items():\n",
    "    #     _sums_grp.create_dataset(_sample, data=_arr)\n",
    "    # # interaction_ctrl_counts ...\n",
    "    # _sums_grp = f.create_group(\"counts_trans\")\n",
    "    # # create subgroups per sample\n",
    "    # for _sample, _arr in interaction_counts_trans.items():\n",
    "    #     _sums_grp.create_dataset(_sample, data=_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saddle_strength(k, sums_stack, counts_stack, dist_range=None):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    if dist_range is not None:\n",
    "        S = np.nansum(sums_stack[dist_range], axis=0)\n",
    "        C = np.nansum(counts_stack[dist_range], axis=0)\n",
    "    else:\n",
    "        S = np.nansum(sums_stack, axis=0)\n",
    "        C = np.nansum(counts_stack, axis=0)\n",
    "\n",
    "    # exclude extremes - the outliers\n",
    "    S = S[1:-1,1:-1]\n",
    "    C = C[1:-1,1:-1]\n",
    "\n",
    "    m, n = S.shape\n",
    "    if m != n:\n",
    "        raise ValueError(\"`saddledata` should be square.\")\n",
    "\n",
    "    # _b corner indices ...\n",
    "    _b = slice(0, k)\n",
    "    # _a corner indices ...\n",
    "    _a = slice(n-k, n)\n",
    "\n",
    "    # make sure corners are equally sized ...\n",
    "    assert (_b.stop - _b.start) == (_a.stop - _a.start)\n",
    "\n",
    "    intra_BB = np.nansum(S[_b, _b]) / np.nansum(C[_b, _b])\n",
    "    intra_AA = np.nansum(S[_a, _a]) / np.nansum(C[_a, _a])\n",
    "    intra_AA_BB = (\n",
    "        (np.nansum(S[_b, _b]) + np.nansum(S[_a, _a])) /\n",
    "        (np.nansum(C[_b, _b]) + np.nansum(C[_a, _a]))\n",
    "    )\n",
    "    inter_AB_BA = (\n",
    "        (np.nansum(S[_b, _a]) + np.nansum(S[_a, _b])) /\n",
    "        (np.nansum(C[_b, _a]) + np.nansum(C[_a, _b]))\n",
    "    )\n",
    "\n",
    "    return pd.Series({\"AA\" : intra_AA/inter, \"BB\" : intra_BB/inter, \"AA_BB\": intra_AA_BB/inter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saddle_strength(k, sample, dist_name, dist_range=None):\n",
    "#     \"\"\"\n",
    "#     ...\n",
    "#     \"\"\"\n",
    "#     if dist_name == \"trans\":\n",
    "#         S = np.nansum(interaction_sums_trans[sample], axis=0)\n",
    "#         C = np.nansum(interaction_counts_trans[sample], axis=0)\n",
    "#     else:\n",
    "#         if dist_range is not None:\n",
    "#             S = np.nansum(interaction_sums[sample][dist_range], axis=0)\n",
    "#             C = np.nansum(interaction_counts[sample][dist_range], axis=0)\n",
    "#         else:\n",
    "#             S = np.nansum(interaction_sums[sample], axis=0)\n",
    "#             C = np.nansum(interaction_counts[sample], axis=0)\n",
    "\n",
    "#     # ...\n",
    "#     S = S[1:-1,1:-1]\n",
    "#     C = C[1:-1,1:-1]\n",
    "\n",
    "#     m, n = S.shape\n",
    "#     if m != n:\n",
    "#         raise ValueError(\"`saddledata` should be square.\")\n",
    "\n",
    "#     intra_BB = np.nansum(S[0:k, 0:k]) / np.nansum(C[0:k, 0:k])\n",
    "#     intra_AA = np.nansum(S[n - k : n, n - k : n]) / np.nansum(C[n - k : n, n - k : n])\n",
    "#     intra_all = (np.nansum(S[0:k, 0:k])+np.nansum(S[n - k : n, n - k : n])) \\\n",
    "#                 / (np.nansum(C[0:k, 0:k])+np.nansum(C[n - k : n, n - k : n]))\n",
    "\n",
    "#     inter_sum = np.nansum(S[0:k, n - k : n]) + np.nansum(S[n - k : n, 0:k])\n",
    "#     inter_count = np.nansum(C[0:k, n - k : n]) + np.nansum(C[n - k : n, 0:k])\n",
    "#     inter = inter_sum / inter_count\n",
    "\n",
    "#     # return pd.Series({\"AA\" : intra_AA, \"BB\" : intra_BB})\n",
    "#     # return pd.Series({\"AA\" : intra_AA/inter, \"BB\" : intra_BB/inter,})\n",
    "#     return pd.Series({\"AA\" : intra_AA/inter, \"BB\" : intra_BB/inter, \"AandB\": intra_all/inter})\n",
    "#     # return pd.Series({\"all\": intra_all/inter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore GC-content vs gene density for fun ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fasta sequence is required for calculating binned profile of GC conent\n",
    "if not os.path.isfile('./hg38.fa'):\n",
    "    ## note downloading a ~1Gb file can take a minute\n",
    "    subprocess.call('wget https://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/hg38.fa.gz', shell=True)\n",
    "    subprocess.call('gunzip hg38.fa.gz', shell=True)\n",
    "\n",
    "#################################################################\n",
    "clr_ctrl = telo_clrs[\"m5hR1R2\"]\n",
    "bins = clr_ctrl.bins()[:]\n",
    "gc_fname = f'hg38_gc_cov_{binsize//1000}kb.tsv'\n",
    "if os.path.isfile(gc_fname):\n",
    "    print(f\"loading exiasting file {gc_fname} ...\")\n",
    "    gc_cov = pd.read_csv(gc_fname, sep='\\t')\n",
    "else:\n",
    "    hg38_genome = bioframe.load_fasta('./hg38.fa');\n",
    "    ## note the next command may require installing pysam\n",
    "    gc_cov = bioframe.frac_gc(bins[['chrom', 'start', 'end']], hg38_genome)\n",
    "    gc_cov.to_csv(gc_fname, index=False, sep='\\t')\n",
    "# display(gc_cov.head())\n",
    "\n",
    "#################################################################\n",
    "# load some genes ...\n",
    "all_gene_df = bioframe.read_table(\n",
    "    \"./fini_genes/hg38.refGene.exons.reducedchroms.hgbed\",\n",
    "    schema=\"bed6\"\n",
    ")\n",
    "\n",
    "gene_cov = bioframe.frac_gene_coverage(\n",
    "    bins,\n",
    "    all_gene_df,\n",
    ")[[\"chrom\",\"start\",\"end\",\"count\"]]\n",
    "# gene_cov.head()\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"GC\" : gc_cov[\"GC\"],\n",
    "    \"count\" : gene_cov[\"count\"].astype(\"float\"),\n",
    "})\n",
    "df.head()\n",
    "\n",
    "#################################################################\n",
    "# plotting GC vs gene counts ...\n",
    "_cats = pd.cut(df[\"count\"],bins=[0,1,2,3,np.inf],right=False)\n",
    "cmap = mpl.colormaps['Dark2']\n",
    "gene_counts = _cats.dtypes.categories\n",
    "\n",
    "f,axs = plt.subplots(nrows=2,ncols=1,sharex=True,figsize=(5,6))\n",
    "f.set_constrained_layout(True)\n",
    "\n",
    "ax = axs[0]\n",
    "GC_range=(0.3,0.7)\n",
    "ax.hist(\n",
    "    [df.groupby(_cats).get_group(i)[\"GC\"] for i in gene_counts],\n",
    "    density=True,\n",
    "    histtype=\"step\",\n",
    "    bins=np.linspace(*GC_range,75),\n",
    "    label=[f\"{i} genes/bin \" for i in gene_counts],\n",
    "    # cumulative=True,\n",
    "    # log=True,\n",
    "    # stacked=True,\n",
    "    color=cmap(np.linspace(0, 0.7, len(gene_counts)))\n",
    ");\n",
    "ax.legend(frameon=False)\n",
    "ax.set_ylabel(\"histogram density\")\n",
    "\n",
    "ax = axs[1]\n",
    "dsshow(\n",
    "    df,\n",
    "    ds.Point(\"GC\",\"count\"),\n",
    "    norm='eq_hist',\n",
    "    cmap=\"inferno\",\n",
    "    aspect=0.021,\n",
    "    x_range=GC_range,\n",
    "    y_range=(-0.1,10),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"GC\")\n",
    "ax.set_ylabel(\"gene count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T18:43:27.981259Z",
     "iopub.status.busy": "2024-03-26T18:43:27.980077Z",
     "iopub.status.idle": "2024-03-26T18:43:28.004569Z",
     "shell.execute_reply": "2024-03-26T18:43:28.003710Z",
     "shell.execute_reply.started": "2024-03-26T18:43:27.981198Z"
    }
   },
   "source": [
    "samples we've got EV1 for ...\n",
    "```\n",
    "mMito\n",
    "mTelo\n",
    "mCyto\n",
    "m5hR1R2\n",
    "m10hR1R2\n",
    "pMito\n",
    "pTelo\n",
    "pCyto\n",
    "p5hR1R2\n",
    "p10hR1R2\n",
    "mp10hR1R2\n",
    "N93m5\n",
    "N93m10\n",
    "N93p5\n",
    "N93p10\n",
    "N93mp10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare some EV1 ...\n",
    "\n",
    "samplex = \"N93m5\"\n",
    "sampley = \"N93p5\"\n",
    "_, xeigs = telo_cis_eigs_gene[samplex]\n",
    "_, yeigs = telo_cis_eigs_gene[sampley]\n",
    "\n",
    "f,ax = plt.subplots(nrows=1,ncols=1, figsize=(6,6),sharex=True,sharey=True)\n",
    "_art = dsshow(\n",
    "    pd.DataFrame({\"x\":xeigs[\"E1\"],\"y\":yeigs[\"E1\"]}),\n",
    "    ds.Point(\"x\", \"y\"),\n",
    "    # ds.count_cat(\"cat\"),\n",
    "    norm='eq_hist',\n",
    "    cmap=\"inferno\",\n",
    "    x_range=(-2,2),\n",
    "    y_range=(-2,2),\n",
    "    ax=ax,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "# unused but required import for doing 3d projections with matplotlib < 3.2\n",
    "import mpl_toolkits.mplot3d  # noqa: F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr=\"chr18\"\n",
    "\n",
    "_common_mask = pd.concat(\n",
    "    [_df.query(f\"chrom=='{chr}'\")[\"E1\"].rename(_sample) for _sample, (_, _df) in telo_cis_eigs_gene.items()],\n",
    "    axis=1,\n",
    ").isna().any(axis=1).to_numpy()\n",
    "\n",
    "_pca_samples = [\n",
    "    # 'mTelo',\n",
    "    # 'mCyto',\n",
    "    'm5hR1R2',\n",
    "    # 'm10hR1R2',\n",
    "    # 'pTelo',\n",
    "    # 'pCyto',\n",
    "    'p5hR1R2',\n",
    "    # 'p10hR1R2',\n",
    "    # 'mp10hR1R2',\n",
    "    'N93m5',\n",
    "    # 'N93m10',\n",
    "    # 'N93p5',\n",
    "    'N93p10',\n",
    "    # 'N93mp10',\n",
    "]\n",
    "_rest_samples = [_sample for _sample in telo_cis_eigs_gene if (_sample not in _pca_samples)]\n",
    "\n",
    "\n",
    "X = pd.concat(\n",
    "    [telo_cis_eigs_gene[_sample][1].query(f\"chrom=='{chr}'\")[\"E1\"].rename(_sample) for _sample in _pca_samples],\n",
    "    axis=1,\n",
    ").to_numpy()[~_common_mask].T\n",
    "\n",
    "\n",
    "\n",
    "X_rest = pd.concat(\n",
    "    [telo_cis_eigs_gene[_sample][1].query(f\"chrom=='{chr}'\")[\"E1\"].rename(_sample) for _sample in _rest_samples],\n",
    "    axis=1,\n",
    ").to_numpy()[~_common_mask].T\n",
    "\n",
    "\n",
    "\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "print(\"running PCA ...\")\n",
    "pca.fit(X)\n",
    "X_trans = pca.transform(X)\n",
    "X_rest_trans = pca.transform(X_rest)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr=\"chr18\"\n",
    "\n",
    "_common_mask = pd.concat(\n",
    "    [_df[\"E1\"].rename(_sample) for _sample, (_, _df) in telo_cis_eigs_gene.items()],\n",
    "    axis=1,\n",
    ").isna().any(axis=1).to_numpy()\n",
    "\n",
    "_pca_samples = [\n",
    "    # 'mTelo',\n",
    "    # 'mCyto',\n",
    "    'm5hR1R2',\n",
    "    'm10hR1R2',\n",
    "    # 'pTelo',\n",
    "    # 'pCyto',\n",
    "    'p5hR1R2',\n",
    "    'p10hR1R2',\n",
    "    # 'mp10hR1R2',\n",
    "    'N93m5',\n",
    "    'N93m10',\n",
    "    'N93p5',\n",
    "    'N93p10',\n",
    "    # 'N93mp10',\n",
    "]\n",
    "_rest_samples = [_sample for _sample in telo_cis_eigs_gene if (_sample not in _pca_samples)]\n",
    "\n",
    "\n",
    "X = pd.concat(\n",
    "    [telo_cis_eigs_gene[_sample][1][\"E1\"].rename(_sample) for _sample in _pca_samples],\n",
    "    axis=1,\n",
    ").to_numpy()[~_common_mask].T\n",
    "\n",
    "\n",
    "\n",
    "X_rest = pd.concat(\n",
    "    [telo_cis_eigs_gene[_sample][1][\"E1\"].rename(_sample) for _sample in _rest_samples],\n",
    "    axis=1,\n",
    ").to_numpy()[~_common_mask].T\n",
    "\n",
    "\n",
    "\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "print(\"running PCA ...\")\n",
    "pca.fit(X)\n",
    "X_trans = pca.transform(X)\n",
    "X_rest_trans = pca.transform(X_rest)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_x, _y, _z = X_trans[:,0], X_trans[:,1], X_trans[:,2]\n",
    "plt.scatter(_x, _y, s=50, color=\"red\")\n",
    "ax = plt.gca()\n",
    "for i, txt in enumerate(_pca_samples):\n",
    "    ax.annotate(txt, (_x[i], _y[i]))\n",
    "\n",
    "_x, _y, _z = X_rest_trans[:,0], X_rest_trans[:,1], X_rest_trans[:,2]\n",
    "plt.scatter(_x, _y, s=50, color=\"blue\")\n",
    "for i, txt in enumerate(_rest_samples):\n",
    "    ax.annotate(txt, (_x[i], _y[i]))\n",
    "\n",
    "\n",
    "\n",
    "_1, _2, _3 = pca.explained_variance_ratio_[:3]\n",
    "ax.set_xlabel(f\"pc1 {_1:.2f}\")\n",
    "ax.set_ylabel(f\"pc2 {_2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _x, _y, _z = X_trans[:,0], X_trans[:,1], X_trans[:,2]\n",
    "# fig = plt.figure(1, figsize=(6, 6))\n",
    "# ax = fig.add_subplot(111, projection=\"3d\", elev=48, azim=134)\n",
    "# ax.set_position([0, 0, 0.95, 1])\n",
    "# _1, _2, _3 = pca.explained_variance_ratio_[:3]\n",
    "# ax.scatter(_x, _y, _z, edgecolor=\"k\")\n",
    "# ax.set_xlabel(f\"pc1 {_1:.2f}\")\n",
    "# ax.set_ylabel(f\"pc2 {_2:.2f}\")\n",
    "# ax.set_zlabel(f\"pc3 {_3:.2f}\")\n",
    "# # plt.scatter(_x, _y, s=50, color=\"red\")\n",
    "# # ax = plt.gca()\n",
    "# for i, txt in enumerate(_name_samples):\n",
    "#     ax.text3D(_x[i], _y[i], _z[i], txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples_m = [\n",
    "    \"mMito\",\n",
    "    \"mTelo\",\n",
    "    \"mCyto\",\n",
    "    \"m5hR1R2\",\n",
    "    \"m10hR1R2\",\n",
    "]\n",
    "sub_samples_p = [\n",
    "    \"pMito\",\n",
    "    \"pTelo\",\n",
    "    \"pCyto\",\n",
    "    \"p5hR1R2\",\n",
    "    \"p10hR1R2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples_m),\n",
    "    ncols=2,\n",
    "    figsize=(16,10),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "# a contiguous region ...\n",
    "the_region = hg38_arms.set_index(\"name\").loc[\"chr12_p\"]\n",
    "#\n",
    "_start = 120_000_000\n",
    "_width = 55_000_000\n",
    "the_region = (\"chr6\",_start,_start+_width)\n",
    "\n",
    "for sample_m, sample_p, (i, axs) in zip(sub_samples_m, sub_samples_p, enumerate(axs)):\n",
    "    axm,axp = axs\n",
    "    meval, meigs = telo_cis_eigs_gene[sample_m]\n",
    "    peval, peigs = telo_cis_eigs_gene[sample_p]\n",
    "    # select for a region\n",
    "    meigs = bioframe.select(meigs, the_region)\n",
    "    peigs = bioframe.select(peigs, the_region)\n",
    "    axm.plot([0,len(meigs)],[0,0],'k',lw=0.25)\n",
    "    axm.plot( np.arange(0, len(meigs)), meigs['E1'], label='E1',linewidth=0.5, color=\"gray\")\n",
    "    # ...\n",
    "    axp.plot([0,len(peigs)],[0,0],'k',lw=0.25)\n",
    "    axp.plot( np.arange(0, len(peigs)), peigs['E1'], label='E1',linewidth=0.5, color=\"gray\")\n",
    "    # ...\n",
    "    axm.set_xlim(0, len(meigs))\n",
    "    axp.set_xlim(0, len(peigs))\n",
    "    # ...\n",
    "    axm.set_ylim(-1.5, 1.5)\n",
    "    axp.set_ylim(-1.5, 1.5)\n",
    "    # ...\n",
    "    axm.set_xticks([])\n",
    "    axm.set_yticks([])\n",
    "    axp.set_xticks([])\n",
    "    axp.set_yticks([])\n",
    "    if i == 0:\n",
    "        axm.set_title(\"m\")\n",
    "        axp.set_title(\"p\")\n",
    "    axm.set_ylabel(sample_m.lstrip(\"m\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-load ID anchors to put the on the map here as well ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_anchor_fnames = {\n",
    "    \"mega_2X_enrichment\": \"ID_anchors/mega_2X_enrichment.fourth_mega.max_size.bed\",\n",
    "    \"5hr_2X_enrichment_old\": \"ID_anchors/5hr_2X_enrichment.second_bulk.max_size.bed\",\n",
    "    \"5hr_2X_enrichment\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.bed\",\n",
    "    \"5hr_2X_enrichment_nosing\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.no_singletons.bed\",\n",
    "    \"5hr_notinCyto_2X_enrichment_signal\": \"ID_anchors/p5notin_pCyto_anchors_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"5hr_2X_enrichment_signal\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"10hr_2X_enrichment_signal\": \"ID_anchors/10hrs_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"N93p5_2X_enrichment_signal\": \"ID_anchors/N93p5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"pCyto_2X_enrichment_signal\": \"ID_anchors/pCyto_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"mCyto_2X_enrichment_signal\": \"ID_anchors/mCyto_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"mega_3X_enrichment\": \"ID_anchors/mega_3X_enrichment.fifth_mega3x.max_size.bed\",\n",
    "    \"MEGA_2X_enrichment\": \"ID_anchors/MEGAp5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGA_weaker_2X_enrichment\": \"ID_anchors/MEGA_plus_weak_anchors_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGAN93_2X_enrichment\": \"ID_anchors/MEGAN93p5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGAminus_2X_enrichment\": \"ID_anchors/MEGA_minus_ctrl_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"cyto_2x_enrichment\": \"ID_anchors/cyto_2x_enrichment.third_mCyto.max_size.bed\",\n",
    "}\n",
    "\n",
    "id_anchors_dict = {}\n",
    "for id_name, fname in id_anchor_fnames.items():\n",
    "    id_anchors_dict[id_name] = pd.read_csv(fname, sep=\"\\t\")\n",
    "    # ...\n",
    "    print(f\"loaded {len(id_anchors_dict[id_name]):5d} ID anchors {id_name:>20} in BED format ...\")\n",
    "\n",
    "\n",
    "# _anchors5 = id_anchors_dict[\"MEGA_2X_enrichment\"]\n",
    "_anchors5 = id_anchors_dict[\"5hr_2X_enrichment_signal\"]\n",
    "_anchorsCyto = id_anchors_dict[\"pCyto_2X_enrichment_signal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples =[\n",
    "    \"m5hR1R2\",\n",
    "    # \"pCyto\",\n",
    "    \"p5hR1R2\",\n",
    "]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples),\n",
    "    ncols=1,\n",
    "    figsize=(16,10),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "# a contiguous region ...\n",
    "the_region = hg38_arms.set_index(\"name\").loc[\"chr12_p\"]\n",
    "#\n",
    "_start = 130_000_000\n",
    "_width = 35_000_000\n",
    "the_region = (\"chr2\",_start,_start+_width)\n",
    "\n",
    "\n",
    "# detect IDs in the region to show on the plots ...\n",
    "# _anchors5 = id_anchors_dict[\"5hr_2X_enrichment_signal\"]\n",
    "# _anchorsCyto = id_anchors_dict[\"pCyto_2X_enrichment_signal\"]\n",
    "# MEGA_2X_enrichment\n",
    "id_in_reg = bioframe.select(id_anchors_dict[\"MEGA_2X_enrichment\"], the_region)\n",
    "_id_bins_in_reg_MEGA = id_in_reg.eval(\"(start - @_start)/@binsize\")\n",
    "id_in_reg = bioframe.select(id_anchors_dict[\"pCyto_2X_enrichment_signal\"], the_region)\n",
    "_id_bins_in_reg_Cyto = id_in_reg.eval(\"(start - @_start)/@binsize\")\n",
    "id_in_reg = bioframe.select(id_anchors_dict[\"5hr_2X_enrichment_signal\"], the_region)\n",
    "_id_bins_in_reg_5hrs = id_in_reg.eval(\"(start - @_start)/@binsize\")\n",
    "\n",
    "for ii, sample, ax in zip(itertools.count(), sub_samples, axs):\n",
    "    _eval, _eigs = telo_cis_eigs_gene[sample]\n",
    "    # select for a region\n",
    "    _eigs = bioframe.select(_eigs, the_region)\n",
    "    ax.plot([0,len(_eigs)],[0,0],'k',lw=0.25)\n",
    "    ax.plot( np.arange(0, len(_eigs)), _eigs['E1'], label='E1',linewidth=0.75, color=\"gray\")\n",
    "    # ...\n",
    "    ax.set_xlim(0, len(_eigs))\n",
    "    # ...\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    # ...\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if ii == 0:\n",
    "        ax.set_title(f\"EV1 @{the_region=}\")\n",
    "    ax.set_ylabel(sample)\n",
    "    for _id_bin in _id_bins_in_reg_MEGA:\n",
    "        ax.axvline(_id_bin, alpha=0.2, color=\"grey\")\n",
    "    for _id_bin in _id_bins_in_reg_5hrs:\n",
    "        ax.axvline(_id_bin, alpha=0.3, color=\"blue\")\n",
    "    for _id_bin in _id_bins_in_reg_Cyto:\n",
    "        ax.axvline(_id_bin, alpha=0.6, color=\"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples =[\n",
    "    \"m10hR1R2\",\n",
    "    \"mp10hR1R2\",\n",
    "    \"p10hR1R2\",\n",
    "]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples),\n",
    "    ncols=1,\n",
    "    figsize=(16,10),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "# a contiguous region ...\n",
    "the_region = hg38_arms.set_index(\"name\").loc[\"chr12_p\"]\n",
    "#\n",
    "_start = 128_000_000\n",
    "_width = 12_000_000\n",
    "the_region = (\"chr6\",_start,_start+_width)\n",
    "\n",
    "\n",
    "# detect IDs in the region to show on the plots ...\n",
    "# _anchors5 = id_anchors_dict[\"5hr_2X_enrichment_signal\"]\n",
    "# _anchorsCyto = id_anchors_dict[\"pCyto_2X_enrichment_signal\"]\n",
    "# MEGA_2X_enrichment\n",
    "id_in_reg = bioframe.select(id_anchors_dict[\"MEGA_2X_enrichment\"], the_region)\n",
    "_id_bins_in_reg_MEGA = id_in_reg.eval(\"(start - @_start)/@binsize\")\n",
    "id_in_reg = bioframe.select(id_anchors_dict[\"pCyto_2X_enrichment_signal\"], the_region)\n",
    "_id_bins_in_reg_Cyto = id_in_reg.eval(\"(start - @_start)/@binsize\")\n",
    "id_in_reg = bioframe.select(id_anchors_dict[\"5hr_2X_enrichment_signal\"], the_region)\n",
    "_id_bins_in_reg_5hrs = id_in_reg.eval(\"(start - @_start)/@binsize\")\n",
    "\n",
    "for ii, sample, ax in zip(itertools.count(), sub_samples, axs):\n",
    "    _eval, _eigs = telo_cis_eigs_gene[sample]\n",
    "    # select for a region\n",
    "    _eigs = bioframe.select(_eigs, the_region)\n",
    "    # ax.plot([0,len(_eigs)],[0,0],'k',lw=0.25)\n",
    "    # ax.plot([0,len(_eigs)],[0,0],'k',lw=0.25)\n",
    "    ax.axhline(0,color='k',lw=0.25)\n",
    "    ax.plot( np.arange(0, len(_eigs)-1), np.diff(_eigs['E1']), label='E1',linewidth=0.75, color=\"gray\")\n",
    "    # ...\n",
    "    ax.set_xlim(0, len(_eigs))\n",
    "    # ...\n",
    "    ax.set_ylim(-0.5, 0.5)\n",
    "    # ...\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if ii == 0:\n",
    "        ax.set_title(f\"delta(EV1) @{the_region=}\")\n",
    "    ax.set_ylabel(sample)\n",
    "    for _id_bin in _id_bins_in_reg_MEGA:\n",
    "        ax.axvline(_id_bin-1, alpha=0.2, color=\"grey\")\n",
    "    for _id_bin in _id_bins_in_reg_5hrs:\n",
    "        ax.axvline(_id_bin-1, alpha=0.3, color=\"blue\")\n",
    "    for _id_bin in _id_bins_in_reg_Cyto:\n",
    "        ax.axvline(_id_bin-1, alpha=0.6, color=\"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lite wrapper around KMeans ...\n",
    "from sklearn.cluster import KMeans\n",
    "def get_cluster_labels(df, num_clust, subset_cols=None):\n",
    "    \"\"\"\n",
    "     - small wrapper around KMeans ...\n",
    "\n",
    "    receives a DataFrame, performs Kmeans clustering,\n",
    "    treating rows as \"samples\" to be clustered and\n",
    "    different columns as the coordinates of those \"samples\"\n",
    "\n",
    "    returns a numpy array of cluster labels\n",
    "    - corresponding to the DataFrame ...\n",
    "    -1 stands for unclustered samples ...\n",
    "    \"\"\"\n",
    "    if subset_cols is not None:\n",
    "        X = df[subset_cols].to_numpy()\n",
    "    else:\n",
    "        # use all of the columns ...\n",
    "        X = df.to_numpy()\n",
    "    # ...\n",
    "    # ...\n",
    "    _nkluster = KMeans(n_clusters=num_clust)\n",
    "    # we can cluster only real values,\n",
    "    # mask all samples that have\n",
    "    # at least 1 NaN coordinate\n",
    "    real_samples_mask = np.all(~np.isnan(X), axis=1)\n",
    "    # subset data to real samples only ...\n",
    "    _X = X[real_samples_mask, :]\n",
    "    # perform clustering ...\n",
    "    kfit = _nkluster.fit(_X)\n",
    "    # we've clsutered only non-NA samples\n",
    "    # so we don't have any kfit.labels_ for the NaN-ed bins ...\n",
    "    _labels_unmasked = np.zeros_like( real_samples_mask, dtype=\"int\") - 1\n",
    "    _labels_unmasked[real_samples_mask] = kfit.labels_\n",
    "    # ...\n",
    "    return _labels_unmasked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds, xarray as xr\n",
    "from datashader import transfer_functions as tf, reductions as rd\n",
    "from datashader.mpl_ext import dsshow, alpha_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, meigs = telo_cis_eigs_gene[\"m5hR1R2\"]\n",
    "_, peigs = telo_cis_eigs_gene[\"p5hR1R2\"]\n",
    "_, mpeigs = telo_cis_eigs_gene['mp10hR1R2']\n",
    "\n",
    "# masking IDs with NaNs\n",
    "# meval, meigs = telo_cis_eigs[\"m5hR1R2\"]\n",
    "# meigs.loc[_id_idxCommon,\"E1\"] = np.nan\n",
    "# telo_cis_eigs[\"m5hR1R2\"] = (meval, meigs)\n",
    "\n",
    "# # a contiguous region ...\n",
    "# the_region = hg38_arms.set_index(\"name\").loc[\"chr2_p\"]\n",
    "\n",
    "# the_region = \"chr6\"\n",
    "# meigs = bioframe.select(meigs, the_region)\n",
    "# peigs = bioframe.select(peigs, the_region)\n",
    "# mpeigs = bioframe.select(mpeigs, the_region)\n",
    "\n",
    "_id_idx5 = bioframe.overlap(\n",
    "    meigs,\n",
    "    _anchors5,\n",
    "    return_index=True,\n",
    "    cols2=[\"chrom\",\"peak_start\",\"peak_end\"],\n",
    ").dropna(subset=[\"chrom_\",\"start_\",\"end_\"])[\"index\"].unique()\n",
    "_id_idxCyto = bioframe.overlap(\n",
    "    meigs,\n",
    "    _anchorsCyto,\n",
    "    return_index=True,\n",
    "    cols2=[\"chrom\",\"peak_start\",\"peak_end\"],\n",
    ").dropna(subset=[\"chrom_\",\"start_\",\"end_\"])[\"index\"].unique()\n",
    "# _id_idxCommon = np.unique(np.concatenate([_id_idx5, _id_idxCyto]))\n",
    "\n",
    "# df = pd.DataFrame({ \"m\":meigs[\"E1\"], \"p\":peigs[\"E1\"] })\n",
    "df = pd.DataFrame({\n",
    "    \"m\":meigs[\"E1\"], \"p\":peigs[\"E1\"],\n",
    "    \"m2\":meigs[\"E2\"], \"p2\":peigs[\"E2\"],\n",
    "    # \"m3\":meigs[\"E3\"], \"p3\":peigs[\"E3\"],\n",
    "})\n",
    "df[\"cat\"] = get_cluster_labels(df, num_clust=3)\n",
    "df[\"cat\"] = df[\"cat\"].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots( nrows=1, ncols=1, figsize=(6,6) )\n",
    "\n",
    "_evmin, _evmax = -2, 2\n",
    "hist_kwargs = dict(\n",
    "    bins=np.linspace(_evmin, _evmax, 100),\n",
    "    # color=[\"grey\",\"royalblue\",\"crimson\"],\n",
    "    density=False,\n",
    "    histtype=\"step\",\n",
    ")\n",
    "\n",
    "_art = dsshow(\n",
    "    df,\n",
    "    ds.Point(\"m\", \"p\"),\n",
    "    ds.count_cat(\"cat\"),\n",
    "    norm='eq_hist',\n",
    "    cmap=\"inferno\",\n",
    "    x_range=(_evmin, _evmax),\n",
    "    y_range=(_evmin, _evmax),\n",
    "    shade_hook=partial(tf.dynspread, threshold=np.log10(9.5145), how='over'),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend(handles=_art.get_legend_elements(), frameon=False)\n",
    "# plt.title('Point category');\n",
    "\n",
    "# # ax.invert_yaxis()\n",
    "# # ax.invert_xaxis()\n",
    "# _id_marker_size = 0.5\n",
    "# for _color, _idx_subset in zip([\"royalblue\", \"crimson\"], [_id_idx5, _id_idxCyto]):\n",
    "#     ax.scatter(\n",
    "#         df.loc[_idx_subset, \"m\"],\n",
    "#         df.loc[_idx_subset, \"p\"],\n",
    "#         s=_id_marker_size,\n",
    "#         alpha=0.8,\n",
    "#         color=_color\n",
    "#     )\n",
    "\n",
    "ax.set_xlabel(\"m-cis EV1\")\n",
    "ax.set_ylabel(\"p-cis EV1\")\n",
    "_grid_kwargs = dict(color=\"grey\", lw=0.5)\n",
    "ax.axvline(0, **_grid_kwargs)\n",
    "ax.axhline(0, **_grid_kwargs)\n",
    "ax.plot([_evmin, _evmax],[_evmin, _evmax], **_grid_kwargs)\n",
    "# ...\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_x = divider.append_axes(\"top\", size=1, pad=0.1, sharex=ax)\n",
    "ax_y = divider.append_axes(\"right\", size=1, pad=0.1, sharey=ax)\n",
    "# # ...\n",
    "# for ax, _type, _orient in zip([ax_x, ax_y], [\"m\", \"p\"], [\"vertical\", \"horizontal\"]):\n",
    "#     ax.hist(\n",
    "#         [df[ _type], df.loc[_id_idx5, _type], df.loc[_id_idxCyto, _type]],\n",
    "#         orientation=_orient,\n",
    "#         **hist_kwargs,\n",
    "#     )\n",
    "# # # ...\n",
    "for ax, _type, _orient in zip([ax_x, ax_y], [\"m\", \"p\"], [\"vertical\", \"horizontal\"]):\n",
    "    ax.hist(\n",
    "        [g[_type] for i,g in df.groupby(\"cat\", observed=True) if i != -1],\n",
    "        orientation=_orient,\n",
    "        **hist_kwargs,\n",
    "    )\n",
    "# make some labels invisible\n",
    "ax_x.xaxis.set_tick_params(labelbottom=False)\n",
    "ax_y.yaxis.set_tick_params(labelleft=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(telo_cis_eigs_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots( nrows=1, ncols=1, figsize=(7,5) )\n",
    "bins=np.linspace(_evmin, _evmax, 100)\n",
    "\n",
    "\n",
    "x = telo_cis_eigs_gene[\"mCyto\"][1][\"E1\"]\n",
    "y = telo_cis_eigs_gene[\"pCyto\"][1][\"E1\"]\n",
    "# z = telo_cis_eigs_gene['pCyto'][1][\"E1\"]\n",
    "\n",
    "ax.hist(x, bins=bins, label=\"m\")\n",
    "ax.hist(y, bins=bins, alpha=0.5, label=\"p\");\n",
    "# ax.hist(z, bins=bins, alpha=0.5, label=\"mp\");\n",
    "ax.legend(frameon=False)\n",
    "ax.set_title(\"Cyto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots( nrows=1, ncols=1, figsize=(7,5) )\n",
    "bins=np.linspace(_evmin, _evmax, 100)\n",
    "\n",
    "\n",
    "x = telo_cis_eigs_gene[\"m10hR1R2\"][1][\"E1\"]\n",
    "y = telo_cis_eigs_gene[\"p10hR1R2\"][1][\"E1\"]\n",
    "# z = telo_cis_eigs_gene['pCyto'][1][\"E1\"]\n",
    "\n",
    "ax.hist(x, bins=bins, label=\"m\")\n",
    "ax.hist(y, bins=bins, alpha=0.5, label=\"p\");\n",
    "# ax.hist(z, bins=bins, alpha=0.5, label=\"mp\");\n",
    "ax.legend(frameon=False)\n",
    "ax.set_title(\"10hR1R2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots( nrows=1, ncols=1, figsize=(7,5) )\n",
    "bins=np.linspace(_evmin, _evmax, 100)\n",
    "\n",
    "\n",
    "x = telo_cis_eigs_gene[\"m5hR1R2\"][1][\"E1\"]\n",
    "y = telo_cis_eigs_gene[\"p5hR1R2\"][1][\"E1\"]\n",
    "# z = telo_cis_eigs_gene['pCyto'][1][\"E1\"]\n",
    "\n",
    "ax.hist(x, bins=bins, label=\"m\")\n",
    "ax.hist(y, bins=bins, alpha=0.5, label=\"p\");\n",
    "# ax.hist(z, bins=bins, alpha=0.5, label=\"mp\");\n",
    "ax.legend(frameon=False)\n",
    "ax.set_title(\"5hR1R2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots( nrows=1, ncols=1, figsize=(6,6) )\n",
    "\n",
    "_evmin, _evmax = -2, 2\n",
    "hist_kwargs = dict(\n",
    "    bins=np.linspace(_evmin, _evmax, 100),\n",
    "    color=[\"grey\",\"royalblue\",\"crimson\"],\n",
    "    density=True,\n",
    "    histtype=\"step\",\n",
    ")\n",
    "\n",
    "_art = dsshow(\n",
    "    df,\n",
    "    ds.Point(\"m\", \"p\"),\n",
    "    ds.count_cat(\"cat\"),\n",
    "    norm='eq_hist',\n",
    "    cmap=\"inferno\",\n",
    "    x_range=(_evmin, _evmax),\n",
    "    y_range=(_evmin, _evmax),\n",
    "    shade_hook=partial(tf.dynspread, threshold=np.log10(9.5145), how='over'),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend(handles=_art.get_legend_elements(), frameon=False)\n",
    "# plt.title('Point category');\n",
    "\n",
    "_id_marker_size = 0.0\n",
    "for _color, _idx_subset in zip([\"royalblue\", \"crimson\"], [_id_idx5, _id_idxCyto]):\n",
    "    ax.scatter(\n",
    "        df.loc[_idx_subset, \"m\"],\n",
    "        df.loc[_idx_subset, \"p\"],\n",
    "        s=_id_marker_size,\n",
    "        alpha=0.8,\n",
    "        color=_color\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"m-cis EV1\")\n",
    "ax.set_ylabel(\"p-cis EV1\")\n",
    "_grid_kwargs = dict(color=\"grey\", lw=0.5)\n",
    "ax.axvline(0, **_grid_kwargs)\n",
    "ax.axhline(0, **_grid_kwargs)\n",
    "ax.plot([_evmin, _evmax],[_evmin, _evmax], **_grid_kwargs)\n",
    "# ...\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_x = divider.append_axes(\"top\", size=1, pad=0.1, sharex=ax)\n",
    "ax_y = divider.append_axes(\"right\", size=1, pad=0.1, sharey=ax)\n",
    "# ...\n",
    "for ax, _type, _orient in zip([ax_x, ax_y], [\"m\", \"p\"], [\"vertical\", \"horizontal\"]):\n",
    "    ax.hist(\n",
    "        [df[ _type], df.loc[_id_idx5, _type], df.loc[_id_idxCyto, _type]],\n",
    "        orientation=_orient,\n",
    "        **hist_kwargs,\n",
    "    )\n",
    "# make some labels invisible\n",
    "ax_x.xaxis.set_tick_params(labelbottom=False)\n",
    "ax_y.yaxis.set_tick_params(labelleft=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots( nrows=1, ncols=1, figsize=(6,6) )\n",
    "\n",
    "_evmin, _evmax = -2, 2\n",
    "hist_kwargs = dict(\n",
    "    bins=np.linspace(_evmin, _evmax, 100),\n",
    "    color=[\"grey\",\"royalblue\",\"crimson\"],\n",
    "    density=False,\n",
    "    histtype=\"step\",\n",
    ")\n",
    "\n",
    "_art = dsshow(\n",
    "    df,\n",
    "    ds.Point(\"m\", \"p\"),\n",
    "    ds.count_cat(\"cat\"),\n",
    "    norm='eq_hist',\n",
    "    cmap=\"inferno\",\n",
    "    x_range=(_evmin, _evmax),\n",
    "    y_range=(_evmin, _evmax),\n",
    "    shade_hook=partial(tf.dynspread, threshold=np.log10(9.5145), how='over'),\n",
    "    ax=ax,\n",
    ")\n",
    "ax.legend(handles=_art.get_legend_elements(), frameon=False)\n",
    "# plt.title('Point category');\n",
    "\n",
    "_id_marker_size = 0.0\n",
    "for _color, _idx_subset in zip([\"royalblue\", \"crimson\"], [_id_idx5, _id_idxCyto]):\n",
    "    ax.scatter(\n",
    "        df.loc[_idx_subset, \"m\"],\n",
    "        df.loc[_idx_subset, \"p\"],\n",
    "        s=_id_marker_size,\n",
    "        alpha=0.8,\n",
    "        color=_color\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"m-cis EV1\")\n",
    "ax.set_ylabel(\"p-cis EV1\")\n",
    "_grid_kwargs = dict(color=\"grey\", lw=0.5)\n",
    "ax.axvline(0, **_grid_kwargs)\n",
    "ax.axhline(0, **_grid_kwargs)\n",
    "ax.plot([_evmin, _evmax],[_evmin, _evmax], **_grid_kwargs)\n",
    "# ...\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_x = divider.append_axes(\"top\", size=1, pad=0.1, sharex=ax)\n",
    "ax_y = divider.append_axes(\"right\", size=1, pad=0.1, sharey=ax)\n",
    "# ...\n",
    "for ax, _type, _orient in zip([ax_x, ax_y], [\"m\", \"p\"], [\"vertical\", \"horizontal\"]):\n",
    "    ax.hist(\n",
    "        [df[ _type], df.loc[_id_idx5, _type], df.loc[_id_idxCyto, _type]],\n",
    "        orientation=_orient,\n",
    "        **hist_kwargs,\n",
    "    )\n",
    "# make some labels invisible\n",
    "ax_x.xaxis.set_tick_params(labelbottom=False)\n",
    "ax_y.yaxis.set_tick_params(labelleft=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"m\":meigs[\"E1\"],\n",
    "#         \"p\":peigs[\"E1\"],\n",
    "#         # \"cat\":0\n",
    "#     }\n",
    "# )\n",
    "# # df.loc[_id_idx,\"cat\"] = 1\n",
    "# # df[\"cat\"] = df[\"cat\"].astype(\"category\")\n",
    "\n",
    "# f,axs = plt.subplots(nrows=1,ncols=2, figsize=(12,6),sharex=True,sharey=True)\n",
    "\n",
    "# ax = axs[0]\n",
    "# _art = dsshow(\n",
    "#     df,\n",
    "#     ds.Point(\"m\", \"p\"),\n",
    "#     # ds.count_cat(\"cat\"),\n",
    "#     norm='eq_hist',\n",
    "#     cmap=\"inferno\",\n",
    "#     x_range=(-2,2),\n",
    "#     y_range=(-2,2),\n",
    "#     ax=ax,\n",
    "# )\n",
    "# ax.scatter(\n",
    "#     df.loc[_id_idx5,\"m\"],\n",
    "#     df.loc[_id_idx5,\"p\"],\n",
    "#     s=0.2,\n",
    "#     alpha=0.8,\n",
    "#     color=\"royalblue\"\n",
    "# )\n",
    "# ax.scatter(\n",
    "#     df.loc[_id_idxCyto,\"m\"],\n",
    "#     df.loc[_id_idxCyto,\"p\"],\n",
    "#     s=0.2,\n",
    "#     alpha=0.8,\n",
    "#     color=\"crimson\"\n",
    "# )\n",
    "# ax.set_xlabel(\"m-cis EV1\")\n",
    "# ax.set_ylabel(\"p-cis EV1\")\n",
    "# ax.axvline(0, color=\"grey\", lw=0.5)\n",
    "# ax.axhline(0, color=\"grey\", lw=0.5)\n",
    "# ax.plot([-2,2],[-2,2], color=\"grey\", lw=0.5)\n",
    "# #\n",
    "# divider = make_axes_locatable(ax)\n",
    "# ax_x = divider.append_axes(\"top\", size=1, pad=0.1, sharex=ax)\n",
    "# ax_y = divider.append_axes(\"right\", size=1, pad=0.1, sharey=ax)\n",
    "\n",
    "# # ax_x.hist(df[\"m\"],bins=np.linspace(-2,2,100),alpha=0.5,color=\"grey\")\n",
    "# # ax_x.hist(df.loc[_id_idx5,\"m\"],bins=np.linspace(-2,2,100),color=\"royalblue\")\n",
    "# # ax_x.hist(df.loc[_id_idxCyto,\"m\"],bins=np.linspace(-2,2,100),color=\"crimson\")\n",
    "\n",
    "# ax_x.hist(\n",
    "#     [df[\"m\"], df.loc[_id_idx5,\"m\"], df.loc[_id_idxCyto,\"m\"]],\n",
    "#     bins=np.linspace(-2,2,100),\n",
    "#     # alpha=0.5,\n",
    "#     color=[\"grey\",\"royalblue\",\"crimson\"],\n",
    "#     orientation=\"vertical\",\n",
    "#     density=True,\n",
    "#     histtype=\"step\",\n",
    "#     # stacked=True\n",
    "# )\n",
    "\n",
    "\n",
    "# ax_y.hist(\n",
    "#     [df[\"p\"], df.loc[_id_idx5,\"p\"], df.loc[_id_idxCyto,\"p\"]],\n",
    "#     bins=np.linspace(-2,2,100),\n",
    "#     # alpha=0.5,\n",
    "#     color=[\"grey\",\"royalblue\",\"crimson\"],\n",
    "#     orientation=\"horizontal\",\n",
    "#     density=True,\n",
    "#     histtype=\"step\",\n",
    "#     # stacked=True\n",
    "# )\n",
    "\n",
    "# ax_x.set_xlim(-2,2)\n",
    "# # ax_y.set_ylim(-2,2)\n",
    "\n",
    "# ax = axs[1]\n",
    "# _art = dsshow(\n",
    "#     df.drop(_id_idxCommon, axis=0),\n",
    "#     # df,\n",
    "#     ds.Point(\"m\", \"p\"),\n",
    "#     # ds.count_cat(\"cat\"),\n",
    "#     norm='log',\n",
    "#     cmap=\"inferno_r\",\n",
    "#     x_range=(-2,2),\n",
    "#     y_range=(-2,2),\n",
    "#     ax=ax,\n",
    "# )\n",
    "# ax.axvline(0, color=\"grey\", lw=0.5)\n",
    "# ax.axhline(0, color=\"grey\", lw=0.5)\n",
    "# ax.plot([-2,2],[-2,2], color=\"grey\", lw=0.5)\n",
    "\n",
    "# divider = make_axes_locatable(ax)\n",
    "# ax_x = divider.append_axes(\"top\", size=1, pad=0.1, sharex=ax)\n",
    "# ax_y = divider.append_axes(\"right\", size=1, pad=0.1, sharey=ax)\n",
    "# # # create new axes on the right and on the top of the current axes.\n",
    "# # divider = make_axes_locatable(axb)\n",
    "# # axb_x = divider.append_axes(\"bottom\", size=0.12, pad=0.00, sharex=axb)\n",
    "# # axb_y = divider.append_axes(\"left\", size=0.12, pad=0.00, sharey=axb)\n",
    "# # # create new axes on the right and on the top of the current axes.\n",
    "# ax_x.hist(df.drop(_id_idxCommon, axis=0)[\"m\"],bins=np.linspace(-2,2,100))\n",
    "# ax_y.hist(df.drop(_id_idxCommon, axis=0)[\"p\"],bins=np.linspace(-2,2,100), orientation=\"horizontal\")\n",
    "# ax_x.set_xlim(-2,2)\n",
    "# # ax_y.set_ylim(-2,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross correlation of the EV1 for selected regions and genome-wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = {}\n",
    "for sample in sub_samples_m+sub_samples_p:\n",
    "    eval, eigs = telo_cis_eigs_gene[sample]\n",
    "\n",
    "    ddd[sample] = bioframe.select(eigs, the_region)[\"E1\"]\n",
    "    # ddd[sample] = eigs[\"E1\"]\n",
    "\n",
    "sns.heatmap(pd.DataFrame(ddd).corr(method='pearson'), annot=True, cmap=\"Reds\",vmin=0,vmax=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = {}\n",
    "for sample in sub_samples_m+sub_samples_p:\n",
    "    eval, eigs = telo_cis_eigs_gene[sample]\n",
    "\n",
    "    # ddd[sample] = bioframe.select(eigs, the_region)[\"E1\"]\n",
    "    ddd[sample] = eigs[\"E1\"]\n",
    "\n",
    "sns.heatmap(pd.DataFrame(ddd).corr(method='pearson'), annot=True, cmap=\"Reds\",vmin=0,vmax=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at eigenvalues jusat for fun ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = {}\n",
    "numevals = 20\n",
    "for sample in sub_samples_m+sub_samples_p:\n",
    "    eval, eigs = telo_cis_eigs_gene[sample]\n",
    "\n",
    "    # ddd[sample] = bioframe.select(eigs, the_region)[\"E1\"]\n",
    "    ddd[sample] = eval.query(\"name == 'chr6_q'\")[[f\"eigval{i}\" for i in range(1,numevals+1)]]\n",
    "\n",
    "# sns.heatmap(pd.DataFrame(ddd).corr(method='spearman'), annot=True, cmap=\"Reds\",vmin=0,vmax=1)\n",
    "plt.imshow(pd.concat(ddd).abs(), cmap=\"Reds\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(np.arange(len(sub_samples_m+sub_samples_p)))\n",
    "ax.set_yticklabels(sub_samples_m+sub_samples_p)\n",
    "\n",
    "ax.set_xticks(np.arange(numevals))\n",
    "ax.set_xticklabels([f\"e{i}\" for i in range(1,numevals+1)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the first eigenvector next to the Hi-C map allows us to see how this captures the plaid pattern. \n",
    "\n",
    "To better visualize this relationship, we overlay the map with a binary segmentation of the eigenvector. Eigenvectors can be segmented by a variety of methods. The simplest segmentation, shown here, is to simply binarize eigenvectors, and term everything above zero the \"A-compartment\" and everything below 0 the \"B-compartment\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in telo_clrs:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l digitized_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _sample in telo_clrs:\n",
    "    track = align_track_with_cooler(\n",
    "        telo_cis_eigs_gene[_sample][1][[\"chrom\",\"start\",\"end\",\"E1\"]],\n",
    "        telo_clrs[_sample],\n",
    "        view_df=hg38_arms,\n",
    "        clr_weight_name=\"weight\",\n",
    "        mask_clr_bad_bins=True,\n",
    "        drop_track_na=False,  # this adds check for chromosomes that have all missing values\n",
    "    )\n",
    "    digitized_track, binedges = digitize(\n",
    "        track.iloc[:, :4],\n",
    "        n_bins,\n",
    "        qrange=qrange,\n",
    "        digitized_suffix=\".d\",\n",
    "    )\n",
    "    digitized_track[\"value\"] = track[\"value\"]\n",
    "    print(f\"saving {_sample} ...\")\n",
    "    # print(digitized_track)\n",
    "    digitized_track.to_csv(f\"./digitized_ev/{_sample}.tsv\", sep=\"\\t\", index=False)\n",
    "    # xxxm = digitized_track.groupby(\"value.d\")[\"value\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(4,1.5))\n",
    "ax = f.add_subplot()\n",
    "data = xxxm.loc[1:38]\n",
    "ax.fill_between(data.index, data, 0, color=\"lightsteelblue\", ec=\"black\",step=\"mid\")\n",
    "ax.set_ylim(-1.2,1.2)\n",
    "ax.set_xlim(1,38.1)\n",
    "ax.spines[:].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(True)\n",
    "ax.tick_params(bottom=False,left=True,labelbottom=False)\n",
    "# ax.set_frame_on(False)\n",
    "# plt.axis(\"off\")\n",
    "ax.grid(color=\"black\",lw=0.5)\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "# f = plt.figure(figsize=(4,1.5))\n",
    "# ax = f.add_subplot()\n",
    "data = xxxp.loc[1:38]\n",
    "ax.fill_between(data.index, data, 0, color=\"green\", ec=\"black\",step=\"mid\",alpha=0.7)\n",
    "ax.set_ylim(-1.2,1.2)\n",
    "ax.set_xlim(1,38.1)\n",
    "ax.spines[:].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(True)\n",
    "ax.tick_params(bottom=False,left=True,labelbottom=False)\n",
    "# ax.set_frame_on(False)\n",
    "# plt.axis(\"off\")\n",
    "ax.grid(color=\"black\",lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(\n",
    "#     nrows=len(sub_samples_m),\n",
    "#     ncols=2,\n",
    "#     figsize=(4,12),\n",
    "#     sharex=True,\n",
    "#     sharey=True,\n",
    "# )\n",
    "\n",
    "# imshow_kwargs = dict(\n",
    "#         norm=LogNorm(vmin=1/3, vmax=3),\n",
    "#         cmap=\"RdBu_r\",\n",
    "#         interpolation=\"nearest\",\n",
    "# )\n",
    "\n",
    "# min_diag, max_diag = 0,-1\n",
    "\n",
    "# for sample_m, sample_p, (i, axs) in zip(sub_samples_m, sub_samples_p, enumerate(axs)):\n",
    "#     axm,axp = axs\n",
    "#     Cm = np.divide(\n",
    "#         np.nanmean(interaction_sums[sample_m][min_diag:max_diag], axis=0),\n",
    "#         np.nanmean(interaction_counts[sample_m][min_diag:max_diag], axis=0)\n",
    "#     )\n",
    "#     Cp = np.divide(\n",
    "#         np.nanmean(interaction_sums[sample_p][min_diag:max_diag], axis=0),\n",
    "#         np.nanmean(interaction_counts[sample_p][min_diag:max_diag], axis=0)\n",
    "#     )\n",
    "#     axm.imshow(Cm[1:-1,1:-1], **imshow_kwargs)\n",
    "#     axp.imshow(Cp[1:-1,1:-1], **imshow_kwargs)\n",
    "#     axm.set_xticks([])\n",
    "#     axm.set_yticks([])\n",
    "#     axp.set_xticks([])\n",
    "#     axp.set_yticks([])\n",
    "#     if i == 0:\n",
    "#         axm.set_title(\"m\")\n",
    "#         axp.set_title(\"p\")\n",
    "#     axm.set_ylabel(sample_m.lstrip(\"m\"))\n",
    "\n",
    "# fig.suptitle(f\"cis saddles: {int((min_diag*binsize)//1_000_000)}-{int((max_diag*binsize)//1_000_000)} Mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/48625475/python-shifted-logarithmic-colorbar-white-color-offset-to-center\n",
    "class MidPointLogNorm(LogNorm):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        LogNorm.__init__(self,vmin=vmin, vmax=vmax, clip=clip)\n",
    "        self.midpoint=midpoint\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [np.log(self.vmin), np.log(self.midpoint), np.log(self.vmax)], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(np.log(value), x, y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_saddle_data(sample, dist_name, dist_range=None):\n",
    "    \"\"\"\n",
    "    little convenience func - to turn local interaction_sums and interaction_counts\n",
    "    into saddle data ...\n",
    "    \"\"\"\n",
    "    if dist_name == \"trans\":\n",
    "        _sum = np.nansum(interaction_sums_trans[sample], axis=0)\n",
    "        _count = np.nansum(interaction_counts_trans[sample], axis=0)\n",
    "    else:\n",
    "        if dist_range is not None:\n",
    "            _sum = np.nansum(interaction_sums[sample][dist_range], axis=0)\n",
    "            _count = np.nansum(interaction_counts[sample][dist_range], axis=0)\n",
    "        else:\n",
    "            _sum = np.nansum(interaction_sums[sample], axis=0)\n",
    "            _count = np.nansum(interaction_counts[sample], axis=0)\n",
    "    return _sum / _count\n",
    "\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        # norm=LogNorm(vmin=1/5, vmax=5),\n",
    "        norm=MidPointLogNorm(vmin=1/5, vmax=3, midpoint=1),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"none\",\n",
    ")\n",
    "\n",
    "\n",
    "# # # introduce distance ranges\n",
    "# # # 0-1mb: 0:21 bins\n",
    "# # # 1-7Mb: 21:141 bins\n",
    "# # # 7-50Mb: 141:1001 bins\n",
    "# # # trans: : bins\n",
    "# distances = {\n",
    "#     \"short:<1MB\": slice(0, int(1_000_000/binsize)+1),\n",
    "#     \"mid:1MB-7Mb\": slice(int(1_000_000/binsize), int(7_000_000/binsize)+1),\n",
    "#     \"long7Mb-50Mb\": slice(int(7_000_000/binsize), int(50_000_000/binsize)+1),\n",
    "#     \"trans\": slice(None),\n",
    "# }\n",
    "distances = {\n",
    "    \"all-cis\": slice(None),\n",
    "    \"trans\": slice(None),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples_m = [\n",
    "    \"mMito\",\n",
    "    \"mTelo\",\n",
    "    \"mCyto\",\n",
    "    \"m5hR1R2\",\n",
    "    \"m10hR1R2\",\n",
    "]\n",
    "sub_samples_p = [\n",
    "    \"pMito\",\n",
    "    \"pTelo\",\n",
    "    \"pCyto\",\n",
    "    \"p5hR1R2\",\n",
    "    \"p10hR1R2\",\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples_m),\n",
    "    ncols=2*len(distances),\n",
    "    figsize=(4*len(distances),2*len(sub_samples_m)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "for sample_m, sample_p, (i, _axs) in zip(sub_samples_m, sub_samples_p, enumerate(axs)):\n",
    "    for jj, (_dist_name, _dist) in enumerate(distances.items()):\n",
    "        axm, axp = _axs[jj], _axs[len(distances) + jj]\n",
    "        Cm = get_saddle_data(sample_m, _dist_name, _dist)\n",
    "        Cp = get_saddle_data(sample_p, _dist_name, _dist)\n",
    "        axm.imshow(Cm[1:-1,1:-1], **imshow_kwargs)\n",
    "        axp.imshow(Cp[1:-1,1:-1], **imshow_kwargs)\n",
    "\n",
    "# annotate labels and titles ...\n",
    "for jj, _dist_name in enumerate(distances):\n",
    "    # m ...\n",
    "    axs[0, jj].set_title(f\"m-{_dist_name}\")\n",
    "    # p ...\n",
    "    axs[0, len(distances) + jj].set_title(f\"p-{_dist_name}\")\n",
    "for ii, _sample in enumerate(sub_samples_m):\n",
    "    axs[ii,0].set_ylabel(_sample.lstrip(\"m\"))\n",
    "    axs[ii,0].set_yticks([])\n",
    "    axs[ii,0].set_xticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saddle_strength(k, sample, dist_name, dist_range=None):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    if dist_name == \"trans\":\n",
    "        S = np.nansum(interaction_sums_trans[sample], axis=0)\n",
    "        C = np.nansum(interaction_counts_trans[sample], axis=0)\n",
    "    else:\n",
    "        if dist_range is not None:\n",
    "            S = np.nansum(interaction_sums[sample][dist_range], axis=0)\n",
    "            C = np.nansum(interaction_counts[sample][dist_range], axis=0)\n",
    "        else:\n",
    "            S = np.nansum(interaction_sums[sample], axis=0)\n",
    "            C = np.nansum(interaction_counts[sample], axis=0)\n",
    "\n",
    "    # ...\n",
    "    S = S[1:-1,1:-1]\n",
    "    C = C[1:-1,1:-1]\n",
    "\n",
    "    m, n = S.shape\n",
    "    if m != n:\n",
    "        raise ValueError(\"`saddledata` should be square.\")\n",
    "\n",
    "    intra_BB = np.nansum(S[0:k, 0:k]) / np.nansum(C[0:k, 0:k])\n",
    "    intra_AA = np.nansum(S[n - k : n, n - k : n]) / np.nansum(C[n - k : n, n - k : n])\n",
    "    intra_all = (np.nansum(S[0:k, 0:k])+np.nansum(S[n - k : n, n - k : n])) \\\n",
    "                / (np.nansum(C[0:k, 0:k])+np.nansum(C[n - k : n, n - k : n]))\n",
    "\n",
    "    inter_sum = np.nansum(S[0:k, n - k : n]) + np.nansum(S[n - k : n, 0:k])\n",
    "    inter_count = np.nansum(C[0:k, n - k : n]) + np.nansum(C[n - k : n, 0:k])\n",
    "    inter = inter_sum / inter_count\n",
    "\n",
    "    # return pd.Series({\"AA\" : intra_AA, \"BB\" : intra_BB})\n",
    "    # return pd.Series({\"AA\" : intra_AA/inter, \"BB\" : intra_BB/inter,})\n",
    "    return pd.Series({\"AA\" : intra_AA/inter, \"BB\" : intra_BB/inter, \"AandB\": intra_all/inter})\n",
    "    # return pd.Series({\"all\": intra_all/inter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # introduce distance ranges\n",
    "# # # 0-1mb: 0:21 bins\n",
    "# # # 1-7Mb: 21:141 bins\n",
    "# # # 7-50Mb: 141:1001 bins\n",
    "# # # trans: : bins\n",
    "distances = {\n",
    "    \"all-cis\": slice(None),\n",
    "    \"trans\": slice(None),\n",
    "}\n",
    "# distances = {\n",
    "#     \"short:<3MB\": slice(0, int(3_000_000/binsize)+1),\n",
    "#     # \"mid:1MB-7Mb\": slice(int(1_000_000/binsize), int(7_000_000/binsize)+1),\n",
    "#     \"long3Mb-50Mb\": slice(int(3_000_000/binsize), int(50_000_000/binsize)+1),\n",
    "#     \"trans\": slice(None),\n",
    "# }\n",
    "\n",
    "_dfs_m = {}\n",
    "_dfs_p = {}\n",
    "for _dist in distances:\n",
    "    _dfs_m[_dist] = {}\n",
    "    _dfs_p[_dist] = {}\n",
    "\n",
    "for sample_m, sample_p in zip(sub_samples_m, sub_samples_p):\n",
    "    for _dist_name, _dist in distances.items():\n",
    "        _sm = saddle_strength(k=11, sample=sample_m, dist_name=_dist_name, dist_range=_dist)\n",
    "        _sp = saddle_strength(k=11, sample=sample_p, dist_name=_dist_name, dist_range=_dist)\n",
    "        #\n",
    "        _dfs_m[_dist_name][sample_m] = _sm\n",
    "        _dfs_p[_dist_name][sample_p] = _sp\n",
    "\n",
    "dfm = pd.concat([pd.DataFrame(_dfs_m[_dist]).T.add_suffix(f\"-{_dist}\") for _dist in distances], axis=1)\n",
    "dfm.index = [ii.lstrip(\"m\") for ii in dfm.index]\n",
    "dfm = dfm.add_prefix(\"ctrl::\")\n",
    "dfp = pd.concat([pd.DataFrame(_dfs_p[_dist]).T.add_suffix(f\"-{_dist}\") for _dist in distances], axis=1)\n",
    "dfp.index = [ii.lstrip(\"p\") for ii in dfp.index]\n",
    "dfp = dfp.add_prefix(\"delta::\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dfm, dfp], axis=1).to_csv(\"their_own_EV1_k11_comp_strength.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce \"fake\" time to convey the duration of the Cyto->G1 transition ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_time = [0,1,2,5,6]\n",
    "dfm[\"time\"] = _time\n",
    "dfp[\"time\"] = _time\n",
    "\n",
    "dfm = dfm.set_index(\"time\")\n",
    "dfp = dfp.set_index(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aabb_colors = [\"crimson\",\"royalblue\", \"slategrey\"]\n",
    "# aabb_colors = [\"slategrey\",\"royalblue\", \"green\"]\n",
    "\n",
    "for _sub in distances:\n",
    "    dfm.filter(like=_sub).plot(\n",
    "        color=aabb_colors,\n",
    "        markersize=8,\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    ax = plt.gca()\n",
    "    dfp.filter(like=_sub).plot(\n",
    "        ax=ax,\n",
    "        color=aabb_colors,\n",
    "        marker=\"x\",\n",
    "        markersize=9,\n",
    "        linestyle=\":\",\n",
    "    )\n",
    "    ax.set_ylim(1,2)\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xticks(_time)\n",
    "    ax.set_xticklabels([\"Mito\", \"Telo\", \"Cyto\", \"G1\", \"G1\"])\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_yticks([1,2,3,4,5,6])\n",
    "    ax.set_xlabel(\"cell cycle stage\")\n",
    "    # ax.set_yticks([1,2])\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.minorticks_off()\n",
    "    # ax.set_ylabel(\"intra_OE\")\n",
    "    ax.set_ylabel(\"comparment strength: intra_OE/inter_OE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # the mix one - mp\n",
    "sub_samples_m = [\n",
    "    \"N93m5\",\n",
    "    \"N93m10\",\n",
    "]\n",
    "# p ...\n",
    "sub_samples_p = [\n",
    "    \"N93p5\",\n",
    "    \"N93p10\",\n",
    "]\n",
    "\n",
    "\n",
    "# # introduce distance ranges\n",
    "# # 0-1mb: 0:21 bins\n",
    "# # 1-7Mb: 21:141 bins\n",
    "# # 7-50Mb: 141:1001 bins\n",
    "# # trans: : bins\n",
    "distances = {\n",
    "    \"short:<1MB\": slice(0, int(1_000_000/binsize)+1),\n",
    "    \"mid:1MB-7Mb\": slice(int(1_000_000/binsize), int(7_000_000/binsize)+1),\n",
    "    \"long7Mb-50Mb\": slice(int(7_000_000/binsize), int(50_000_000/binsize)+1),\n",
    "    \"trans\": slice(None),\n",
    "}\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples_m),\n",
    "    ncols=2*len(distances),\n",
    "    figsize=(4*len(distances),2*len(sub_samples_m)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "for sample_m, sample_p, (i, _axs) in zip(sub_samples_m, sub_samples_p, enumerate(axs)):\n",
    "    for jj, (_dist_name, _dist) in enumerate(distances.items()):\n",
    "        axm, axp = _axs[jj], _axs[len(distances) + jj]\n",
    "        Cm = get_saddle_data(sample_m, _dist_name, _dist)\n",
    "        Cp = get_saddle_data(sample_p, _dist_name, _dist)\n",
    "        axm.imshow(Cm[1:-1,1:-1], **imshow_kwargs)\n",
    "        axp.imshow(Cp[1:-1,1:-1], **imshow_kwargs)\n",
    "\n",
    "# annotate labels and titles ...\n",
    "for jj, _dist_name in enumerate(distances):\n",
    "    # m ...\n",
    "    axs[0, jj].set_title(f\"m-{_dist_name}\")\n",
    "    # p ...\n",
    "    axs[0, len(distances) + jj].set_title(f\"p-{_dist_name}\")\n",
    "for ii, _sample in enumerate(sub_samples_m):\n",
    "    axs[ii,0].set_ylabel(_sample.lstrip(\"m\"))\n",
    "    axs[ii,0].set_yticks([])\n",
    "    axs[ii,0].set_xticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples =[\n",
    "        \"m10hR1R2\",\n",
    "        \"p10hR1R2\",\n",
    "        \"mp10hR1R2\",\n",
    "    ]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples),\n",
    "    ncols=len(distances),\n",
    "    figsize=(2*len(distances),2*len(sub_samples)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "for ii, _sample in enumerate(sub_samples):\n",
    "    for jj, (_dist_name, _dist) in enumerate(distances.items()):\n",
    "        ax = axs[ii, jj]\n",
    "        saddle_data = get_saddle_data(_sample, _dist_name, _dist)\n",
    "        ax.imshow(saddle_data[1:,1:], **imshow_kwargs)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "# annotate labels and titles ...\n",
    "for jj, _dist_name in enumerate(distances):\n",
    "    axs[0,jj].set_title(f\"{_dist_name}\")\n",
    "for ii, _sample in enumerate(sub_samples):\n",
    "    axs[ii,0].set_ylabel(_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples = [\n",
    "        \"N93m10\",\n",
    "        \"N93p10\",\n",
    "        \"N93mp10\",\n",
    "    ]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples),\n",
    "    ncols=len(distances),\n",
    "    figsize=(2*len(distances),2*len(sub_samples)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "for ii, _sample in enumerate(sub_samples):\n",
    "    for jj, (_dist_name, _dist) in enumerate(distances.items()):\n",
    "        ax = axs[ii, jj]\n",
    "        saddle_data = get_saddle_data(_sample, _dist_name, _dist)\n",
    "        ax.imshow(saddle_data[1:,1:], **imshow_kwargs)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "# annotate labels and titles ...\n",
    "for jj, _dist_name in enumerate(distances):\n",
    "    axs[0,jj].set_title(f\"{_dist_name}\")\n",
    "for ii, _sample in enumerate(sub_samples):\n",
    "    axs[ii,0].set_ylabel(_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import bbi\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import ConnectionPatch, Rectangle\n",
    "from mpl_toolkits.axes_grid1 import Divider, Size\n",
    "from mpl_toolkits.axes_grid1.inset_locator import BboxConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telo_clrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q_LO = 0.025 # ignore 2.5% of genomic bins with the lowest E1 values\n",
    "Q_HI = 0.975 # ignore 2.5% of genomic bins with the highest E1 values\n",
    "N_GROUPS = 38 # divide remaining 95% of the genome into 38 equisized groups, 2.5% each\n",
    "n_bins = N_GROUPS\n",
    "\n",
    "sample_m, sample_p = 'N93m5', 'N93p5'\n",
    "\n",
    "track = align_track_with_cooler(\n",
    "    telo_cis_eigs_gene[sample_m][1][[\"chrom\",\"start\",\"end\",\"E1\"]],\n",
    "    telo_clrs[sample_m],\n",
    "    view_df=hg38_arms,\n",
    "    clr_weight_name=\"weight\",\n",
    "    mask_clr_bad_bins=True,\n",
    "    drop_track_na=False,  # this adds check for chromosomes that have all missing values\n",
    ")\n",
    "digitized_track, binedges = digitize(\n",
    "    track.iloc[:, :4],\n",
    "    n_bins,\n",
    "    # vrange=vrange,\n",
    "    qrange=qrange,\n",
    "    digitized_suffix=\".d\",\n",
    ")\n",
    "digitized_track[\"value\"] = track[\"value\"]\n",
    "xxxm = digitized_track.groupby(\"value.d\")[\"value\"].mean()\n",
    "\n",
    "track = align_track_with_cooler(\n",
    "    telo_cis_eigs_gene[sample_p][1][[\"chrom\",\"start\",\"end\",\"E1\"]],\n",
    "    telo_clrs[sample_p],\n",
    "    view_df=hg38_arms,\n",
    "    clr_weight_name=\"weight\",\n",
    "    mask_clr_bad_bins=True,\n",
    "    drop_track_na=False,  # this adds check for chromosomes that have all missing values\n",
    ")\n",
    "digitized_track, binedges = digitize(\n",
    "    track.iloc[:, :4],\n",
    "    n_bins,\n",
    "    # vrange=vrange,\n",
    "    qrange=qrange,\n",
    "    digitized_suffix=\".d\",\n",
    ")\n",
    "digitized_track[\"value\"] = track[\"value\"]\n",
    "xxxp = digitized_track.groupby(\"value.d\")[\"value\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 6, 2.8\n",
    "margin = 0.2\n",
    "matw = 1.15\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize=(w, h),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = [\n",
    "    Size.Fixed(margin), Size.Fixed(matw),\n",
    "    Size.Fixed(margin), Size.Fixed(matw),\n",
    "    # Size.Fixed(margin), Size.Fixed(matw),\n",
    "    # Size.Fixed(margin), Size.Fixed(matw),\n",
    "]\n",
    "# goes from bottom to the top ...\n",
    "v = [\n",
    "    Size.Fixed(0.1), Size.Fixed(matw),\n",
    "    Size.Fixed(0.1), Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin), Size.Fixed(matw*0.2),\n",
    "    Size.Fixed(0.2*margin), Size.Fixed(matw),\n",
    "]\n",
    "\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "axs = {}\n",
    "axs[\"cis_ctrl\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=3))\n",
    "axs[\"trans_ctrl\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=1))\n",
    "axs[\"cis_ctrl_ev\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=5))\n",
    "\n",
    "axs[\"cis_delta\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=3))\n",
    "axs[\"trans_delta\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=1))\n",
    "axs[\"cis_delta_ev\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=5))\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "for k, ax in axs.items():\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "\n",
    "_dist_name = \"all_cis\"\n",
    "Cm = get_saddle_data(sample_m, _dist_name, None)\n",
    "Cp = get_saddle_data(sample_p,  _dist_name, None)\n",
    "axs[\"cis_ctrl\"].imshow(Cm[1:-1,1:-1], **imshow_kwargs)\n",
    "axs[\"cis_delta\"].imshow(Cp[1:-1,1:-1], **imshow_kwargs)\n",
    "\n",
    "_dist_name = \"trans\"\n",
    "Cm = get_saddle_data(sample_m, _dist_name, None)\n",
    "Cp = get_saddle_data(sample_p,  _dist_name, None)\n",
    "axs[\"trans_ctrl\"].imshow(Cm[1:-1,1:-1], **imshow_kwargs)\n",
    "axs[\"trans_delta\"].imshow(Cp[1:-1,1:-1], **imshow_kwargs)\n",
    "\n",
    "# # annotate labels and titles ...\n",
    "# for jj, _dist_name in enumerate(distances):\n",
    "#     # m ...\n",
    "#     axs[0, jj].set_title(f\"m-{_dist_name}\")\n",
    "#     # p ...\n",
    "#     axs[0, len(distances) + jj].set_title(f\"p-{_dist_name}\")\n",
    "# for ii, _sample in enumerate(sub_samples_m):\n",
    "#     axs[ii,0].set_ylabel(_sample.lstrip(\"m\"))\n",
    "#     axs[ii,0].set_yticks([])\n",
    "#     axs[ii,0].set_xticks([])\n",
    "\n",
    "data = xxxm.loc[1:38]\n",
    "axs[\"cis_ctrl_ev\"].fill_between(data.index, data, 0, color=\"darkgoldenrod\", ec=\"darkgoldenrod\",step=\"mid\")\n",
    "axs[\"cis_ctrl_ev\"].set_ylim(-1.2,1.2)\n",
    "axs[\"cis_ctrl_ev\"].set_xlim(1,38.1)\n",
    "axs[\"cis_ctrl_ev\"].spines[:].set_visible(False)\n",
    "axs[\"cis_ctrl_ev\"].axhline(0,color=\"black\",lw=0.5)\n",
    "axs[\"cis_ctrl_ev\"].spines[\"right\"].set_visible(True)\n",
    "axs[\"cis_ctrl_ev\"].spines[\"left\"].set_visible(True)\n",
    "# ax.tick_params(bottom=False,left=True,labelbottom=False)\n",
    "# # ax.set_frame_on(False)\n",
    "# # plt.axis(\"off\")\n",
    "# ax.grid(color=\"black\",lw=0.5)\n",
    "\n",
    "\n",
    "data = xxxp.loc[1:38]\n",
    "axs[\"cis_delta_ev\"].fill_between(data.index, data, 0, color=\"goldenrod\", ec=\"goldenrod\",step=\"mid\")\n",
    "axs[\"cis_delta_ev\"].set_ylim(-1.2,1.2)\n",
    "axs[\"cis_delta_ev\"].set_xlim(1,38.1)\n",
    "axs[\"cis_delta_ev\"].spines[:].set_visible(False)\n",
    "axs[\"cis_delta_ev\"].axhline(0,color=\"black\",lw=0.5)\n",
    "axs[\"cis_delta_ev\"].spines[\"right\"].set_visible(True)\n",
    "axs[\"cis_delta_ev\"].spines[\"left\"].set_visible(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_LO = 0.025 # ignore 2.5% of genomic bins with the lowest E1 values\n",
    "Q_HI = 0.975 # ignore 2.5% of genomic bins with the highest E1 values\n",
    "N_GROUPS = 38 # divide remaining 95% of the genome into 38 equisized groups, 2.5% each\n",
    "n_bins = N_GROUPS\n",
    "# vrange = (-2.5,2.5)\n",
    "# qrange=(Q_LO,Q_HI)\n",
    "\n",
    "sample_m, sample_p = \"m5hR1R2\", \"p5hR1R2\"\n",
    "\n",
    "\n",
    "track = align_track_with_cooler(\n",
    "    telo_cis_eigs_gene[sample_m][1][[\"chrom\",\"start\",\"end\",\"E1\"]],\n",
    "    telo_clrs[sample_m],\n",
    "    view_df=hg38_arms,\n",
    "    clr_weight_name=\"weight\",\n",
    "    mask_clr_bad_bins=True,\n",
    "    drop_track_na=False,  # this adds check for chromosomes that have all missing values\n",
    ")\n",
    "digitized_track, binedges = digitize(\n",
    "    track.iloc[:, :4],\n",
    "    n_bins,\n",
    "    # vrange=vrange,\n",
    "    qrange=qrange,\n",
    "    digitized_suffix=\".d\",\n",
    ")\n",
    "digitized_track[\"value\"] = track[\"value\"]\n",
    "xxxm = digitized_track.groupby(\"value.d\")[\"value\"].mean()\n",
    "\n",
    "track = align_track_with_cooler(\n",
    "    telo_cis_eigs_gene[sample_p][1][[\"chrom\",\"start\",\"end\",\"E1\"]],\n",
    "    telo_clrs[sample_p],\n",
    "    view_df=hg38_arms,\n",
    "    clr_weight_name=\"weight\",\n",
    "    mask_clr_bad_bins=True,\n",
    "    drop_track_na=False,  # this adds check for chromosomes that have all missing values\n",
    ")\n",
    "digitized_track, binedges = digitize(\n",
    "    track.iloc[:, :4],\n",
    "    n_bins,\n",
    "    # vrange=vrange,\n",
    "    qrange=qrange,\n",
    "    digitized_suffix=\".d\",\n",
    ")\n",
    "digitized_track[\"value\"] = track[\"value\"]\n",
    "xxxp = digitized_track.groupby(\"value.d\")[\"value\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w, h = 6, 2.8\n",
    "margin = 0.2\n",
    "matw = 1.15\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize=(w, h),\n",
    ")\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = [\n",
    "    Size.Fixed(margin), Size.Fixed(matw),\n",
    "    Size.Fixed(margin), Size.Fixed(matw),\n",
    "]\n",
    "# goes from bottom to the top ...\n",
    "v = [\n",
    "    Size.Fixed(0.1), Size.Fixed(matw),\n",
    "    Size.Fixed(0.1), Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin), Size.Fixed(matw*0.2),\n",
    "    Size.Fixed(0.2*margin), Size.Fixed(matw),\n",
    "]\n",
    "\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "axs = {}\n",
    "axs[\"cis_ctrl\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=3))\n",
    "axs[\"trans_ctrl\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=1))\n",
    "axs[\"cis_ctrl_ev\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=5))\n",
    "\n",
    "axs[\"cis_delta\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=3))\n",
    "axs[\"trans_delta\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=1))\n",
    "axs[\"cis_delta_ev\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=5))\n",
    "\n",
    "########################################\n",
    "for k, ax in axs.items():\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "\n",
    "_dist_name = \"all_cis\"\n",
    "Cm = get_saddle_data(sample_m, _dist_name, None)\n",
    "Cp = get_saddle_data(sample_p,  _dist_name, None)\n",
    "axs[\"cis_ctrl\"].imshow(Cm[1:-1,1:-1], **imshow_kwargs)\n",
    "axs[\"cis_delta\"].imshow(Cp[1:-1,1:-1], **imshow_kwargs)\n",
    "\n",
    "_dist_name = \"trans\"\n",
    "Cm = get_saddle_data(sample_m, _dist_name, None)\n",
    "Cp = get_saddle_data(sample_p,  _dist_name, None)\n",
    "axs[\"trans_ctrl\"].imshow(Cm[1:-1,1:-1], **imshow_kwargs)\n",
    "axs[\"trans_delta\"].imshow(Cp[1:-1,1:-1], **imshow_kwargs)\n",
    "\n",
    "\n",
    "data = xxxm.loc[1:38]\n",
    "axs[\"cis_ctrl_ev\"].fill_between(data.index, data, 0, color=\"darkgoldenrod\", ec=\"darkgoldenrod\",step=\"mid\")\n",
    "axs[\"cis_ctrl_ev\"].set_ylim(-1.2,1.2)\n",
    "axs[\"cis_ctrl_ev\"].set_xlim(1,38.1)\n",
    "axs[\"cis_ctrl_ev\"].spines[:].set_visible(False)\n",
    "axs[\"cis_ctrl_ev\"].axhline(0,color=\"black\",lw=0.5)\n",
    "axs[\"cis_ctrl_ev\"].spines[\"right\"].set_visible(True)\n",
    "axs[\"cis_ctrl_ev\"].spines[\"left\"].set_visible(True)\n",
    "\n",
    "\n",
    "data = xxxp.loc[1:38]\n",
    "axs[\"cis_delta_ev\"].fill_between(data.index, data, 0, color=\"goldenrod\", ec=\"goldenrod\",step=\"mid\")\n",
    "axs[\"cis_delta_ev\"].set_ylim(-1.2,1.2)\n",
    "axs[\"cis_delta_ev\"].set_xlim(1,38.1)\n",
    "axs[\"cis_delta_ev\"].spines[:].set_visible(False)\n",
    "axs[\"cis_delta_ev\"].axhline(0,color=\"black\",lw=0.5)\n",
    "axs[\"cis_delta_ev\"].spines[\"right\"].set_visible(True)\n",
    "axs[\"cis_delta_ev\"].spines[\"left\"].set_visible(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebe.vmin, bebe.vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import PowerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.colorbar??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.get_cmap(imshow_kwargs[\"cmap\"])#(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure(figsize=(0.5,2))\n",
    "cax = f.add_subplot()\n",
    "\n",
    "\n",
    "plt.colorbar(\n",
    "    cm.ScalarMappable(norm=PowerNorm(1/3., vmin=imshow_kwargs[\"norm\"].vmin, vmax=imshow_kwargs[\"norm\"].vmax), cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cax,\n",
    ")\n",
    "# f.colorbar(\n",
    "#     cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "#     cax=cax,\n",
    "# )\n",
    "# # cax.set_yticks([imshow_kwargs[\"norm\"].vmin, imshow_kwargs[\"norm\"].midpoint, imshow_kwargs[\"norm\"].vmax])\n",
    "# # cax.set_yticklabels([imshow_kwargs[\"norm\"].vmin, imshow_kwargs[\"norm\"].midpoint, imshow_kwargs[\"norm\"].vmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_kwargs[\"norm\"](1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/48625475/python-shifted-logarithmic-colorbar-white-color-offset-to-center\n",
    "class MidPointLogNorm(LogNorm):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        LogNorm.__init__(self,vmin=vmin, vmax=vmax, clip=clip)\n",
    "        self.midpoint=midpoint\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        vmin, midpoint, vmax = self.vmin, self.midpoint, self.vmax\n",
    "        x, y = [np.log(vmin), np.log(midpoint), np.log(vmax)], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(np.log(value), x, y))\n",
    "\n",
    "    def inverse(self, value):\n",
    "        if not self.scaled():\n",
    "            raise ValueError(\"Not invertible until scaled\")\n",
    "        # t_vmin, t_midpoint, t_vmax = np.log(self.vmin), np.log(self.midpoint), np.log(self.vmax)\n",
    "        vmin, midpoint, vmax = self.vmin, self.midpoint, self.vmax\n",
    "\n",
    "        x, y = [0, 0.5, 1], [np.log(vmin), np.log(midpoint), np.log(vmax)]\n",
    "        # # return np.ma.masked_array(np.interp(np.log(value), x, y))\n",
    "        # if np.iterable(value):\n",
    "        #     val = np.ma.asarray(value)\n",
    "        #     return np.ma.power(val, 1. / gamma) * (vmax - vmin) + vmin\n",
    "        # else:\n",
    "        # return pow(value, 1. / gamma) * (vmax - vmin) + vmin\n",
    "        return np.exp(np.interp(value, x, y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vmin, midpoint, vmax = 0.2,1,3\n",
    "x,y = [np.log(vmin), np.log(midpoint), np.log(vmax)], [0, 0.5, 1]\n",
    "np.interp(np.log(0.2), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vmin, midpoint, vmax = 0.2,1,3\n",
    "x,y = [np.log(vmin), np.log(midpoint), np.log(vmax)], [0, 0.5, 1]\n",
    "np.interp(np.log(0.2), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure(figsize=(0.5,2))\n",
    "cax = f.add_subplot()\n",
    "\n",
    "\n",
    "# plt.colorbar(\n",
    "#     cm.ScalarMappable(norm=PowerNorm(1/3., vmin=imshow_kwargs[\"norm\"].vmin, vmax=imshow_kwargs[\"norm\"].vmax), cmap=imshow_kwargs[\"cmap\"]),\n",
    "#     cax=cax,\n",
    "# )\n",
    "\n",
    "\n",
    "_ppp = MidPointLogNorm(vmin=1/5,vmax=3,midpoint=1)\n",
    "f.colorbar(\n",
    "    cm.ScalarMappable(norm=_ppp, cmap=\"RdBu_r\"),\n",
    "    cax=cax,\n",
    ")\n",
    "cax.set_yticks([imshow_kwargs[\"norm\"].vmin, imshow_kwargs[\"norm\"].midpoint, imshow_kwargs[\"norm\"].vmax])\n",
    "cax.set_yticklabels([imshow_kwargs[\"norm\"].vmin, imshow_kwargs[\"norm\"].midpoint, imshow_kwargs[\"norm\"].vmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_kwargs[\"norm\"].vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_kwargs[\"norm\"].cen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
