{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291b0f37-61ed-46f8-bc8d-55c5eea8b2da",
   "metadata": {},
   "source": [
    "## This is just a pileup plotting notebook that relies on a pre-calculated results stored in an HDF5 file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adeb24e-aa19-490c-bfc3-16b011e36a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Hi-C utilities imports:\n",
    "import cooler\n",
    "import bioframe\n",
    "import cooltools\n",
    "# Visualization imports:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import EngFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb4552-d8be-4c72-b14e-c95bb44b12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbi for stackups ...\n",
    "import bbi\n",
    "# functions and assets specific to this repo/project ...\n",
    "from data_catalog import bws, bws_vlim, telo_dict\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "# import mpire for nested multi-processing\n",
    "\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import ConnectionPatch, Rectangle\n",
    "from mpl_toolkits.axes_grid1 import Divider, Size\n",
    "from mpl_toolkits.axes_grid1.inset_locator import BboxConnector\n",
    "from matplotlib import cm\n",
    "# from mpl_toolkits.axes_grid1.Size import Fixed\n",
    "\n",
    "\n",
    "# enable editable text ...\n",
    "mpl.rcParams[\"pdf.fonttype\"]=42\n",
    "mpl.rcParams[\"svg.fonttype\"]=\"none\"\n",
    "mpl.rcParams['axes.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e88790-01dc-4356-bc22-2e45ef0ce8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mb(bp_val):\n",
    "    # check MB\n",
    "    if np.mod(bp_val, 1_000_000):\n",
    "        # just give 1 decimal if not even Mb\n",
    "        return f\"{bp_val/1_000_000:.1f}\"\n",
    "    else:\n",
    "        return f\"{bp_val//1_000_000}\"\n",
    "\n",
    "# given the range - generate pretty axis name\n",
    "def _get_name(_left, _right, _amount):\n",
    "    if np.isclose(_left, 0.0):\n",
    "        return f\"<{to_mb(_right)} Mb: {_amount}\"\n",
    "    elif _right > 80_000_000:\n",
    "        return f\">{to_mb(_left)} Mb: {_amount}\"\n",
    "    else:\n",
    "        return f\"{to_mb(_left)}-{to_mb(_right)} Mb: {_amount}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef645cb-8dec-414b-87cc-32a4cbd2981d",
   "metadata": {},
   "source": [
    "### Chrom arms as a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5689161-6ec4-4d74-911d-70479f0d1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bioframe to fetch the genomic features from the UCSC.\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "hg38_arms_full = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "# # remove \"bad\" chromosomes and near-empty arms ...\n",
    "# excluded_arms = [\"chr13_p\", \"chr14_p\", \"chr15_p\", \"chr21_p\", \"chr22_p\", \"chrM_p\", \"chrY_p\", \"chrY_q\", \"chrX_p\", \"chrX_q\"]\n",
    "# hg38_arms = hg38_arms_full[~hg38_arms_full[\"name\"].isin(excluded_arms)].reset_index(drop=True)\n",
    "\n",
    "# can do 1 chromosome (or arm) as well ..\n",
    "included_arms = [\"chr1_q\", \"chr2_p\", \"chr4_q\", \"chr6_q\"]\n",
    "included_arms = hg38_arms_full[\"name\"].to_list()[:44] # all autosomal ones ...\n",
    "hg38_arms = hg38_arms_full[hg38_arms_full[\"name\"].isin(included_arms)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76e50c-9801-4dee-b60e-9cb961cb4996",
   "metadata": {},
   "source": [
    "# There is a problem with our arms view of the chromosomes ...\n",
    "\n",
    "the way we do it now - end of p-arm is alsways equal to the start of q-arm ...\n",
    "\n",
    "After binning this could lead to the situation where last bin of p-arm is upstream of the first q-arm bin ...\n",
    "\n",
    "This makes `cooltools.api.is_valid_expected` crash ...\n",
    "\n",
    "Let's try solving that by adding 1 bp to the start of every q-arm ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c091e-9efa-43fd-804b-bd902ce155c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_arm_view(\n",
    "    view_df,\n",
    "    binsize,\n",
    "):\n",
    "    \"\"\"\n",
    "    adjust arm-based view of the genome to fix slightly overlapping p and q arms ...\n",
    "    \"\"\"\n",
    "    _iter_view = view_df.itertuples(index=False)\n",
    "    return pd.DataFrame(\n",
    "        [(c,s+binsize,e,n) if (\"q\" in n) else (c,s,e,n) for c,s,e,n in _iter_view],\n",
    "        columns=hg38_arms.columns\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4ef7a-e9fd-4523-a312-ce7a4699c10c",
   "metadata": {},
   "source": [
    "### Read pre-called native compartments\n",
    "## ... and Pick one list of anchors and annotate it with epigenetic marks ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bfd74-7d0f-483b-9061-9d061e14c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_anchor_fnames = {\n",
    "    \"mega_2X_enrichment\": \"ID_anchors/mega_2X_enrichment.fourth_mega.max_size.bed\",\n",
    "    \"5hr_2X_enrichment_old\": \"ID_anchors/5hr_2X_enrichment.second_bulk.max_size.bed\",\n",
    "    \"5hr_2X_enrichment\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.bed\",\n",
    "    \"5hr_2X_enrichment_nosing\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.no_singletons.bed\",\n",
    "    \"5hr_notinCyto_2X_enrichment_signal\": \"ID_anchors/p5notin_pCyto_anchors_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"5hr_2X_enrichment_signal\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"10hr_2X_enrichment_signal\": \"ID_anchors/10hrs_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"N93p5_2X_enrichment_signal\": \"ID_anchors/N93p5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"pCyto_2X_enrichment_signal\": \"ID_anchors/pCyto_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"mCyto_2X_enrichment_signal\": \"ID_anchors/mCyto_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"mega_3X_enrichment\": \"ID_anchors/mega_3X_enrichment.fifth_mega3x.max_size.bed\",\n",
    "    \"MEGA_2X_enrichment\": \"ID_anchors/MEGAp5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGA_weaker_2X_enrichment\": \"ID_anchors/MEGA_plus_weak_anchors_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGAN93_2X_enrichment\": \"ID_anchors/MEGAN93p5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGAminus_2X_enrichment\": \"ID_anchors/MEGA_minus_ctrl_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"cyto_2x_enrichment\": \"ID_anchors/cyto_2x_enrichment.third_mCyto.max_size.bed\",\n",
    "}\n",
    "\n",
    "id_anchors_dict = {}\n",
    "for id_name, fname in id_anchor_fnames.items():\n",
    "    id_anchors_dict[id_name] = pd.read_csv(fname, sep=\"\\t\")\n",
    "    # ...\n",
    "    print(f\"loaded {len(id_anchors_dict[id_name]):5d} ID anchors {id_name:>20} in BED format ...\")\n",
    "\n",
    "\n",
    "_anchors = id_anchors_dict[\"5hr_2X_enrichment_signal\"]\n",
    "_anchorsG1 = id_anchors_dict[\"5hr_2X_enrichment_signal\"]\n",
    "_anchorsCyto = id_anchors_dict[\"pCyto_2X_enrichment_signal\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285102f-660a-406a-8735-c52cde201d7d",
   "metadata": {},
   "source": [
    "## Annotate da heck out of those anchors for pileup subgrouping ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19169a-7be3-4e66-a3e0-697966fcc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if anchors overlap other anchors ....\n",
    "# _g1_index = bioframe.overlap(\n",
    "#     _anchors,\n",
    "#     _anchorsG1.eval(\n",
    "#         \"\"\"\n",
    "#         peak_start = peak_start - 15_000\n",
    "#         peak_end = peak_end + 15_000\n",
    "#         \"\"\"\n",
    "#     ),\n",
    "#     return_input=False,\n",
    "#     return_index=True,\n",
    "#     return_overlap=False,\n",
    "#     suffixes=('', '_'),\n",
    "#     keep_order=True,\n",
    "#     cols1=(\"chrom\",\"peak_start\",\"peak_end\"),\n",
    "#     cols2=(\"chrom\",\"peak_start\",\"peak_end\"),\n",
    "# ).dropna()[\"index\"].unique()\n",
    "\n",
    "# # annotate G1 status of some of the pCyto anchors ...\n",
    "# _anchors[\"G1status\"] = False\n",
    "# _anchors.loc[_g1_index, \"G1status\"] = True\n",
    "\n",
    "\n",
    "# check if anchors overlap other anchors ....\n",
    "_cyto_index = bioframe.overlap(\n",
    "    _anchors,\n",
    "    _anchorsCyto.eval(\n",
    "        \"\"\"\n",
    "        peak_start = peak_start - 15_000\n",
    "        peak_end = peak_end + 15_000\n",
    "        \"\"\"\n",
    "    ),\n",
    "    return_input=False,\n",
    "    return_index=True,\n",
    "    return_overlap=False,\n",
    "    suffixes=('', '_'),\n",
    "    keep_order=True,\n",
    "    cols1=(\"chrom\",\"peak_start\",\"peak_end\"),\n",
    "    cols2=(\"chrom\",\"peak_start\",\"peak_end\"),\n",
    ").dropna()[\"index\"].unique()\n",
    "\n",
    "# annotate G1 status of some of the pCyto anchors ...\n",
    "_anchors[\"Cytostatus\"] = False\n",
    "_anchors.loc[_cyto_index, \"Cytostatus\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa667f52-bb1e-4be8-8c32-ebdcd5b940a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _anchors.query(\"~Cytostatus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a32922-2c03-4848-a3cb-0a65f1781957",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_kyes_to_use = [\n",
    "    'mG.atac',\n",
    "    'H3K27me3',\n",
    "    'H3K4me3',\n",
    "    'H3K27ac',\n",
    "    'ctcf',\n",
    "    'dots',\n",
    "]\n",
    "\n",
    "bws[\"dots\"] = \"mega_dots_anchors.bb\"\n",
    "\n",
    "for k, bw in bws.items():\n",
    "    if k in bw_kyes_to_use:\n",
    "        # left anchor annotation ...\n",
    "        print(f\"working on {k} ...\")\n",
    "        _anchors[f\"{k}\"] = bbi.stackup(\n",
    "                bw,\n",
    "                _anchors[\"chrom\"],\n",
    "                _anchors[\"start\"],\n",
    "                _anchors[\"end\"],\n",
    "                bins=1,\n",
    "            ).flatten()\n",
    "\n",
    "\n",
    "# ...\n",
    "_anchors[f\"{k}_footprint\"] = bbi.stackup(\n",
    "    bw,\n",
    "    _anchors[\"chrom\"],\n",
    "    _anchors[\"peak_start\"],\n",
    "    _anchors[\"peak_end\"],\n",
    "    bins=1,\n",
    ").flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b42d0f-e98e-4a4b-bda7-c2558eaea772",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    [\n",
    "        _anchors.query(\"dots_footprint == 0\")[\"size\"],\n",
    "        _anchors.query(\"dots_footprint > 0\")[\"size\"],\n",
    "    ],\n",
    "    bins=np.linspace(20_000,250_000, 50),\n",
    "    stacked=True,\n",
    "    label=[\"dots_footprint == 0\",\"dots_footprint > 0\"]\n",
    "    # color = ['r','g']\n",
    ")\n",
    "plt.legend()\n",
    "plt.gca().set_xlabel(\"ID anchor footprint\")\n",
    "plt.gca().set_title(\"ID set: 5hr_2X_enrichment_signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99425cbb-17f2-4682-9662-a0457d54addc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T17:32:04.095571Z",
     "iopub.status.busy": "2023-12-18T17:32:04.094655Z",
     "iopub.status.idle": "2023-12-18T17:32:04.394455Z",
     "shell.execute_reply": "2023-12-18T17:32:04.393244Z",
     "shell.execute_reply.started": "2023-12-18T17:32:04.095511Z"
    }
   },
   "source": [
    "## Pre-define coolers that drive all of that - just in case ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f22c8a0-591b-402e-9bd2-15c4d230d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cooler files that we'll work on :\n",
    "binsize10 = 10_000\n",
    "telo_clrs10 = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize10}\") for _k, _path in telo_dict.items() }\n",
    "\n",
    "# cooler files that we'll work on :\n",
    "binsize25 = 25_000\n",
    "telo_clrs25 = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize25}\") for _k, _path in telo_dict.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c7af0-786a-4421-bc81-f3057c018b79",
   "metadata": {},
   "source": [
    "## Now let's load HDF5 file with all of the pileups and anchor indices for the all-by-all dataframes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ae8b8-ff55-4969-838f-13c407bc27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba40bf5-e637-4164-a851-1430b0c71a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls /data/sergpolly/tmp/Pileups_ID*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed4f92-002f-40c5-8c9a-5f6aede0af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fr.items()\n",
    "def print_attrs(name, obj):\n",
    "    # Create indent\n",
    "    shift = name.count('/') * '    '\n",
    "    item_name = name.split(\"/\")[-1]\n",
    "    print(shift + item_name)\n",
    "    try:\n",
    "        for key, val in obj.attrs.items():\n",
    "            print(shift + '    ' + f\"{key}: {val}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "with h5py.File(\"/data/sergpolly/tmp/Pileups_ID_by_distance.hdf5\", 'r') as fr:\n",
    "# with h5py.File(\"/data/sergpolly/tmp/Pileups_ID_by_distance_pCyto.hdf5\", 'r') as fr:\n",
    "    fr.visititems(print_attrs)\n",
    "\n",
    "    # check general metadata ...\n",
    "    _pileup_meta = dict(fr.attrs)\n",
    "    for k,v in _pileup_meta.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"...\")\n",
    "    print(\"restoring cis all-by-all table ...\")\n",
    "    # extract indices to recreate all-by-all in cis:\n",
    "    cis_left = fr.get(\"cis/indices\").get(\"anchor1\")[()]\n",
    "    cis_right = fr.get(\"cis/indices\").get(\"anchor2\")[()]\n",
    "    # assuming index and cluster - are the same ...\n",
    "    _df_intra_arm = pd.concat(\n",
    "        [\n",
    "            _anchors.iloc[cis_left].add_suffix(\"1\").reset_index(drop=True),\n",
    "            _anchors.iloc[cis_right].add_suffix(\"2\").reset_index(drop=True)\n",
    "        ],\n",
    "        axis=1\n",
    "     )\n",
    "    _df_intra_arm = _df_intra_arm.reset_index(drop=True)\n",
    "    _df_intra_arm[\"dist\"] = _df_intra_arm.eval(\".5*(start2+end2) - .5*(start1+end1)\")\n",
    "\n",
    "    print(\"restoring trans all-by-all table ...\")\n",
    "    # extract indices to recreate all-by-all in trans:\n",
    "    trans_left = fr.get(\"trans/indices\").get(\"anchor1\")[()]\n",
    "    trans_right = fr.get(\"trans/indices\").get(\"anchor2\")[()]\n",
    "    # assuming index and cluster - are the same ...\n",
    "    tr_feat = pd.concat(\n",
    "        [\n",
    "            _anchors.iloc[trans_left].add_suffix(\"1\").reset_index(drop=True),\n",
    "            _anchors.iloc[trans_right].add_suffix(\"2\").reset_index(drop=True)\n",
    "        ],\n",
    "        axis=1\n",
    "     )\n",
    "    tr_feat = tr_feat.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"extracting cis pileups as is...\")\n",
    "    # sort out the results per sample ...\n",
    "    fullstacks_cis = {}\n",
    "    cis_pileups_grp = fr.get(\"cis/pileups\")\n",
    "    for _sample in cis_pileups_grp.keys():\n",
    "        fullstacks_cis[_sample] = cis_pileups_grp.get(_sample)[()]\n",
    "\n",
    "\n",
    "    print(\"extracting trans pileups and calculating means ...\")\n",
    "    # # create indexes for pileup groups\n",
    "    _dotless_idx = tr_feat.query(\"(~Cytostatus1) & (~Cytostatus2)\").index\n",
    "    _dotted_idx = tr_feat.query(\"Cytostatus1 & Cytostatus2\").index\n",
    "    # _dotless_idx = tr_feat.query(\"(~G1status1) & (~G1status2)\").index\n",
    "    # _dotted_idx = tr_feat.query(\"G1status1 & G1status2\").index\n",
    "    # _dotless_idx = tr_feat.query(\"(dots_footprint1==0)&(dots_footprint2==0)\").index\n",
    "    # _dotted_idx = tr_feat.query(\"(dots_footprint1>0)&(dots_footprint2>0)\").index\n",
    "    len(tr_feat), len(_dotless_idx), len(_dotted_idx)\n",
    "\n",
    "    # now average those sub-pileups :\n",
    "    stack_means = {}\n",
    "    trans_pileups_grp = fr.get(\"trans/pileups\")\n",
    "    for _sample in trans_pileups_grp.keys():\n",
    "        print(f\"    processing trans pileup {_sample} ...\")\n",
    "        #\n",
    "        _stack = trans_pileups_grp.get(_sample)[()]\n",
    "        stack_means[_sample] = [\n",
    "            np.nanmean(_stack[_dotless_idx], axis=0),\n",
    "            np.nanmean(_stack[_dotted_idx], axis=0),\n",
    "            np.nanmean(_stack, axis=0),\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb90c51-1fc8-4b28-bd45-6249f6c776c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed07a4e2-560a-4a32-930d-53a35625da74",
   "metadata": {},
   "source": [
    "# plotting pups ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b559b6-bdf1-493a-86f7-32c0246f6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pileup select samples only !\n",
    "_select_sample_groups = [\n",
    "    [\"mMito\",\"mTelo\",\"mCyto\",\"m5hR1R2\",\"m10hR1R2\"],\n",
    "    # # p-ones\n",
    "    [\"pMito\",\"pTelo\",\"pCyto\",\"p5hR1R2\",\"p10hR1R2\"],\n",
    "    # # # # the mix one - mp\n",
    "    [\"N93m5\",\"N93m10\"],\n",
    "    # p ...\n",
    "    [\"N93p5\",\"N93p10\"],\n",
    "    [\"m10hR1R2\",\"p10hR1R2\",\"mp10hR1R2\"],\n",
    "    [\"N93m10\",\"N93p10\",\"N93mp10\"],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c46eae-9db2-463b-84de-908349fb410f",
   "metadata": {},
   "source": [
    "# Full figure 3D ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75a91d-8485-40d9-b125-ec10d1281f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2\n",
    "tcourse_spacing = 0.1\n",
    "matw = 0.35\n",
    "cbarh = 0.07\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"nearest\",\n",
    ")\n",
    "\n",
    "# timecourse_samples = [\"Mito\", \"Telo\", \"Cyto\", \"5hR1R2\", \"10hR1R2\"]\n",
    "timecourse_samples = [\"Mito\", \"Telo\", \"Cyto\", \"5hR1R2\"]\n",
    "_nsamples = len(timecourse_samples)\n",
    "\n",
    "_flank = 100_000\n",
    "_dfff = _df_intra_arm\n",
    "# _cis_subidx = _dfff.query(\"(dots_footprint1==0)&(dots_footprint2==0)\").index\n",
    "# _cis_subidx = _dfff.query(\"(dots_footprint1>0)&(dots_footprint2>0)\").index\n",
    "# _cis_G1idx = _dfff.query(\"G1status1 & G1status2\").index\n",
    "_cis_G1idx = _dfff.query(\"~Cytostatus1 & ~Cytostatus2\").index\n",
    "_cis_Cytoidx = _dfff.query(\"Cytostatus1 & Cytostatus2\").index\n",
    "# _cis_subidx = _dfff.index\n",
    "_trans_G1idx = 0\n",
    "_trans_Cytoidx = 1\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = [ Size.Fixed(margin) ] + \\\n",
    "    (_nsamples-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(tcourse_spacing) ] + \\\n",
    "    (_nsamples-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(margin) ]\n",
    "# goes from bottom to the top ...\n",
    "v = [ Size.Fixed(margin), Size.Fixed(cbarh), Size.Fixed(0.5*margin),\n",
    "     Size.Fixed(matw), Size.Fixed(0.25*margin), Size.Fixed(matw), Size.Fixed(1.5*margin),\n",
    "     Size.Fixed(matw), Size.Fixed(0.25*margin), Size.Fixed(matw), Size.Fixed(margin)]\n",
    "\n",
    "\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "axs_g1_m = {}\n",
    "axs_g1_p = {}\n",
    "axs_g1_trans_m = {}\n",
    "axs_g1_trans_p = {}\n",
    "\n",
    "axs_cyto_m = {}\n",
    "axs_cyto_p = {}\n",
    "axs_cyto_trans_m = {}\n",
    "axs_cyto_trans_p = {}\n",
    "\n",
    "for i, _sample in enumerate(timecourse_samples):\n",
    "    # G1-specific ...\n",
    "    # mind the gaps/marging between actual plots ...\n",
    "    axs_g1_p[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*(i+_nsamples)+1, ny=5))\n",
    "    axs_g1_m[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=5))\n",
    "    axs_g1_trans_p[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*(i+_nsamples)+1, ny=3))\n",
    "    axs_g1_trans_m[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=3))\n",
    "    # Cyto-specific ...\n",
    "    # mind the gaps/marging between actual plots ...\n",
    "    axs_cyto_p[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*(i+_nsamples)+1, ny=9))\n",
    "    axs_cyto_m[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=9))\n",
    "    axs_cyto_trans_p[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*(i+_nsamples)+1, ny=7))\n",
    "    axs_cyto_trans_m[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=7))\n",
    "\n",
    "cbar_ax = fig.add_axes(\n",
    "    divider.get_position(),\n",
    "    axes_locator=divider.new_locator(nx=2*(i+_nsamples-1)+1, nx1=2*(i+_nsamples+1), ny=1)\n",
    ")\n",
    "cbar_ax.set_xticks([])\n",
    "cbar_ax.set_yticks([])\n",
    "\n",
    "\n",
    "for jj, _sample in enumerate(timecourse_samples):\n",
    "    axm, axp = axs_g1_m[_sample], axs_g1_p[_sample]\n",
    "    taxm, taxp = axs_g1_trans_m[_sample], axs_g1_trans_p[_sample]\n",
    "    #\n",
    "    sample_m = f\"m{_sample}\"\n",
    "    sample_p = f\"p{_sample}\"\n",
    "    _cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_G1idx], axis=0)\n",
    "    _cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_G1idx], axis=0)\n",
    "    _trans_stack_m = stack_means[sample_m][_trans_G1idx]\n",
    "    _trans_stack_p = stack_means[sample_p][_trans_G1idx]\n",
    "    # cis pileups first ...\n",
    "    _hm = axm.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    _hm = axp.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    # # trans pileups second ...\n",
    "    _hm = taxm.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    _hm = taxp.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    for _ax in [axp, axm, taxp, taxm]:\n",
    "        _ax.set_xticks([])\n",
    "        _ax.set_yticks([])\n",
    "    # ylabel\n",
    "    if jj == 0:\n",
    "        axm.set_ylabel(\"cis\", fontsize=6, labelpad=1)\n",
    "        taxm.set_ylabel(\"trans\", fontsize=6, labelpad=1)\n",
    "    # add ticks ...\n",
    "    _mat_size = _trans_stack_m.shape[0]\n",
    "    taxm.set_xticks([0-0.5, _mat_size/2-0.5, _mat_size-0.5])\n",
    "    taxm.set_xticklabels([-_flank//1000, 0, _flank//1000], fontsize=4)\n",
    "    taxm.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "    for _tidx, tick in enumerate(taxm.xaxis.get_majorticklabels()):\n",
    "        if _tidx == 0:\n",
    "            tick.set_horizontalalignment(\"left\")\n",
    "        elif _tidx == 2:\n",
    "            tick.set_horizontalalignment(\"right\")\n",
    "        else:\n",
    "            tick.set_horizontalalignment(\"center\")\n",
    "    taxp.set_xticks([0-0.5, _mat_size/2-0.5, _mat_size-0.5])\n",
    "    taxp.set_xticklabels([-_flank//1000, 0, _flank//1000], fontsize=4)\n",
    "    taxp.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "    for _tidx, tick in enumerate(taxp.xaxis.get_majorticklabels()):\n",
    "        if _tidx == 0:\n",
    "            tick.set_horizontalalignment(\"left\")\n",
    "        elif _tidx == 2:\n",
    "            tick.set_horizontalalignment(\"right\")\n",
    "        else:\n",
    "            tick.set_horizontalalignment(\"center\")\n",
    "    # for the very last one ... - do ticks again ...\n",
    "    if jj == len(timecourse_samples) - 1:\n",
    "        _mat_size = _trans_stack_m.shape[0]\n",
    "        taxp.yaxis.tick_right()\n",
    "        taxp.set_yticks(\n",
    "            [0-0.5, _mat_size/2-0.5, _mat_size-0.5],\n",
    "            labels=[-_flank//1000, 0, _flank//1000],\n",
    "            rotation=90,\n",
    "            fontsize=4,\n",
    "        )\n",
    "        taxp.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "        for _tidx, tick in enumerate(taxp.yaxis.get_majorticklabels()):\n",
    "            if _tidx == 0:\n",
    "                tick.set_verticalalignment(\"top\")\n",
    "            elif _tidx == 2:\n",
    "                tick.set_verticalalignment(\"bottom\")\n",
    "            else:\n",
    "                tick.set_verticalalignment(\"center\")\n",
    "        _mat_size = _cis_stack_m.shape[0]\n",
    "        axp.yaxis.tick_right()\n",
    "        axp.set_yticks(\n",
    "            [0-0.5, _mat_size/2-0.5, _mat_size-0.5],\n",
    "            labels=[-_flank//1000, 0, _flank//1000],\n",
    "            rotation=90,\n",
    "            fontsize=4,\n",
    "        )\n",
    "        axp.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "        for _tidx, tick in enumerate(axp.yaxis.get_majorticklabels()):\n",
    "            if _tidx == 0:\n",
    "                tick.set_verticalalignment(\"top\")\n",
    "            elif _tidx == 2:\n",
    "                tick.set_verticalalignment(\"bottom\")\n",
    "            else:\n",
    "                tick.set_verticalalignment(\"center\")\n",
    "\n",
    "for jj, _sample in enumerate(timecourse_samples):\n",
    "    axm, axp = axs_cyto_m[_sample], axs_cyto_p[_sample]\n",
    "    taxm, taxp = axs_cyto_trans_m[_sample], axs_cyto_trans_p[_sample]\n",
    "    #\n",
    "    sample_m = f\"m{_sample}\"\n",
    "    sample_p = f\"p{_sample}\"\n",
    "    _cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_Cytoidx], axis=0)\n",
    "    _cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_Cytoidx], axis=0)\n",
    "    _trans_stack_m = stack_means[sample_m][_trans_Cytoidx]\n",
    "    _trans_stack_p = stack_means[sample_p][_trans_Cytoidx]\n",
    "    # cis pileups first ...\n",
    "    _hm = axm.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    _hm = axp.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    # # trans pileups second ...\n",
    "    _hm = taxm.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    _hm = taxp.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    for _ax in [axp, axm, taxp, taxm]:\n",
    "        _ax.set_xticks([])\n",
    "        _ax.set_yticks([])\n",
    "    # ylabel\n",
    "    if jj == 0:\n",
    "        axm.set_ylabel(\"cis\", fontsize=6, labelpad=1)\n",
    "        taxm.set_ylabel(\"trans\", fontsize=6, labelpad=1)\n",
    "    # ...\n",
    "    axm.set_title(_sample, fontsize=6, pad=1)\n",
    "    axp.set_title(_sample, fontsize=6, pad=1)\n",
    "    # for the very last one ... - do ticks again ...\n",
    "    if jj == len(timecourse_samples) - 1:\n",
    "        _mat_size = _trans_stack_m.shape[0]\n",
    "        taxp.yaxis.tick_right()\n",
    "        taxp.set_yticks(\n",
    "            [0-0.5, _mat_size/2-0.5, _mat_size-0.5],\n",
    "            labels=[-_flank//1000, 0, _flank//1000],\n",
    "            rotation=90,\n",
    "            fontsize=4,\n",
    "        )\n",
    "        taxp.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "        for _tidx, tick in enumerate(taxp.yaxis.get_majorticklabels()):\n",
    "            if _tidx == 0:\n",
    "                tick.set_verticalalignment(\"top\")\n",
    "            elif _tidx == 2:\n",
    "                tick.set_verticalalignment(\"bottom\")\n",
    "            else:\n",
    "                tick.set_verticalalignment(\"center\")\n",
    "        _mat_size = _cis_stack_m.shape[0]\n",
    "        axp.yaxis.tick_right()\n",
    "        axp.set_yticks(\n",
    "            [0-0.5, _mat_size/2-0.5, _mat_size-0.5],\n",
    "            labels=[-_flank//1000, 0, _flank//1000],\n",
    "            rotation=90,\n",
    "            fontsize=4,\n",
    "        )\n",
    "        axp.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "        for _tidx, tick in enumerate(axp.yaxis.get_majorticklabels()):\n",
    "            if _tidx == 0:\n",
    "                tick.set_verticalalignment(\"top\")\n",
    "            elif _tidx == 2:\n",
    "                tick.set_verticalalignment(\"bottom\")\n",
    "            else:\n",
    "                tick.set_verticalalignment(\"center\")\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax], fontsize=6)\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "for _tidx, tick in enumerate(cbar_ax.xaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_horizontalalignment(\"left\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_horizontalalignment(\"right\")\n",
    "    else:\n",
    "        tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "\n",
    "plt.savefig(\"fig3D_timecourse.svg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86357fe7-ab6c-413c-b889-3a90a99adce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0256065-aa19-4138-a02e-31a6cee0850a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151162d-db24-4966-8fed-60847875e303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f82ae7-3cf0-44cf-a782-f9a9b9264272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828f955-ce39-42f2-b52e-019b67a8dde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad010c73-019d-4e87-909a-6640440d0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# margin = 0.2\n",
    "# tcourse_spacing = 0.1\n",
    "# matw = 0.45\n",
    "# cbarh = 0.075\n",
    "\n",
    "# imshow_kwargs = dict(\n",
    "#         norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "#         cmap=\"RdBu_r\",\n",
    "#         interpolation=\"nearest\",\n",
    "# )\n",
    "\n",
    "# # timecourse_samples = [\"Mito\", \"Telo\", \"Cyto\", \"5hR1R2\", \"10hR1R2\"]\n",
    "# timecourse_samples = [\"Mito\", \"Telo\", \"Cyto\", \"5hR1R2\"]\n",
    "# _nsamples = len(timecourse_samples)\n",
    "\n",
    "# _flank = 100_000\n",
    "# _dfff = _df_intra_arm\n",
    "# # _cis_subidx = _dfff.query(\"(dots_footprint1==0)&(dots_footprint2==0)\").index\n",
    "# # _cis_subidx = _dfff.query(\"(dots_footprint1>0)&(dots_footprint2>0)\").index\n",
    "# # _cis_subidx = _dfff.query(\"G1status1 & G1status2\").index\n",
    "# # _cis_subidx = _dfff.query(\"~Cytostatus1 & ~Cytostatus2\").index\n",
    "# _cis_subidx = _dfff.index\n",
    "# _trans_idx = 0\n",
    "\n",
    "# # The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "# h = [ Size.Fixed(margin) ] + \\\n",
    "#     (_nsamples-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "#     [ Size.Fixed(matw), Size.Fixed(tcourse_spacing) ] + \\\n",
    "#     (_nsamples-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "#     [ Size.Fixed(matw), Size.Fixed(margin) ]\n",
    "# # goes from bottom to the top ...\n",
    "# v = [ Size.Fixed(margin), Size.Fixed(cbarh), Size.Fixed(0.2*margin),\n",
    "#      Size.Fixed(matw), Size.Fixed(tcourse_spacing), Size.Fixed(matw), Size.Fixed(margin)]\n",
    "\n",
    "\n",
    "# # set figsize based on the tiling provided ...\n",
    "# fig_width = sum(_h.fixed_size for _h in h)\n",
    "# fig_height = sum(_v.fixed_size for _v in v)\n",
    "# fig = plt.figure(\n",
    "#     figsize=(fig_width, fig_height),\n",
    "#     # facecolor='lightblue'\n",
    "# )\n",
    "# print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "\n",
    "# # ...\n",
    "# divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "# axs_m = {}\n",
    "# axs_p = {}\n",
    "# axs_trans_m = {}\n",
    "# axs_trans_p = {}\n",
    "\n",
    "# for i, _sample in enumerate(timecourse_samples):\n",
    "#     # mind the gaps/marging between actual plots ...\n",
    "#     axs_p[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*(i+_nsamples)+1, ny=5))\n",
    "#     axs_m[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=5))\n",
    "#     axs_trans_p[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*(i+_nsamples)+1, ny=3))\n",
    "#     axs_trans_m[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=3))\n",
    "\n",
    "# cbar_ax = fig.add_axes(\n",
    "#     divider.get_position(),\n",
    "#     axes_locator=divider.new_locator(nx=2*(i+_nsamples-1)+1, nx1=2*(i+_nsamples+1), ny=1)\n",
    "# )\n",
    "# cbar_ax.set_xticks([])\n",
    "# cbar_ax.set_yticks([])\n",
    "\n",
    "\n",
    "# for jj, _sample in enumerate(timecourse_samples):\n",
    "#     axm, axp = axs_m[_sample], axs_p[_sample]\n",
    "#     taxm, taxp = axs_trans_m[_sample], axs_trans_p[_sample]\n",
    "#     #\n",
    "#     sample_m = f\"m{_sample}\"\n",
    "#     sample_p = f\"p{_sample}\"\n",
    "#     _cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_subidx], axis=0)\n",
    "#     _cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_subidx], axis=0)\n",
    "#     _trans_stack_m = stack_means[sample_m][_trans_idx]\n",
    "#     _trans_stack_p = stack_means[sample_p][_trans_idx]\n",
    "#     # #\n",
    "#     # # cis pileups first ...\n",
    "#     _hm = axm.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     _hm = axp.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     # # trans pileups second ...\n",
    "#     _hm = taxm.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     _hm = taxp.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     for _ax in [axp, axm, taxp, taxm]:\n",
    "#         _ax.set_xticks([])\n",
    "#         _ax.set_yticks([])\n",
    "#     # axm.set_title(f\"{_dist_key}\", fontsize=9)\n",
    "#     # axp.set_xticks(np.arange(len(ticklabels)))\n",
    "#     # axp.set_xticklabels(np.asarray(ticklabels[::-1]), rotation=\"vertical\")\n",
    "#     # if jj == 0:\n",
    "#     #     axm.set_ylabel(sample_m)\n",
    "#     #     axp.set_ylabel(sample_p)\n",
    "\n",
    "# # add a single colorbar ...\n",
    "# fig.colorbar(\n",
    "#     cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "#     cax=cbar_ax,\n",
    "#     orientation=\"horizontal\",\n",
    "# )\n",
    "# cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "# cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "# cbar_ax.minorticks_off()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb93aa-b74d-4d47-b609-c515d2d99d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd5d9d-8ef0-458a-ad98-7b5c3e455b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad893ec3-dc10-4811-b8a9-582743a0dd00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6d4a1-6e01-4fb4-b5ad-ef700b61e9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "517d1c14-a457-4e68-bd7c-85225cf492ca",
   "metadata": {},
   "source": [
    "# Mostly legacy stuff below ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17e3e9-5bc9-4939-b2fe-59c879a29d0e",
   "metadata": {},
   "source": [
    "## create a function that assigns distance in dots\n",
    "\n",
    "### Load the dots (not anchors) first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4c541-fd62-4909-b104-c4d070e5dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "# ############################################# anchors ...\n",
    "# anchor_fnames = {\n",
    "#     \"mega_ctrl\": \"dot_anchors_10kb_MEGA/mG1s_MEGA.bed\",\n",
    "# }\n",
    "# # ...\n",
    "# dot_anchors_dict = {}\n",
    "# for id_name, fname in anchor_fnames.items():\n",
    "#     dot_anchors_dict[id_name] = pd.read_csv(fname, sep=\"\\t\")\n",
    "#     # ...\n",
    "#     print(f\"loaded {len(dot_anchors_dict[id_name]):5d} ID anchors {id_name:>20} in BED format ...\")\n",
    "# # ...\n",
    "# ##################################################################\n",
    "# ############################################# dots themselves ...\n",
    "dot_fnames = {\n",
    "    \"mega_ctrl\": \"dots_10kb_MEGA_samples/mG1s_MEGA_10kb_wheader.bedpe\",\n",
    "    \"mega_depl\": \"dots_10kb_MEGA_samples/pG1s_MEGA_10kb_wheader.bedpe\",\n",
    "    \"mega_mito\": \"dots_10kb_MEGA_samples/Ms_MEGA_10kb_wheader.bedpe\",\n",
    "    \"cyto\": \"dots_10kb_samples/mCyto_10kb_wheader.bedpe\",\n",
    "}\n",
    "# ...\n",
    "# let's load them all into a dictionary ...\n",
    "dots_dict = {}\n",
    "for id_name, fname in dot_fnames.items():\n",
    "    dots_dict[id_name] = pd.read_csv(fname, sep=\"\\t\")\n",
    "    # ...\n",
    "    print(f\"loaded {len(dots_dict[id_name]):5d} dots {id_name:>20} in BEDPE format ...\")\n",
    "\n",
    "\n",
    "# pick specific anchors and dots ...\n",
    "# _the_anchors = dot_anchors_dict[\"mega_ctrl\"]\n",
    "_the_dots = dots_dict[\"mega_ctrl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dddf4b-7c11-439e-ac44-d73982445c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "_the_dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658893b-de41-4662-ba1e-d29549a03a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dot_distance(\n",
    "    df_grid,\n",
    "    dots,\n",
    "):\n",
    "    # ...\n",
    "    _overlap_kwargs = dict(\n",
    "        return_input=False,\n",
    "        return_index=True,\n",
    "        return_overlap=True,\n",
    "        suffixes=(\"\",\"_dot\"),\n",
    "        keep_order=True,\n",
    "    )\n",
    "    ######################################################################################\n",
    "    _1 = bioframe.overlap(\n",
    "        df_grid,\n",
    "        dots,\n",
    "        cols1=(\"chrom1\", \"peak_start1\", \"peak_end1\"),\n",
    "        cols2=(\"chrom1\", \"start1\", \"end1\"),\n",
    "        **_overlap_kwargs,\n",
    "    )\n",
    "    _2 = bioframe.overlap(\n",
    "        df_grid,\n",
    "        dots,\n",
    "        cols1=(\"chrom1\", \"peak_start1\", \"peak_end1\"),\n",
    "        cols2=(\"chrom2\", \"start2\", \"end2\"),\n",
    "        **_overlap_kwargs,\n",
    "    )\n",
    "    _left_dot_exact = pd.concat([_1, _2]).sort_values(by=\"index\").reset_index(drop=True)\n",
    "    ######################################################################################\n",
    "    # ...                                                                                #\n",
    "    ######################################################################################\n",
    "    _1 = bioframe.overlap(\n",
    "        df_grid,\n",
    "        dots,\n",
    "        cols1=(\"chrom2\", \"peak_start2\", \"peak_end2\"),\n",
    "        cols2=(\"chrom1\", \"start1\", \"end1\"),\n",
    "        **_overlap_kwargs,\n",
    "    )\n",
    "    _2 = bioframe.overlap(\n",
    "        df_grid,\n",
    "        dots,\n",
    "        cols1=(\"chrom2\", \"peak_start2\", \"peak_end2\"),\n",
    "        cols2=(\"chrom2\", \"start2\", \"end2\"),\n",
    "        **_overlap_kwargs,\n",
    "    )\n",
    "    _right_dot_exact = pd.concat([_1, _2]).sort_values(by=\"index\").reset_index(drop=True)\n",
    "    ######################################################################################\n",
    "    #\n",
    "    #\n",
    "    ######################################################################################\n",
    "    _dot_annot = _left_dot_exact.merge(\n",
    "        _right_dot_exact,\n",
    "        on=\"index\",\n",
    "    )\n",
    "    _dot_annot[\"dot_order\"] = _dot_annot.eval(\"abs(index_dot_x - index_dot_y)\")\n",
    "    _min_dotorder_perIDID = _dot_annot.groupby(\"index\")[\"dot_order\"].min()\n",
    "    return _min_dotorder_perIDID.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe440d-4eb5-491e-8a18-c93cef763da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_intra_arm\n",
    "# _the_dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe36a0d-608b-4cca-bd65-fb5cbe6d3ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dot_distance(\n",
    "    _df_intra_arm,\n",
    "    _the_dots,\n",
    ").query(\"dot_order < 3\").index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c72de2-4d39-4436-ad95-95a15f2d892a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f79470-aa56-46b1-af45-d6b38742b7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d756f962-cf8d-41b7-b8bd-a7e9550f63a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b4445-a1fa-4b72-b173-4ee5c3ca6b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b5655f9-f75f-4cfd-be05-b7c4df37d1b8",
   "metadata": {},
   "source": [
    "# Nup93 Figure Ext fig 5 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435874d-a53f-4316-b4c5-c99a6985310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 6, 2.9\n",
    "margin = 0.2\n",
    "matw = 0.75*1.15\n",
    "cbarh = 0.1\n",
    "# cbarw = 0.7*matw\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize=(w, h),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"none\",\n",
    ")\n",
    "\n",
    "# timecourse_samples = [\"Mito\", \"Telo\", \"Cyto\", \"5hR1R2\", \"10hR1R2\"]\n",
    "# timecourse_samples = [\"Mito\", \"Telo\", \"Cyto\", \"5hR1R2\"]\n",
    "timecourse_samples = [\"5\", \"10\"]\n",
    "_nsamples = len(timecourse_samples)\n",
    "\n",
    "\n",
    "_flank = 100_000\n",
    "_dfff = _df_intra_arm\n",
    "\n",
    "\n",
    "\n",
    "# _cis_subidx = _dfff.query(\"(dots_footprint1==0)&(dots_footprint2==0)\").index\n",
    "_cis_subidx = _dfff.query(\"(dots_footprint1>0)&(dots_footprint2>0)\").index\n",
    "# _cis_subidx = _dfff.query(\"G1status1 & G1status2\").index\n",
    "# _cis_subidx = _dfff.query(\"~Cytostatus1 & ~Cytostatus2\").index\n",
    "# _cis_subidx = _dfff.index\n",
    "_trans_idx = 1\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = _nsamples*[Size.Fixed(0.25*margin), Size.Fixed(matw)] + [Size.Fixed(margin)] + _nsamples*[Size.Fixed(matw), Size.Fixed(0.25*margin)]\n",
    "# goes from bottom to the top ...\n",
    "v = [Size.Fixed(margin), Size.Fixed(cbarh)] + 2*[Size.Fixed(margin), Size.Fixed(matw)]\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "axs_m = {}\n",
    "axs_p = {}\n",
    "axs_trans_m = {}\n",
    "axs_trans_p = {}\n",
    "# cax_h = {}\n",
    "\n",
    "for i, _sample in enumerate(timecourse_samples):\n",
    "    # mind the gaps/marging between actual plots ...\n",
    "    axs_p[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*(i+_nsamples)+1, ny=5))\n",
    "    axs_m[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=5))\n",
    "    axs_trans_p[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*(i+_nsamples)+1, ny=3))\n",
    "    axs_trans_m[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=3))\n",
    "\n",
    "# _dist_key = \"trans\"\n",
    "# # mind the gaps/marging between actual plots ...\n",
    "# axs_p[_dist_key] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=3))\n",
    "# axs_m[_dist_key] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=5))\n",
    "\n",
    "cbar_ax = fig.add_axes(\n",
    "    divider.get_position(),\n",
    "    axes_locator=divider.new_locator(nx=2*(i+_nsamples-1)+1, nx1=2*(i+_nsamples+1)+1, ny=1)\n",
    ")\n",
    "cbar_ax.set_xticks([])\n",
    "cbar_ax.set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "for jj, _sample in enumerate(timecourse_samples):\n",
    "    axm, axp = axs_m[_sample], axs_p[_sample]\n",
    "    taxm, taxp = axs_trans_m[_sample], axs_trans_p[_sample]\n",
    "    #\n",
    "    sample_m = f\"N93m{_sample}\"\n",
    "    sample_p = f\"N93p{_sample}\"\n",
    "    _cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_subidx], axis=0)\n",
    "    _cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_subidx], axis=0)\n",
    "    _trans_stack_m = stack_means[sample_m][_trans_idx]\n",
    "    _trans_stack_p = stack_means[sample_p][_trans_idx]\n",
    "    # #\n",
    "    # # cis pileups first ...\n",
    "    _hm = axm.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    _hm = axp.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    # # trans pileups second ...\n",
    "    _hm = taxm.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    _hm = taxp.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "    _hm.cmap.set_over(\"#300000\")\n",
    "    for _ax in [axp, axm, taxp, taxm]:\n",
    "        _ax.set_xticks([])\n",
    "        _ax.set_yticks([])\n",
    "    # axm.set_title(f\"{_dist_key}\", fontsize=9)\n",
    "    # axp.set_xticks(np.arange(len(ticklabels)))\n",
    "    # axp.set_xticklabels(np.asarray(ticklabels[::-1]), rotation=\"vertical\")\n",
    "    # if jj == 0:\n",
    "    #     axm.set_ylabel(sample_m)\n",
    "    #     axp.set_ylabel(sample_p)\n",
    "\n",
    "\n",
    "# # treat trans separately ...\n",
    "# jj = jj + 1\n",
    "# _dist_key = \"trans\"\n",
    "# _dist_idx = slice(None)\n",
    "# axm, axp = axs_m[_dist_key], axs_p[_dist_key]\n",
    "# _hm = axm.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "# _hm.cmap.set_over(\"#300000\")\n",
    "# _hm = axp.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "# _hm.cmap.set_over(\"#300000\")\n",
    "# for _ax in [axp, axm]:\n",
    "#     _ax.set_xticks([])\n",
    "#     _ax.set_yticks([])\n",
    "# axm.set_title(f\"{_dist_key}\", fontsize=9)\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.minorticks_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e5070-045d-4b8f-abe8-3a9b99cf9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 6, 2.9\n",
    "margin = 0.2\n",
    "matw = 0.75*1.15\n",
    "cbarh = 0.1\n",
    "# cbarw = 0.7*matw\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize=(w, h),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"none\",\n",
    ")\n",
    "\n",
    "\n",
    "_flank = 100_000\n",
    "_dfff = _df_intra_arm\n",
    "\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = 2*[Size.Fixed(margin), Size.Fixed(matw)]\n",
    "# goes from bottom to the top ...\n",
    "v = [Size.Fixed(margin), Size.Fixed(cbarh)] + 3*[Size.Fixed(margin), Size.Fixed(matw)]\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "# mind the gaps/marging between actual plots ...\n",
    "ax_m_dot = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=7))\n",
    "ax_p_dot = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=7))\n",
    "\n",
    "ax_m_dotted = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=5))\n",
    "ax_p_dotted = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=5))\n",
    "\n",
    "ax_m_dotless = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=3))\n",
    "ax_p_dotless = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=3))\n",
    "\n",
    "\n",
    "\n",
    "for _ax in [ax_m_dot, ax_p_dot, ax_m_dotted, ax_p_dotted, ax_m_dotless, ax_p_dotless]:\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "sample_m = f\"N93m5\"\n",
    "sample_p = f\"N93p10\"\n",
    "\n",
    "\n",
    "# @ the dot exact\n",
    "_cis_subidx = get_dot_distance(_dfff, _the_dots).query(\"dot_order < 3\").index\n",
    "_cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_subidx], axis=0)\n",
    "_cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_subidx], axis=0)\n",
    "# # cis pileups first ...\n",
    "_hm = ax_m_dot.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "_hm = ax_p_dot.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "\n",
    "# dotted\n",
    "_cis_subidx = _dfff.query(\"(dots_footprint1>0)&(dots_footprint2>0)\").index\n",
    "_cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_subidx], axis=0)\n",
    "_cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_subidx], axis=0)\n",
    "# # cis pileups first ...\n",
    "_hm = ax_m_dotted.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "_hm = ax_p_dotted.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "\n",
    "# dotless\n",
    "_cis_subidx = _dfff.query(\"(dots_footprint1==0)&(dots_footprint2==0)\").index\n",
    "_cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_subidx], axis=0)\n",
    "_cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_subidx], axis=0)\n",
    "# # cis pileups first ...\n",
    "_hm = ax_m_dotless.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "_hm = ax_p_dotless.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "\n",
    "cbar_ax = fig.add_axes(\n",
    "    divider.get_position(),\n",
    "    axes_locator=divider.new_locator(nx=3, ny=1)\n",
    ")\n",
    "cbar_ax.set_xticks([])\n",
    "cbar_ax.set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for jj, _sample in enumerate(timecourse_samples):\n",
    "#     axm, axp = axs_m[_sample], axs_p[_sample]\n",
    "#     taxm, taxp = axs_trans_m[_sample], axs_trans_p[_sample]\n",
    "#     #\n",
    "#     sample_m = f\"N93m{_sample}\"\n",
    "#     sample_p = f\"N93p{_sample}\"\n",
    "#     _cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_subidx], axis=0)\n",
    "#     _cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_subidx], axis=0)\n",
    "#     _trans_stack_m = stack_means[sample_m][_trans_idx]\n",
    "#     _trans_stack_p = stack_means[sample_p][_trans_idx]\n",
    "#     # #\n",
    "#     # # cis pileups first ...\n",
    "#     _hm = axm.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     _hm = axp.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     # # trans pileups second ...\n",
    "#     _hm = taxm.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     _hm = taxp.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     for _ax in [axp, axm, taxp, taxm]:\n",
    "#         _ax.set_xticks([])\n",
    "#         _ax.set_yticks([])\n",
    "#     # axm.set_title(f\"{_dist_key}\", fontsize=9)\n",
    "#     # axp.set_xticks(np.arange(len(ticklabels)))\n",
    "#     # axp.set_xticklabels(np.asarray(ticklabels[::-1]), rotation=\"vertical\")\n",
    "#     # if jj == 0:\n",
    "#     #     axm.set_ylabel(sample_m)\n",
    "#     #     axp.set_ylabel(sample_p)\n",
    "\n",
    "\n",
    "# # # treat trans separately ...\n",
    "# # jj = jj + 1\n",
    "# # _dist_key = \"trans\"\n",
    "# # _dist_idx = slice(None)\n",
    "# # axm, axp = axs_m[_dist_key], axs_p[_dist_key]\n",
    "# # _hm = axm.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "# # _hm.cmap.set_over(\"#300000\")\n",
    "# # _hm = axp.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "# # _hm.cmap.set_over(\"#300000\")\n",
    "# # for _ax in [axp, axm]:\n",
    "# #     _ax.set_xticks([])\n",
    "# #     _ax.set_yticks([])\n",
    "# # axm.set_title(f\"{_dist_key}\", fontsize=9)\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.minorticks_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae11e52-9be4-418f-b27b-476423f48b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb9e53-e4b1-4564-96b1-2c3d5e878129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83a79b-a33f-4665-b2a7-b39ccfc0304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 6, 2.9\n",
    "margin = 0.2\n",
    "matw = 0.75*1.15\n",
    "cbarh = 0.1\n",
    "# cbarw = 0.7*matw\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize=(w, h),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"none\",\n",
    ")\n",
    "\n",
    "_flank = 100_000\n",
    "_dfff = _df_intra_arm\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = 4*[Size.Fixed(margin), Size.Fixed(matw)]\n",
    "# goes from bottom to the top ...\n",
    "v = [Size.Fixed(margin), Size.Fixed(cbarh)] + 3*[Size.Fixed(margin), Size.Fixed(matw)]\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "# mind the gaps/marging between actual plots ...\n",
    "ax_m_dot = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=7))\n",
    "ax_p_dot = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=5, ny=7))\n",
    "\n",
    "ax_m_dotted = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=5))\n",
    "ax_p_dotted = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=5, ny=5))\n",
    "\n",
    "ax_m_dotless = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=3))\n",
    "ax_p_dotless = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=5, ny=3))\n",
    "\n",
    "ax_m_trans_dotted = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=5))\n",
    "ax_p_trans_dotted = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=7, ny=5))\n",
    "\n",
    "ax_m_trans_dotless = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, ny=3))\n",
    "ax_p_trans_dotless = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=7, ny=3))\n",
    "\n",
    "for _ax in [\n",
    "    ax_m_dot,\n",
    "    ax_p_dot,\n",
    "    ax_m_dotted,\n",
    "    ax_p_dotted,\n",
    "    ax_m_dotless,\n",
    "    ax_p_dotless,\n",
    "    ax_m_trans_dotted,\n",
    "    ax_p_trans_dotted,\n",
    "    ax_m_trans_dotless,\n",
    "    ax_p_trans_dotless,\n",
    "]:\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "\n",
    "sample_m = f\"N93m5\"\n",
    "sample_p = f\"N93p10\"\n",
    "\n",
    "# @ the dot exact\n",
    "_cis_subidx = get_dot_distance(_dfff, _the_dots).query(\"dot_order < 3\").index\n",
    "_cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_subidx], axis=0)\n",
    "_cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_subidx], axis=0)\n",
    "# # cis pileups first ...\n",
    "_hm = ax_m_dot.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "_hm = ax_p_dot.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "\n",
    "# dotted\n",
    "_cis_subidx = _dfff.query(\"(dots_footprint1>0)&(dots_footprint2>0)\").index\n",
    "_cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_subidx], axis=0)\n",
    "_cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_subidx], axis=0)\n",
    "# # cis pileups first ...\n",
    "_hm = ax_m_dotted.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "_hm = ax_p_dotted.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "\n",
    "# dotless\n",
    "_cis_subidx = _dfff.query(\"(dots_footprint1==0)&(dots_footprint2==0)\").index\n",
    "_cis_stack_m = np.nanmean(fullstacks_cis[sample_m][_cis_subidx], axis=0)\n",
    "_cis_stack_p = np.nanmean(fullstacks_cis[sample_p][_cis_subidx], axis=0)\n",
    "# # cis pileups first ...\n",
    "_hm = ax_m_dotless.imshow( _cis_stack_m, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "_hm = ax_p_dotless.imshow( _cis_stack_p, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "\n",
    "# TRANS ...\n",
    "# dotted\n",
    "_trans_idx = 1\n",
    "_trans_stack_m = stack_means[sample_m][_trans_idx]\n",
    "_trans_stack_p = stack_means[sample_p][_trans_idx]\n",
    "# trans pileups first ...\n",
    "_hm = ax_m_trans_dotted.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "_hm = ax_p_trans_dotted.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "\n",
    "# dotless\n",
    "_trans_idx = 0\n",
    "_trans_stack_m = stack_means[sample_m][_trans_idx]\n",
    "_trans_stack_p = stack_means[sample_p][_trans_idx]\n",
    "# trans pileups first ...\n",
    "_hm = ax_m_trans_dotless.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "_hm = ax_p_trans_dotless.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "_hm.cmap.set_over(\"#300000\")\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "cbar_ax = fig.add_axes(\n",
    "    divider.get_position(),\n",
    "    axes_locator=divider.new_locator(nx=7, ny=1)\n",
    ")\n",
    "cbar_ax.set_xticks([])\n",
    "cbar_ax.set_yticks([])\n",
    "\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.minorticks_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29455b7-0977-4ede-9553-d5a0beb2a9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808a4f0-8e2d-4e2f-9e3a-aa80e11c0cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54fa387-a106-4194-8c06-df0502ca4e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95642eb0-bdfa-4069-b2ce-1333fcee3223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w, h = 6, 2.9\n",
    "# margin = 0.2\n",
    "# matw = 1.15\n",
    "# cbarh = 0.1\n",
    "# # cbarw = 0.7*matw\n",
    "\n",
    "# fig = plt.figure(\n",
    "#     figsize=(w, h),\n",
    "#     # facecolor='lightblue'\n",
    "# )\n",
    "\n",
    "# imshow_kwargs = dict(\n",
    "#         norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "#         cmap=\"RdBu_r\",\n",
    "#         interpolation=\"none\",\n",
    "# )\n",
    "\n",
    "\n",
    "# _flank = 100_000\n",
    "# _dfff = _df_intra_arm\n",
    "# # _dfff = _df_intra_arm.query(\"(dots_footprint1==0)&(dots_footprint2==0)\")\n",
    "# dist_bins = [0, 500_000, 10_000_000, 1_000_000_000]\n",
    "# dist_bins = [0, 250_000, 1_000_000, 10_000_000, 1_000_000_000]\n",
    "# _dist_groups = _dfff.groupby(pd.cut( _dfff[\"dist\"], dist_bins ), observed=True)\n",
    "# ndist = len(_dist_groups)\n",
    "\n",
    "\n",
    "# # The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "# h =  (len(_dist_groups)+1)*[Size.Fixed(margin), Size.Fixed(matw)]\n",
    "# # goes from bottom to the top ...\n",
    "# v = [Size.Fixed(margin), Size.Fixed(cbarh)] + \\\n",
    "#     2 * [Size.Fixed(0.5*margin), Size.Fixed(matw)]\n",
    "# # ...\n",
    "# divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "# sample_m = \"m5hR1R2\"\n",
    "# sample_p = \"p5hR1R2\"\n",
    "# _cis_stack_m = fullstacks_cis[sample_m]\n",
    "# _cis_stack_p = fullstacks_cis[sample_p]\n",
    "\n",
    "# _trans_stack_m = stack_means[sample_m][-1]\n",
    "# _trans_stack_p = stack_means[sample_p][-1]\n",
    "\n",
    "# axs_m = {}\n",
    "# axs_p = {}\n",
    "# cax_h = {}\n",
    "\n",
    "# for i, _dist_key in enumerate(_dist_groups.groups):\n",
    "#     # mind the gaps/marging between actual plots ...\n",
    "#     axs_p[_dist_key] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=3))\n",
    "#     axs_m[_dist_key] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=5))\n",
    "# i = i + 1\n",
    "# _dist_key = \"trans\"\n",
    "# # mind the gaps/marging between actual plots ...\n",
    "# axs_p[_dist_key] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=3))\n",
    "# axs_m[_dist_key] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=5))\n",
    "\n",
    "# cbar_ax = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=1))\n",
    "# cbar_ax.set_xticks([])\n",
    "# cbar_ax.set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "# for jj, (_dist_key, _dist_idx) in enumerate(_dist_groups.groups.items()):\n",
    "#     axm, axp = axs_m[_dist_key], axs_p[_dist_key]\n",
    "#     # cis pileups first ...\n",
    "#     _hm = axm.imshow( np.nanmean(_cis_stack_m[_dist_idx], axis=0), **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     _hm = axp.imshow( np.nanmean(_cis_stack_p[_dist_idx], axis=0), **imshow_kwargs)\n",
    "#     _hm.cmap.set_over(\"#300000\")\n",
    "#     for _ax in [axp, axm]:\n",
    "#         _ax.set_xticks([])\n",
    "#         _ax.set_yticks([])\n",
    "#     axm.set_title(f\"{_dist_key}\", fontsize=9)\n",
    "#     # axp.set_xticks(np.arange(len(ticklabels)))\n",
    "#     # axp.set_xticklabels(np.asarray(ticklabels[::-1]), rotation=\"vertical\")\n",
    "#     if jj == 0:\n",
    "#         axm.set_ylabel(sample_m)\n",
    "#         axp.set_ylabel(sample_p)\n",
    "\n",
    "# stack_means[_sample]\n",
    "\n",
    "# # treat trans separately ...\n",
    "# jj = jj + 1\n",
    "# _dist_key = \"trans\"\n",
    "# _dist_idx = slice(None)\n",
    "# axm, axp = axs_m[_dist_key], axs_p[_dist_key]\n",
    "# _hm = axm.imshow( _trans_stack_m, **imshow_kwargs)\n",
    "# _hm.cmap.set_over(\"#300000\")\n",
    "# _hm = axp.imshow( _trans_stack_p, **imshow_kwargs)\n",
    "# _hm.cmap.set_over(\"#300000\")\n",
    "# for _ax in [axp, axm]:\n",
    "#     _ax.set_xticks([])\n",
    "#     _ax.set_yticks([])\n",
    "# axm.set_title(f\"{_dist_key}\", fontsize=9)\n",
    "\n",
    "\n",
    "# # add a single colorbar ...\n",
    "\n",
    "# fig.colorbar(\n",
    "#     cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "#     cax=cbar_ax,\n",
    "#     orientation=\"horizontal\",\n",
    "# )\n",
    "# cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "# cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "# cbar_ax.minorticks_off()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f247ac7-ea9c-49d9-97e0-c9e72f4d977b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1230e-b726-45f1-af2e-d9bae2859bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe119bc7-ce5f-45a8-8248-e8eb1800406b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c1d529-5a71-41dc-a025-be928f11576b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
