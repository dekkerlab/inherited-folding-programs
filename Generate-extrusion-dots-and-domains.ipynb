{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f380e11b-63c1-479c-a714-5b12bb538b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from saddle import saddleplot\n",
    "\n",
    "\n",
    "# set the number of threads for many common libraries\n",
    "from os import environ\n",
    "N_THREADS = '1'\n",
    "environ['OMP_NUM_THREADS'] = N_THREADS\n",
    "environ['OPENBLAS_NUM_THREADS'] = N_THREADS\n",
    "environ['MKL_NUM_THREADS'] = N_THREADS\n",
    "environ['VECLIB_MAXIMUM_THREADS'] = N_THREADS\n",
    "environ['NUMEXPR_NUM_THREADS'] = N_THREADS\n",
    "# https://superfastpython.com/numpy-number-blas-threads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e7973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "# Hi-C utilities imports:\n",
    "import cooler\n",
    "import bioframe\n",
    "import cooltools\n",
    "from cooltools.lib.numutils import fill_diag\n",
    "\n",
    "# Visualization imports:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import EngFormatter\n",
    "\n",
    "\n",
    "from data_catalog import telo_dict, pubclr_dict, mega_telo_dict\n",
    "\n",
    "clr_fname_dict = mega_telo_dict | pubclr_dict\n",
    "\n",
    "# helper functions for plotting\n",
    "bp_formatter = EngFormatter('b')\n",
    "def format_ticks(ax, x=True, y=True, rotate=True):\n",
    "    \"\"\"format ticks with genomic coordinates as human readable\"\"\"\n",
    "    if y:\n",
    "        ax.yaxis.set_major_formatter(bp_formatter)\n",
    "    if x:\n",
    "        ax.xaxis.set_major_formatter(bp_formatter)\n",
    "        ax.xaxis.tick_bottom()\n",
    "    if rotate:\n",
    "        ax.tick_params(axis='x',rotation=45)\n",
    "\n",
    "\n",
    "# function to draw kernels:\n",
    "def draw_kernel(kernel, axis=None, cmap='viridis'):\n",
    "    if axis is None:\n",
    "        f, axis = plt.subplots()\n",
    "    # kernel:\n",
    "    imk = axis.imshow(\n",
    "                    kernel[::-1,::-1],  # flip it, as in convolution\n",
    "                    alpha=0.85,\n",
    "                    cmap=cmap,\n",
    "                    interpolation='nearest')\n",
    "    # draw a square around the target pixel:\n",
    "    x0 = kernel.shape[0] // 2 - 0.5\n",
    "    y0 = kernel.shape[1] // 2 - 0.5\n",
    "    rect = patches.Rectangle((x0, y0), 1, 1, lw=1, ec='r', fc='r')\n",
    "    axis.add_patch(rect)\n",
    "\n",
    "    # clean axis:\n",
    "    axis.set_xticks([])\n",
    "    axis.set_yticks([])\n",
    "    axis.set_xticklabels('',visible=False)\n",
    "    axis.set_yticklabels('',visible=False)\n",
    "    axis.set_title(\"{} kernel\".format(ktype),fontsize=16)\n",
    "    # add a checkerboard to highlight pixels:\n",
    "    checkerboard = np.add.outer(range(kernel.shape[0]),\n",
    "                                range(kernel.shape[1])) % 2\n",
    "    # show it:\n",
    "    axis.imshow(checkerboard,\n",
    "            cmap='gray',\n",
    "            interpolation='nearest',\n",
    "            alpha=0.3)\n",
    "\n",
    "    return imk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70cdd4f-6b57-4e79-abcc-5d565d9ecd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "# import mpire for nested multi-processing\n",
    "from mpire import WorkerPool\n",
    "from helper_func import (\n",
    "    get_stack,\n",
    "    show_stacks,\n",
    "    plot_stackups_lite,\n",
    "    plot_stackups_sets,\n",
    "    to_bigbed3,\n",
    "    merge_nested,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304b11c-eec7-41f4-8273-aafd94bb5326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "# create a functions that would return a series of rectangles around called dots\n",
    "# in a specific region, and exposing importnat plotting parameters\n",
    "def rectangles_around_dots(dots_df, region, loc=\"upper\", lw=1, ec=\"cyan\", fc=\"none\"):\n",
    "    \"\"\"\n",
    "    yield a series of rectangles around called dots in a given region\n",
    "    \"\"\"\n",
    "    # select dots from the region:\n",
    "    df_reg = bioframe.select(\n",
    "        bioframe.select(dots_df, region, cols=(\"chrom1\",\"start1\",\"end1\")),\n",
    "        region,\n",
    "        cols=(\"chrom2\",\"start2\",\"end2\"),\n",
    "    )\n",
    "    rectangle_kwargs = dict(lw=lw, ec=ec, fc=fc)\n",
    "    # draw rectangular \"boxes\" around pixels called as dots in the \"region\":\n",
    "    for s1, s2, e1, e2 in df_reg[[\"start1\", \"start2\", \"end1\", \"end2\"]].itertuples(index=False):\n",
    "        width1 = e1 - s1\n",
    "        width2 = e2 - s2\n",
    "        if loc == \"upper\":\n",
    "            yield patches.Rectangle((s2, s1), width2, width1, **rectangle_kwargs)\n",
    "        elif loc == \"lower\":\n",
    "            yield patches.Rectangle((s1, s2), width1, width2, **rectangle_kwargs)\n",
    "        else:\n",
    "            raise ValueError(\"loc has to be uppper or lower\")\n",
    "\n",
    "# in a specific region, and exposing importnat plotting parameters\n",
    "def draw_ondiag_domains(bed_df, the_tile, lw=1, ec=\"cyan\", fc=\"none\", halo=30_000, ext_width=0):\n",
    "    rectangle_kwargs = dict(lw=lw, ec=ec, fc=fc)\n",
    "    # parse the tile\n",
    "    _, tspan1, tspan2 = the_tile\n",
    "    # select only visible \"boxes\" :\n",
    "    _the_dots = bed_df \\\n",
    "        .query(\"\"\"(@tspan1[0] - @halo < bin1_id < @tspan1[1] + @halo) & \\\n",
    "                  (@tspan2[0] - @halo < bin2_id < @tspan2[1] + @halo) \"\"\") \\\n",
    "        .eval(\"\"\"\n",
    "                b1 = bin1_id - @tspan1[0] - @ext_width\n",
    "                b2 = bin2_id - @tspan2[0] - @ext_width\n",
    "            \"\"\")\n",
    "    for b1, b2 in _the_dots[[\"b1\", \"b2\"]].itertuples(index=False):\n",
    "        yield patches.Rectangle((b1, b1), b2-b1+1, b2-b1+1, **rectangle_kwargs)\n",
    "\n",
    "\n",
    "# in a specific region, and exposing importnat plotting parameters\n",
    "def rectangles_around_dots_ww(dots_bins_df, the_tile, loc=\"upper\", lw=1, ec=\"cyan\", fc=\"none\", halo=30_000, ext_width=0):\n",
    "    rectangle_kwargs = dict(lw=lw, ec=ec, fc=fc)\n",
    "    # parse the tile\n",
    "    _, tspan1, tspan2 = the_tile\n",
    "    # select only visible \"boxes\" :\n",
    "    _the_dots = dots_bins_df \\\n",
    "        .query(\"\"\"(@tspan1[0] - @halo < bin1_id < @tspan1[1] + @halo) & \\\n",
    "                  (@tspan2[0] - @halo < bin2_id < @tspan2[1] + @halo) \"\"\") \\\n",
    "        .eval(\"\"\"\n",
    "                b1 = bin1_id - @tspan1[0] - @ext_width\n",
    "                b2 = bin2_id - @tspan2[0] - @ext_width\n",
    "                bin1_width = bin1_width + @ext_width\n",
    "                bin2_width = bin2_width + @ext_width\n",
    "            \"\"\")\n",
    "    print(f\"{len(_the_dots)} pixels are visible out of {len(dots_bins_df)} ...\")\n",
    "    for b1, b2, w1, w2 in _the_dots[[\"b1\", \"b2\", \"bin1_width\", \"bin2_width\"]].itertuples(index=False):\n",
    "        if loc == \"upper\":\n",
    "            yield patches.Rectangle((b2, b1), w2+1, w1+1, **rectangle_kwargs)\n",
    "        elif loc == \"lower\":\n",
    "            yield patches.Rectangle((b1, b2), w1+1, w2+1, **rectangle_kwargs)\n",
    "        else:\n",
    "            raise ValueError(\"loc has to be uppper or lower\")\n",
    "\n",
    "\n",
    "\n",
    "def annotate_dots_wmotifs(dots_df, motif_df, extend=0):\n",
    "    # ......................................\n",
    "    # check ctcf convergence for the dots ...\n",
    "    def get_converge(_row):\n",
    "        _1, _2 = _row[\"strand1\"], _row[\"strand2\"]\n",
    "        if (\"+\" in _1) and (\"-\" in _2):\n",
    "            return \"conv\"\n",
    "        else:\n",
    "            return \"nonconv\"\n",
    "    # ......................................\n",
    "    ################\n",
    "    _l = bioframe.overlap(\n",
    "        dots_df.eval(\n",
    "            \"\"\"\n",
    "            start1 = start1 - @extend\n",
    "            end1 = end1 + @extend\n",
    "            \"\"\"\n",
    "        ),\n",
    "        motif_df,\n",
    "        return_input=False,\n",
    "        return_index=True,\n",
    "        cols1=(\"chrom1\",\"start1\",\"end1\"),\n",
    "        keep_order=True,\n",
    "    )\n",
    "    # ...\n",
    "    _left_motif = _l.merge(\n",
    "        motif_df[\"strand\"],\n",
    "        how=\"left\",\n",
    "        left_on=\"index_\",\n",
    "        right_index=True,\n",
    "    ) \\\n",
    "    .groupby(\"index\")[\"strand\"] \\\n",
    "    .unique() \\\n",
    "    .rename(\"strand1\")\n",
    "    ################\n",
    "    # ...\n",
    "    ################\n",
    "    _r = bioframe.overlap(\n",
    "        dots_df.eval(\n",
    "            \"\"\"\n",
    "            start1 = start1 - @extend\n",
    "            end1 = end1 + @extend\n",
    "            \"\"\"\n",
    "        ),\n",
    "        motif_df,\n",
    "        return_input=False,\n",
    "        return_index=True,\n",
    "        cols1=(\"chrom2\",\"start2\",\"end2\"),\n",
    "        keep_order=True,\n",
    "    )\n",
    "    # ...\n",
    "    _right_motif = _r.merge(\n",
    "        motif_df[\"strand\"],\n",
    "        how=\"left\",\n",
    "        left_on=\"index_\",\n",
    "        right_index=True,\n",
    "    ) \\\n",
    "    .groupby(\"index\")[\"strand\"] \\\n",
    "    .unique() \\\n",
    "    .rename(\"strand2\")\n",
    "    ################\n",
    "    # ...\n",
    "    # .......... #\n",
    "    return_dots_df = dots_df.merge(\n",
    "        _left_motif,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    # .......... #\n",
    "    return_dots_df = return_dots_df.merge(\n",
    "        _right_motif,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    # ...\n",
    "    print(f\"calculating convergency status for {len(return_dots_df)} ...\")\n",
    "    return_dots_df[\"ctcf_status\"] = return_dots_df.apply(get_converge, axis=1)\n",
    "    return return_dots_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b0852-efbc-4c1a-a810-1dde6fa8b52c",
   "metadata": {},
   "source": [
    "### Chrom arms as a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bioframe to fetch the genomic features from the UCSC.\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "hg38_arms_full = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "# # remove \"bad\" chromosomes and near-empty arms ...\n",
    "# excluded_arms = [\"chr13_p\", \"chr14_p\", \"chr15_p\", \"chr21_p\", \"chr22_p\", \"chrM_p\", \"chrY_p\", \"chrY_q\", \"chrX_p\", \"chrX_q\"]\n",
    "# hg38_arms = hg38_arms_full[~hg38_arms_full[\"name\"].isin(excluded_arms)].reset_index(drop=True)\n",
    "\n",
    "# can do 1 chromosome (or arm) as well ..\n",
    "included_arms = [\"chr1_q\", \"chr2_p\", \"chr4_q\", \"chr6_q\"]\n",
    "included_arms = hg38_arms_full[\"name\"].to_list()[:44] # all autosomal ones ...\n",
    "hg38_arms = hg38_arms_full[hg38_arms_full[\"name\"].isin(included_arms)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e2ee3-e7be-41a8-a068-d1fe16479597",
   "metadata": {},
   "source": [
    "# Load CTCF motifs for dot annotation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c93a5b9-26a5-4ea4-a16d-9cc84b57c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load motifs ...\n",
    "df_motif = pd.read_csv(\n",
    "    \"ctcf_motifs_MA0139.1.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"chrom\", \"start\", \"end\", \"motif\", \"be\", \"ba\", \"strand\"]\n",
    ")\n",
    "display(df_motif.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6131636-4d9f-40ff-9c1a-c83e79fdb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_arm_view(\n",
    "    view_df,\n",
    "    binsize,\n",
    "):\n",
    "    \"\"\"\n",
    "    adjust arm-based view of the genome to fix slightly overlapping p and q arms ...\n",
    "    \"\"\"\n",
    "    _iter_view = view_df.itertuples(index=False)\n",
    "    return pd.DataFrame(\n",
    "        [(c,s+binsize,e,n) if (\"q\" in n) else (c,s,e,n) for c,s,e,n in _iter_view],\n",
    "        columns=hg38_arms.columns\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d774f9-ccbb-4e27-a3a6-2aaa6acc398a",
   "metadata": {},
   "source": [
    "## Now let's get to pileups ! First - calcualte expected for all samples ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6dc2f-bfd6-43c6-ac6e-ff493e493f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_fname_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71d2424-d430-46a8-bcd0-4a653e593daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 kb is a resolution at which one can clearly see \"dots\":\n",
    "binsize = 10_000\n",
    "# cooler files that we'll work on :\n",
    "sample_clrs = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize}\") for _k, _path in clr_fname_dict.items() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8625f6-c88e-42c0-9661-01a5b9635221",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_clrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905258db-c73d-40a5-977a-027ed1525268",
   "metadata": {},
   "source": [
    "# cis-expected first @10kb ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c774ee1-7d0c-45ff-80a2-f77650e71e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_samples = ['pG1s_MEGA', 'Ms_MEGA', 'mG1s_MEGA', 'dldmicroc']\n",
    "key_samples = ['mG1s_MEGA', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b9747-60b4-4598-94a6-cee94aed0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _job(packed_data, sample):\n",
    "    # packed data -> exp_kwargs and a dict with coolers for each sample\n",
    "    exp_kwargs, clr_dict = packed_data\n",
    "    _clr = clr_dict[sample]\n",
    "    # in order to use spawn/forkserver we have to import for worker\n",
    "    from cooltools import expected_cis\n",
    "    _exp = expected_cis( _clr, **exp_kwargs)\n",
    "    return (sample, _exp)\n",
    "\n",
    "# define expected parameters in the form of kwargs-dict:\n",
    "exp_kwargs = dict(\n",
    "    view_df=hg38_arms,  #  adjust_arm_view(hg38_arms, binsize),\n",
    "    intra_only=False,\n",
    "    nproc=12\n",
    ")\n",
    "\n",
    "# have to use daemon=False, because _job is multiprocessing-based already ...\n",
    "with WorkerPool(\n",
    "    n_jobs=8,\n",
    "    daemon=False,\n",
    "    shared_objects=( exp_kwargs, sample_clrs ),\n",
    "    start_method=\"forkserver\",  # little faster than spawn, fork is the fastest\n",
    "    use_dill=True,\n",
    ") as wpool:\n",
    "    results = wpool.map(_job, sample_clrs, progress_bar=True)\n",
    "\n",
    "# sort out the results ...\n",
    "sample_exp_cis = {sample: _exp for sample, _exp in results}\n",
    "# # old way of doing it\n",
    "# telo_exps_cis = {k: cooltools.expected_cis( _clr, **exp_kwargs) for k, _clr in sample_clrs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760aba61",
   "metadata": {},
   "source": [
    "## dot calling ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef656a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grid of coordinates from -5 to 5, to define round kernels\n",
    "# see https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html for details\n",
    "half = 5  # half width of the kernel\n",
    "x, y = np.meshgrid(\n",
    "    np.linspace(-half, half, 2*half + 1),\n",
    "    np.linspace(-half, half, 2*half + 1),\n",
    ")\n",
    "# define inner and outer radii ...\n",
    "inner_raius_squared = 7\n",
    "outer_radius_squared = 38\n",
    "inner_raius_squared = 7\n",
    "outer_radius_squared = 38\n",
    "\n",
    "# now define a donut-like mask as pixels between 2 radii: sqrt(7) and sqrt(30):\n",
    "mask = (x**2+y**2 > inner_raius_squared) \\\n",
    "    & (x**2+y**2 <= outer_radius_squared)\n",
    "mask[:,half] = 0\n",
    "mask[half,:] = 0\n",
    "\n",
    "# lowleft mask - zero out neccessary parts\n",
    "mask_ll = mask.copy()\n",
    "mask_ll[:,:half] = 0\n",
    "mask_ll[half:,:] = 0\n",
    "\n",
    "# vertical mask\n",
    "mask_vv = (x>-2) & (x<2) & (x**2+y**2 > inner_raius_squared-1)\n",
    "# horizontal mask\n",
    "mask_hh = (y>-2) & (y<2) & (x**2+y**2 > inner_raius_squared-1)\n",
    "\n",
    "# new kernels with more round donut and lowleft masks:\n",
    "kernels_round = {'donut': mask,\n",
    " 'vertical': mask_vv,\n",
    " 'horizontal': mask_hh,\n",
    " 'lowleft': mask_ll}\n",
    "\n",
    "# plot rounded kernels\n",
    "fig, axs = plt.subplots(ncols=4, figsize=(12,2.5))\n",
    "for ax, (ktype, kernel) in zip(axs, kernels_round.items()):\n",
    "    imk = draw_kernel(kernel, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46861c0",
   "metadata": {},
   "source": [
    "### dots on ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and organize expecteds:\n",
    "dots_dict = {}\n",
    "dots_kwargs = dict(\n",
    "    view_df=hg38_arms,\n",
    "    kernels=kernels_round,\n",
    "    # expected_value_col=\"balanced.avg.smoothed\",\n",
    "    expected_value_col=\"balanced.avg\",\n",
    "    # how far from the main diagonal to call dots:\n",
    "    max_loci_separation=15_000_000,\n",
    "    # lambda_bin_fdr=0.1,\n",
    "    max_nans_tolerated=6,\n",
    "    clustering_radius=21_000,\n",
    "    cluster_filtering=False,\n",
    "    tile_size=10_000_000,\n",
    "    nproc=32\n",
    ")\n",
    "# ...\n",
    "for sample in key_samples:\n",
    "    clr = sample_clrs[sample]\n",
    "    exp = sample_exp_cis[sample]\n",
    "    print(f\"calling dots for {sample} ...\")\n",
    "    dots_dict[sample] = cooltools.dots( clr, expected=exp, **dots_kwargs)\n",
    "# ...\n",
    "for sample, dots_df in dots_dict.items():\n",
    "    print(f\"{sample} has {len(dots_df)} dots \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a3ff4",
   "metadata": {},
   "source": [
    "#### number of dots - i.e. centroids of the clusters of enriched pixels\n",
    "```\n",
    "N93mR1 has 16405 dots \n",
    "N93pR1 has 763 dots \n",
    "RGmR1 has 16808 dots \n",
    "RGmR1R2 has 22232 dots \n",
    "RGmR2 has 14469 dots \n",
    "RGpR1 has 1799 dots \n",
    "RGpR1R2 has 4769 dots \n",
    "RGpR2 has 976 dots \n",
    "RGmR1-10h has 7779 dots \n",
    "RGpR1-10h has 575 dots \n",
    "RGmpR1-10h has 6837 dots \n",
    "```\n",
    "#### before clustering ... - just number of enriched pixels\n",
    "```\n",
    " N93mR1 has 40795 dots \n",
    " N93pR1 has 1004 dots \n",
    " RGmR1 has 44001 dots \n",
    " RGmR1R2 has 64080 dots \n",
    " RGmR2 has 34171 dots \n",
    " RGpR1 has 2537 dots \n",
    " RGpR1R2 has 6616 dots \n",
    " RGpR2 has 1304 dots \n",
    " RGmR1-10h has 15468 dots \n",
    " RGpR1-10h has 706 dots \n",
    " RGmpR1-10h has 11951 dots\n",
    "```\n",
    "\n",
    "#### ...\n",
    "```\n",
    "    mMito has 48 dots \n",
    "    mTelo has 2667 dots \n",
    "    mCyto has 8170 dots \n",
    "    m5hR1R2 has 22192 dots \n",
    "    m10hR1R2 has 22487 dots \n",
    "    pMito has 451 dots \n",
    "    pTelo has 1314 dots \n",
    "    pCyto has 3187 dots \n",
    "    p5hR1R2 has 4757 dots \n",
    "    p10hR1R2 has 7395 dots \n",
    "```\n",
    "\n",
    "\n",
    "#### ...\n",
    "```\n",
    "pG1s_MEGA has 18077 dots \n",
    "Ms_MEGA has 713 dots \n",
    "mG1s_MEGA has 27373 dots \n",
    "dldmicroc has 20430 dots\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34ac21",
   "metadata": {},
   "source": [
    "### Make sure they look reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde48bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a region to look into as an example\n",
    "start = 27_275_000 - 2_500_000\n",
    "end = start + 5_000_000\n",
    "start = 27_275_000 - 1_600_000 - 500_000\n",
    "end = start + 2_500_000 + 1_000_000\n",
    "region = ('chr7', start, end)\n",
    "\n",
    "# heatmap kwargs\n",
    "matshow_kwargs = dict(\n",
    "    cmap='YlOrBr',\n",
    "    norm=LogNorm(vmax=0.05),\n",
    "    extent=(start, end, end, start)\n",
    ")\n",
    "\n",
    "# colorbar kwargs\n",
    "colorbar_kwargs = dict(fraction=0.046, label='corrected frequencies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572088f0-f718-495e-babb-ce07ffdafcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a way to check how many dots are singletons and vice a versa\n",
    "dots_dict['mG1s_MEGA'][\"c_size\"].value_counts().sort_index().iloc[:2]\n",
    "\n",
    "# testing filtration ...\n",
    "_sample = \"mG1s_MEGA\"\n",
    "_clr = sample_clrs[_sample]\n",
    "_dots = dots_dict['mG1s_MEGA']\n",
    "\n",
    "\n",
    "# compute heatmap for the region\n",
    "region_matrix = _clr.matrix(balance=True).fetch(region)\n",
    "for diag in [-1,0,1]:\n",
    "    region_matrix = fill_diag(region_matrix, np.nan, i=diag)\n",
    "\n",
    "# see viz.ipynb for details of heatmap visualization\n",
    "f, ax = plt.subplots(figsize=(7,7))\n",
    "im = ax.matshow( region_matrix, **matshow_kwargs)\n",
    "format_ticks(ax, rotate=False)\n",
    "plt.colorbar(im, ax=ax, **colorbar_kwargs)\n",
    "\n",
    "for box in rectangles_around_dots(_dots, region, lw=1.0, ec=\"black\"):\n",
    "    ax.add_patch(box)\n",
    "#\n",
    "ax.set_title(_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cddb381-0cac-4718-b883-202dad8fc09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_filter_kwargs = dict(\n",
    "    obs_raw_name='count',\n",
    "    enrichment_factor_vh=1.2,\n",
    "    enrichment_factor_d_and_ll=1.5,\n",
    "    enrichment_factor_d_or_ll=1.5,\n",
    "    FDR_orphan_threshold=0.0079,\n",
    ")\n",
    "\n",
    "# testing filtration ...\n",
    "_sample = \"mG1s_MEGA\"\n",
    "_clr = sample_clrs[_sample]\n",
    "_dots = dots_dict['mG1s_MEGA']\n",
    "print(f\"number of dots BEFORE filtration {len(_dots)}\")\n",
    "print(_dots[\"c_size\"].value_counts().sort_index().iloc[:5])\n",
    "_dots = cooltools.api.dotfinder.cluster_filtering_hiccups( dots_dict['mG1s_MEGA'], **dot_filter_kwargs)\n",
    "print(f\"number of dots AFTER filtration {len(_dots)}\")\n",
    "print(_dots[\"c_size\"].value_counts().sort_index().iloc[:5])\n",
    "\n",
    "_dots_ctcf = annotate_dots_wmotifs(_dots, df_motif, extend=1_000)\n",
    "print(f\"dots by ctcf status ...\")\n",
    "display(_dots_ctcf[\"ctcf_status\"].value_counts())\n",
    "_dots_conv = bioframe.sort_bedframe(\n",
    "    _dots_ctcf.query(\"ctcf_status == 'conv'\").reset_index(drop=True),\n",
    "    view_df=hg38_arms_full,\n",
    "    cols=(\"chrom1\",\"start1\",\"end1\")\n",
    ").reset_index(drop=True).drop(columns=[\"strand1\",\"strand2\",\"ctcf_status\"])\n",
    "print(_dots_conv[\"c_size\"].value_counts().sort_index().iloc[:5])\n",
    "\n",
    "\n",
    "# decide which dots are final ...\n",
    "_final_dots = _dots_conv\n",
    "\n",
    "# compute heatmap for the region\n",
    "region_matrix = _clr.matrix(balance=True).fetch(region)\n",
    "for diag in [-1,0,1]:\n",
    "    region_matrix = fill_diag(region_matrix, np.nan, i=diag)\n",
    "\n",
    "\n",
    "# see viz.ipynb for details of heatmap visualization\n",
    "f, ax = plt.subplots(figsize=(7,7))\n",
    "im = ax.matshow( region_matrix, **matshow_kwargs)\n",
    "format_ticks(ax, rotate=False)\n",
    "plt.colorbar(im, ax=ax, **colorbar_kwargs)\n",
    "\n",
    "for box in rectangles_around_dots(_dots, region, lw=1.0, ec=\"black\"):\n",
    "    ax.add_patch(box)\n",
    "#\n",
    "ax.set_title(f\"{_sample} - before ctcf filtering\")\n",
    "\n",
    "# see viz.ipynb for details of heatmap visualization\n",
    "f, ax = plt.subplots(figsize=(7,7))\n",
    "im = ax.matshow( region_matrix, **matshow_kwargs)\n",
    "format_ticks(ax, rotate=False)\n",
    "plt.colorbar(im, ax=ax, **colorbar_kwargs)\n",
    "\n",
    "for box in rectangles_around_dots(_final_dots, region, lw=1.0, ec=\"black\"):\n",
    "    ax.add_patch(box)\n",
    "#\n",
    "ax.set_title(f\"{_sample} - conv ctcf only\")\n",
    "\n",
    "\n",
    "# dots by distance here ...\n",
    "dist_bins = [0, 200_000, 1_000_000, 5_000_000, 10_000_000, 30_000_000]\n",
    "dist_bins = [0, 500_000, 2_000_000, 7_000_000, 30_000_000]\n",
    "#\n",
    "# for sample, _dots in dots_dict.items():\n",
    "for sample, _dots in {\"final\": _final_dots, \"ctcf_agnostic\": _dots_ctcf}.items():\n",
    "    print(sample)\n",
    "    print(_dots.groupby(pd.cut(_dots.eval(\"start2 - start1\"),bins=dist_bins)).size())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab12369-773c-4b64-8754-65565bb54171",
   "metadata": {},
   "source": [
    "# Save lists of dots after processing, filtering etc etc ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6caa5-0403-4ca1-a50e-fb82d92de999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _sample, _dots in dots_dict.items():\n",
    "#     _dots = dots_dict[_sample]\n",
    "#     # print(f\"number of dots BEFORE filtration {len(_dots)}\")\n",
    "#     # print(_dots[\"c_size\"].value_counts().sort_index().iloc[:5])\n",
    "#     _dots = cooltools.api.dotfinder.cluster_filtering_hiccups(_dots, **dot_filter_kwargs)\n",
    "#     # print(f\"number of dots AFTER filtration {len(_dots)}\")\n",
    "#     # print(_dots[\"c_size\"].value_counts().sort_index().iloc[:5])\n",
    "#     _dots\\\n",
    "#     .drop(columns=[\"region1\",\"region2\",\"region\"]) \\\n",
    "#     .to_csv(f\"./dots_10kb_MEGA_filtered_samples/{_sample}_10kb_wheader.bedpe\",sep=\"\\t\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "# save such double filtered dots separately to share ...\n",
    "if True:\n",
    "    # ...\n",
    "    #(...)# \"dots_10kb_MEGA_filtered_samples/mG1s_MEGA_10kb_wheader.bedpe\"\n",
    "    _dots_ctcf[[\n",
    "        'chrom1', 'start1', 'end1', 'chrom2', 'start2', 'end2', 'count',\n",
    "       'la_exp.donut.value', 'la_exp.vertical.value',\n",
    "       'la_exp.horizontal.value', 'la_exp.lowleft.value', 'la_exp.donut.qval',\n",
    "       'la_exp.vertical.qval', 'la_exp.horizontal.qval', 'la_exp.lowleft.qval',\n",
    "       'cstart1', 'cstart2', 'c_label', 'c_size', 'ctcf_status'\n",
    "    ]].to_csv(\n",
    "        \"dots_10kb_MEGA_final/mG1s_MEGA_10kb_wheader_CTCF_annotation.bedpe\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )\n",
    "    # ...\n",
    "    #(...)# \"dots_10kb_MEGA_filtered_samples/mG1s_MEGA_10kb_wheader.bedpe\"\n",
    "    _dots_conv[[\n",
    "        'chrom1', 'start1', 'end1', 'chrom2', 'start2', 'end2', 'count',\n",
    "       'la_exp.donut.value', 'la_exp.vertical.value',\n",
    "       'la_exp.horizontal.value', 'la_exp.lowleft.value', 'la_exp.donut.qval',\n",
    "       'la_exp.vertical.qval', 'la_exp.horizontal.qval', 'la_exp.lowleft.qval',\n",
    "       'cstart1', 'cstart2', 'c_label', 'c_size'\n",
    "    ]].to_csv(\n",
    "        \"dots_10kb_MEGA_final/mG1s_MEGA_10kb_wheader_convergent.bedpe\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414e777-3390-4a34-b835-53f7041f3b37",
   "metadata": {},
   "source": [
    "# Generate the domains using the final dots\n",
    "## (filtered hiccups-stype and by ctcf-convergence) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f459618-96c3-43c4-8ffd-3407e1a87555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # domains using middle of the dot coordinate ...\n",
    "# domains using outter dot-coordinate ...\n",
    "_the_dots_filtered = _final_dots.query(\"end2 - end1 <= 3_500_000\").reset_index(drop=True)\n",
    "print(f\"number of dots before filtering {len(_final_dots)} ... and after {len(_the_dots_filtered)} ...\")\n",
    "\n",
    "# the NEW way of getting domains ...\n",
    "# for a given cluster - get min start1/end1 coord, and max start2/end2 coord:\n",
    "_clust = bioframe.cluster(\n",
    "    _the_dots_filtered,\n",
    "    min_dist=21_000,\n",
    "    cols=(\"chrom1\", \"start1\", \"end1\"),\n",
    "    return_input=True,\n",
    "    return_cluster_ids=True,\n",
    ")\n",
    "_index2 = _clust.groupby(\"cluster\")[\"start2\"].idxmax()\n",
    "_index1 = _clust.groupby(\"cluster\")[\"start1\"].idxmin()\n",
    "# now construct a BedFrame for the nested merge ...\n",
    "_pre_domains = pd.DataFrame({\n",
    "    \"chrom\": _the_dots_filtered.loc[_index1, \"chrom1\"].to_numpy(),\n",
    "    \"start\": _the_dots_filtered.loc[_index1, \"start1\"].to_numpy(),\n",
    "    \"end\": _the_dots_filtered.loc[_index2, \"end2\"].to_numpy(),\n",
    "})\n",
    "# _domains = _pre_domains\n",
    "_domains = merge_nested(\n",
    "    # pre-filter super long range dots, as they include translocations ...\n",
    "    _pre_domains,\n",
    "    # merge \"touching\" domains or not ...\n",
    "    overlap_frac=0.735,\n",
    ")\n",
    "\n",
    "# clustering and merging operations do not preserve chrom order ...\n",
    "_domains = bioframe.sort_bedframe(\n",
    "    _domains,\n",
    "    view_df=hg38_arms_full,\n",
    "    # cols=(\"chrom1\",\"start1\",\"end1\")\n",
    ")\n",
    "# print(_domains)\n",
    "\n",
    "f, axs = plt.subplots(ncols=2, figsize=(9,4))\n",
    "# _bins = np.r_[0,np.geomspace(100_000, 30_000_000, 100)]\n",
    "_bins = np.linspace(0, 6_000_000, 25)\n",
    "\n",
    "# check out domain size distribution\n",
    "_domains.eval(\"end - start\").hist(bins=_bins, ax=axs[0], log=True)\n",
    "axs[0].set_title(\"domain size distribution\")\n",
    "# axs[0].set_xscale(\"log\")\n",
    "\n",
    "# inter-domain distances ...\n",
    "_inter_domain_cis = (_domains.shift(-1)[\"chrom\"] == _domains[\"chrom\"])\n",
    "(_domains.shift(-1)[\"start\"] - _domains[\"end\"])[_inter_domain_cis].hist(bins=_bins, ax=axs[1], log=True)\n",
    "axs[1].set_title(\"inter-domain distance distribution\")\n",
    "# axs[1].set_xscale(\"log\")\n",
    "\n",
    "# distribution of dot sizes ...\n",
    "_final_dots.eval(\"end2-end1\").hist(bins=_bins, histtype=\"step\", linewidth=3, ax=axs[0], label=\"dot sizes\")\n",
    "axs[0].legend(frameon=False)\n",
    "\n",
    "axs[0].set_xlabel(\"size, MB\")\n",
    "axs[1].set_xlabel(\"size, MB\")\n",
    "\n",
    "# _domains\n",
    "print(f\"number of detected domains {len(_domains)} ...\")\n",
    "\n",
    "if True:\n",
    "    # save domains to a file !!!!\n",
    "    _domains.to_csv(\n",
    "        \"extrusion_domains/mG1s_MEGA_10kb_double_filtered.bedpe\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a6729-8cd7-429e-8a4d-258c76d5387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb178380-cdc0-41d3-a9e2-5d4a1ace63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate domain defining dots ...\n",
    "_region1 = ('chr7', 27_275_000-3_750_000, 27_275_000+3_750_000)\n",
    "# _region1 = ('chr7', 38_000_000, 38_000_000+12_500_000)\n",
    "# # _region2 = ('chr7', 38_000_000, 38_000_000+12_500_000)\n",
    "# # _region1 = ('chr7', 20_500_000, 20_500_000+12_500_000)\n",
    "# # _region2 = ('chr7', 20_500_000, 20_500_000+12_500_000)\n",
    "# _region1 = (_chrom, _start-1_500_000, _end+1_500_000)\n",
    "# _region1 = ('chr1', 28_500_000-3_500_000, 28_910_000+3_500_000)\n",
    "_region2 = _region1\n",
    "\n",
    "# domains within selected region - turn it back to bedpe ...\n",
    "_domains_region = \\\n",
    "_domains.eval(\"\"\"\n",
    "    chrom1 = chrom\n",
    "    chrom2 = chrom\n",
    "    start1 = start\n",
    "    end1 = start + 10_000\n",
    "    start2 = end - 10_000\n",
    "    end2 = end\n",
    "\"\"\")[['chrom1', 'start1', 'end1', 'chrom2', 'start2', 'end2']]#, 'n_intervals']]\n",
    "\n",
    "# select domains in the region ...\n",
    "_domains_region = bioframe.select(\n",
    "    bioframe.select(_domains_region, _region1, cols=(\"chrom1\",\"start1\",\"end1\")),\n",
    "    _region2, cols=(\"chrom2\",\"start2\",\"end2\"),\n",
    ").reset_index(drop=True)\n",
    "_domains_region[\"bin1_id\"] = _domains_region[[\"chrom1\",\"start1\",\"end1\"]].apply(_clr.offset,axis=1,result_type=\"expand\")\n",
    "_domains_region[\"bin1_width\"] = _domains_region[[\"chrom1\",\"start1\",\"end1\"]].apply(_clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "_domains_region[\"bin2_id\"] = _domains_region[[\"chrom2\",\"start2\",\"end2\"]].apply(_clr.offset,axis=1,result_type=\"expand\")\n",
    "_domains_region[\"bin2_width\"] = _domains_region[[\"chrom2\",\"start2\",\"end2\"]].apply(_clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "\n",
    "# select dots in the region ...\n",
    "_the_dots_region = bioframe.select(\n",
    "    bioframe.select(_final_dots, _region1, cols=(\"chrom1\",\"start1\",\"end1\")),\n",
    "    _region2, cols=(\"chrom2\",\"start2\",\"end2\"),\n",
    ").reset_index(drop=True)\n",
    "_the_dots_region[\"bin1_id\"] = _the_dots_region[[\"chrom1\",\"start1\",\"end1\"]].apply(_clr.offset,axis=1,result_type=\"expand\")\n",
    "_the_dots_region[\"bin1_width\"] = _the_dots_region[[\"chrom1\",\"start1\",\"end1\"]].apply(_clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "_the_dots_region[\"bin2_id\"] = _the_dots_region[[\"chrom2\",\"start2\",\"end2\"]].apply(_clr.offset,axis=1,result_type=\"expand\")\n",
    "_the_dots_region[\"bin2_width\"] = _the_dots_region[[\"chrom2\",\"start2\",\"end2\"]].apply(_clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "region1_name = bioframe.select(hg38_arms, _region1).iat[0,-1]\n",
    "region2_name = bioframe.select(hg38_arms, _region2).iat[0,-1]\n",
    "assert region1_name == region2_name\n",
    "region_name = region2_name\n",
    "\n",
    "tile_span_i = _clr.extent(_region1)\n",
    "tile_span_j = _clr.extent(_region2)\n",
    "_the_tile = (region_name, tile_span_i, tile_span_j )\n",
    "_reg1w = np.diff(tile_span_i).item()\n",
    "_reg2w = np.diff(tile_span_j).item()\n",
    "\n",
    "# observed matrix slice ...\n",
    "_mat = scipy.ndimage.gaussian_filter(\n",
    "    _clr.matrix()[slice(*tile_span_i), slice(*tile_span_j)],\n",
    "    sigma=0.4,\n",
    "    order=0,\n",
    "    mode='reflect',\n",
    "    cval=0.0,\n",
    "    # radius=3,\n",
    "    truncate=1.0,\n",
    ")\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=0.0001, vmax=0.01),\n",
    "        cmap=\"YlOrBr\",\n",
    "        interpolation=\"nearest\",\n",
    "        # interpolation=\"none\",\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8) )\n",
    "ax.imshow(_mat, **imshow_kwargs)\n",
    "ax.set_xlim(0, _reg2w)\n",
    "ax.set_ylim(_reg1w, 0)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# # draw boxes around clustered pixels ...\n",
    "# _big_boxes_kwargs = dict(loc=\"upper\", lw=1.5, ec=\"k\", fc=\"none\", halo=0, ext_width=0)\n",
    "# for box in rectangles_around_dots_ww( _bedpe_region, _the_tile, **_big_boxes_kwargs ):\n",
    "#     ax.add_patch(box)\n",
    "_big_boxes_kwargs = dict(lw=1.5, ec=\"k\", fc=\"none\", halo=0, ext_width=0)\n",
    "for box in draw_ondiag_domains(_domains_region, _the_tile, **_big_boxes_kwargs):\n",
    "    ax.add_patch(box)\n",
    "# draw boxes around clustered pixels ...\n",
    "_big_boxes_kwargs = dict(loc=\"upper\", lw=1.5, ec=\"blue\", fc=\"none\", halo=0, ext_width=0)\n",
    "for box in rectangles_around_dots_ww( _the_dots_region, _the_tile, **_big_boxes_kwargs ):\n",
    "    ax.add_patch(box)\n",
    "# draw boxes around clustered pixels ...\n",
    "_big_boxes_kwargs = dict(loc=\"upper\", lw=1.5, ec=\"red\", fc=\"none\", halo=0, ext_width=0)\n",
    "for box in rectangles_around_dots_ww( _domains_region, _the_tile, **_big_boxes_kwargs ):\n",
    "    ax.add_patch(box)\n",
    "\n",
    "\n",
    "# # draw boxes around clustered pixels ...\n",
    "# _big_boxes_kwargs = dict(loc=\"upper\", lw=1.5, ec=\"green\", fc=\"none\", halo=0, ext_width=1)\n",
    "# for box in rectangles_around_dots_ww( _select_df_region, _the_tile, **_big_boxes_kwargs ):\n",
    "#     ax.add_patch(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8266ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Saving lists of dots ...\n",
    "# # ! mkdir dots_10kb_MEGA_filtered_samples\n",
    "# for _sample, _dots in dots_dict.items():\n",
    "#     _dots = dots_dict[_sample]\n",
    "#     # print(f\"number of dots BEFORE filtration {len(_dots)}\")\n",
    "#     # print(_dots[\"c_size\"].value_counts().sort_index().iloc[:5])\n",
    "#     _dots = cooltools.api.dotfinder.cluster_filtering_hiccups(\n",
    "#         _dots,\n",
    "#         obs_raw_name='count',\n",
    "#         enrichment_factor_vh=1.0,\n",
    "#         enrichment_factor_d_and_ll=1.0,\n",
    "#         enrichment_factor_d_or_ll=1.0,\n",
    "#         # FDR_orphan_threshold=0.00785,\n",
    "#         FDR_orphan_threshold=0.0075,\n",
    "#     )\n",
    "#     # print(f\"number of dots AFTER filtration {len(_dots)}\")\n",
    "#     # print(_dots[\"c_size\"].value_counts().sort_index().iloc[:5])\n",
    "#     _dots\\\n",
    "#     .drop(columns=[\"region1\",\"region2\",\"region\"]) \\\n",
    "#     .to_csv(f\"./dots_10kb_MEGA_filtered_samples/{_sample}_10kb_wheader.bedpe\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1e9d1-c468-4161-8de7-27ab609f682b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30373c-4945-4702-a5cd-0bb7a21e7957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debd536-13c6-4dbf-a076-466dda2126d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06840040-e35e-4486-8776-1f44526cdeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15b9af-0313-48aa-83e1-b92d9c72664e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed8262-e4fd-4f06-a4c2-eaa4d64eeef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921cc9b-bb46-41a3-9947-173ea96ca02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0206b9-5863-4728-a0d0-017cadf68f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ea9b2-5238-4bb5-8e58-c2e803c7bd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6dbd8-cdf7-4290-890f-d4b28df50f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d9f80-b7b3-45b0-9046-67c0a57a5960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f57ca-c899-41a1-81af-5abab38b7437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81ca23-16a8-4ae4-937f-beed734b5eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841b86c-b496-48dc-af55-cea045d3c11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f6770-0b77-42ab-9b19-24232489853c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7da91-a4be-4731-bb07-0c066da78309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67b515d1-4b72-4321-87b8-a21ffc8b114d",
   "metadata": {},
   "source": [
    "# Legacy dot exploration is below ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a2be7",
   "metadata": {},
   "source": [
    "### Pileups ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c73379-97f9-4809-85a3-739a67af0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_dict = {\"final\": _final_dots}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample, dots_df in dots_dict.items():\n",
    "    print(f\"{sample} has {len(dots_df)} dots \")\n",
    "# note to myself - cooltools pileup didn't like my dots because they were already annotated ...\n",
    "dots_filter_dict = {}\n",
    "for sample, _dots in dots_dict.items():\n",
    "    dots_filter_dict[sample] = _dots.drop(columns=[\"region1\",\"region2\",\"region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3227ab5-1ba7-424e-87cb-9fa641b4cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_clrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94455ce8-f46d-418a-9c30-31668e7594b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_exp_cis.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb3978-4bf2-4bc0-87f5-a96f0a3cef3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dist_bins = [0, 100_000, 250_000, 500_000, 1_000_000, 2_500_000, 5_000_000, 10_000_000, 20_000_000]\n",
    "\n",
    "# run and organize expecteds:\n",
    "flank=100_000\n",
    "pileup_kwargs = dict(\n",
    "    view_df=hg38_arms,\n",
    "    expected_value_col=\"balanced.avg.smoothed\",\n",
    "    flank=flank,\n",
    "    nproc=32\n",
    ")\n",
    "\n",
    "pups_dist = {}\n",
    "for _sample_dots in key_samples:\n",
    "    print(f\"piling up dots called in {_sample_dots} ...\")\n",
    "    _dots = dots_filter_dict[\"final\"]\n",
    "    pups_dist[_sample_dots] = {}\n",
    "    for _sample_clr in sample_clrs:\n",
    "        print(f\"... using {_sample_clr} cooler ...\")\n",
    "        _clr = sample_clrs[_sample_clr]\n",
    "        pups_dist[_sample_dots][_sample_clr] = {}\n",
    "        _exp = sample_exp_cis[_sample_clr]\n",
    "        if len(_dots) > 1:\n",
    "            _stack = cooltools.pileup( _clr, _dots, expected_df=_exp, **pileup_kwargs)\n",
    "        else:\n",
    "            _stack = np.zeros((2*int(flank/binsize)+1,2*int(flank/binsize)+1,2))\n",
    "        pups_dist[_sample_dots][_sample_clr] = _stack\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941afeb-17e5-4a80-80ae-92d0b2390e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "# grp = _dots.groupby(pd.cut(_dots.eval(\"start2 - start1\"), bins=[0,100_000,250_000,500_000,2_500_000,15_000_000]))\n",
    "grp = _dots.groupby(pd.cut(_dots.eval(\"start2 - start1\"), bins=[0,15_000_000]))\n",
    "# # dist\n",
    "# dist_ranges_index = pd.IntervalIndex.from_arrays(dist_bins[:-1],dist_bins[1:])\n",
    "# _particular_dist_range = dist_ranges_index[2]\n",
    "# print(f\"plotting pileups in distance range {_particular_dist_range} ...\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(grp),ncols=len(sample_clrs),figsize=(14,12),sharex=True,sharey=True)\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "    norm=mpl.colors.LogNorm(1/5,5),\n",
    "    cmap='RdBu_r',\n",
    ")\n",
    "\n",
    "sample_dot = \"mG1s_MEGA\"\n",
    "\n",
    "# for i, sample_dot in enumerate(key_samples):\n",
    "for i, (_name, _grp_df) in enumerate(grp):\n",
    "    # _dots = dots_filter_dict[\"final\"]\n",
    "    # print(len(_dots))\n",
    "    _idx = _grp_df.index\n",
    "    # _idx = np.asarray(_dots.query(\" 2_000_000 < start2 - start1 < 40_000_000\").index)\n",
    "    for j, sample_clr in enumerate(sample_clrs):\n",
    "        ax = axs[j]\n",
    "        # print(pups_dist[sample_dot][sample_clr].shape)\n",
    "        _pup = np.nanmean(pups_dist[sample_dot][sample_clr][_idx], axis=0)\n",
    "        im = ax.imshow( _pup, **imshow_kwargs)\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"clr:{sample_clr}\", fontsize=8)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"set:{sample_dot}\", fontsize=8)\n",
    "\n",
    "ticks_pixels = np.linspace(0, flank*2//binsize,5)\n",
    "ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*binsize//1000).astype(int)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.set_xticks(ticks_pixels)\n",
    "    ax.set_yticks(ticks_pixels)\n",
    "    ax.set_xticklabels(ticks_kbp)\n",
    "    ax.set_yticklabels(ticks_kbp)\n",
    "\n",
    "fig.colorbar(\n",
    "    im,\n",
    "    ax = axs.ravel().tolist(),\n",
    "    label=\"obs/exp\",\n",
    "    ticks=[0.25,1,4],\n",
    ")\n",
    "\n",
    "# fig.colorbar(\n",
    "#     im,\n",
    "#     ax = ax,\n",
    "#     label=\"obs/exp\",\n",
    "#     ticks=[0.25,1,4],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19f8a1-569d-4aad-9416-56597f37cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dist\n",
    "# dist_ranges_index = pd.IntervalIndex.from_arrays(dist_bins[:-1],dist_bins[1:])\n",
    "# _particular_dist_range = dist_ranges_index[2]\n",
    "# print(f\"plotting pileups in distance range {_particular_dist_range} ...\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1,ncols=len(key_samples),figsize=(14,12),sharex=True,sharey=True)\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "    norm=mpl.colors.LogNorm(1/20,20),\n",
    "    cmap='RdBu_r',\n",
    ")\n",
    "\n",
    "for i, sample_dot in enumerate(key_samples):\n",
    "    _dots = dots_filter_dict[\"final\"]\n",
    "    # print(len(_dots))\n",
    "    _idx = np.asarray(_dots.query(\" 2_000_000 < start2 - start1 < 40_000_000\").index)\n",
    "    for j, sample_clr in enumerate(key_samples):\n",
    "        ax = axs#[j]\n",
    "        # print(pups_dist[sample_dot][sample_clr].shape)\n",
    "        _pup = np.nanmean(pups_dist[sample_dot][sample_clr][_idx], axis=0)\n",
    "        im = ax.imshow( _pup, **imshow_kwargs)\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"clr:{sample_clr}\", fontsize=8)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"set:{sample_dot}\", fontsize=8)\n",
    "\n",
    "ticks_pixels = np.linspace(0, flank*2//binsize,5)\n",
    "ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*binsize//1000).astype(int)\n",
    "\n",
    "# for ax in axs.ravel():\n",
    "ax.set_xticks(ticks_pixels)\n",
    "ax.set_yticks(ticks_pixels)\n",
    "ax.set_xticklabels(ticks_kbp)\n",
    "ax.set_yticklabels(ticks_kbp)\n",
    "\n",
    "# fig.colorbar(\n",
    "#     im,\n",
    "#     ax = axs.ravel().tolist(),\n",
    "#     label=\"obs/exp\",\n",
    "#     ticks=[0.25,1,4],\n",
    "# )\n",
    "\n",
    "fig.colorbar(\n",
    "    im,\n",
    "    ax = ax,\n",
    "    label=\"obs/exp\",\n",
    "    ticks=[0.25,1,4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e3773-a9cd-4811-8b0f-1d0a5658e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dist\n",
    "# dist_ranges_index = pd.IntervalIndex.from_arrays(dist_bins[:-1],dist_bins[1:])\n",
    "# _particular_dist_range = dist_ranges_index[2]\n",
    "# print(f\"plotting pileups in distance range {_particular_dist_range} ...\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(key_samples),ncols=len(key_samples),figsize=(14,12),sharex=True,sharey=True)\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "    norm=mpl.colors.LogNorm(1/5,5),\n",
    "    cmap='RdBu_r',\n",
    ")\n",
    "\n",
    "for i, sample_dot in enumerate(key_samples):\n",
    "    _dots = dots_filter_dict[sample_dot]\n",
    "    # print(len(_dots))\n",
    "    _idx = np.asarray(_dots.query(\" 2_000_000 < start2 - start1 < 40_000_000\").index)\n",
    "    for j, sample_clr in enumerate(key_samples):\n",
    "        ax = axs[i,j]\n",
    "        # print(pups_dist[sample_dot][sample_clr].shape)\n",
    "        _pup = np.nanmean(pups_dist[sample_dot][sample_clr][_idx], axis=0)\n",
    "        im = ax.imshow( _pup, **imshow_kwargs)\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"clr:{sample_clr}\", fontsize=8)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"set:{sample_dot}\", fontsize=8)\n",
    "\n",
    "ticks_pixels = np.linspace(0, flank*2//binsize,5)\n",
    "ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*binsize//1000).astype(int)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.set_xticks(ticks_pixels)\n",
    "    ax.set_yticks(ticks_pixels)\n",
    "    ax.set_xticklabels(ticks_kbp)\n",
    "    ax.set_yticklabels(ticks_kbp)\n",
    "\n",
    "fig.colorbar(\n",
    "    im,\n",
    "    ax = axs.ravel().tolist(),\n",
    "    label=\"obs/exp\",\n",
    "    ticks=[0.25,1,4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943980c-dc90-4868-9a7c-db7ec4ff7482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a37fc9-e25b-4ead-bf9d-2b86cb017edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedpe_cols = [\"chrom1\",\n",
    "\"start1\",\n",
    "\"end1\",\n",
    "\"chrom2\",\n",
    "\"start2\",\n",
    "\"end2\",]\n",
    "\n",
    "bedpe_dtype = {\n",
    "\"start1\":int,\n",
    "\"end1\":int,\n",
    "\"start2\":int,\n",
    "\"end2\":int}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81245f8-9599-476e-96ab-12c6c7b87cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7d13a-4783-4f9f-b8b2-fe1c7c9a0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_filter_dict[\"mG1s_MEGA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c946cf8-cda8-4edb-9c8a-fef75b59f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bedpe_to_anchors(\n",
    "    bedpe_df,\n",
    "    view_df,  # for sorting !\n",
    "    cols1 = [\"chrom1\", \"start1\", \"end1\"],\n",
    "    cols2 = [\"chrom2\", \"start2\", \"end2\"],\n",
    "    mode=\"cluster\"\n",
    "):\n",
    "    \"\"\"\n",
    "    turning bedpe interactions to a bed of anchors - the simple way\n",
    "\n",
    "    mode - allow for several way to merge upstream and downstream\n",
    "    anchors. cluster, max_size, max_valency, median\n",
    "    \"\"\"\n",
    "    _cols = [\"chrom\", \"start\", \"end\"]\n",
    "    _cluster_cols = [\"chrom\", \"cluster_start\", \"cluster_end\"]\n",
    "    # concat left and right anchors ...\n",
    "    _bed = pd.concat(\n",
    "        [\n",
    "            bedpe_df[cols1].rename(columns={c1:c for c1,c in zip(cols1, _cols)}),\n",
    "            bedpe_df[cols2].rename(columns={c2:c for c2,c in zip(cols2, _cols)}),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    # clustering anchors - define clusters of overlaping anchors ...\n",
    "    _anchors = bioframe.cluster(\n",
    "        bioframe.sort_bedframe(_bed, view_df=view_df),\n",
    "        min_dist=None,\n",
    "        return_input=True,\n",
    "    ).reset_index(drop=True)\n",
    "    if mode == \"cluster\":\n",
    "        # simply return resulting clusters - i.e. total footprint of clustered anchors ...\n",
    "        _anchors = _anchors.drop_duplicates(subset=_cluster_cols).reset_index(drop=True)\n",
    "        # calculate size just in case\n",
    "        _anchors[\"size\"] = _anchors[_cluster_cols[2]] - _anchors[_cluster_cols[1]]\n",
    "        # return _anchors with coordinates rename as needed !\n",
    "        return _anchors.drop(columns=[\"start\",\"end\"]).rename(columns={\"cluster_start\":\"start\", \"cluster_end\":\"end\"})\n",
    "    elif mode == \"max_size\":\n",
    "        # return the largest anchor per cluster - size of anchors, not clusters !!!\n",
    "        _anchors[\"size\"] = _anchors[_cols[2]] - _anchors[_cols[1]]\n",
    "        _largest_anchor_idx = _anchors.groupby(\"cluster\")[\"size\"].idxmax()\n",
    "        _anchors = _anchors.loc[_largest_anchor_idx]\n",
    "        # return _anchors - i.e. the largest anchor per cluster of overlaping anchors\n",
    "        return _anchors.drop(columns=[\"cluster_start\",\"cluster_end\"]).reset_index(drop=True)\n",
    "    elif mode == \"median\":\n",
    "        # return the of start and end coords per cluster of overlaping anchors ...\n",
    "        _anchors = _anchors.groupby(\"cluster\").agg({\"chrom\":\"first\", \"start\":\"median\", \"end\":\"median\"})\n",
    "        _anchors = _anchors.reset_index().astype({\"start\":int, \"end\":int})\n",
    "        _anchors[\"size\"] = _anchors[_cols[2]] - _anchors[_cols[1]]\n",
    "        # return _anchors - i.e. the largest anchor per cluster of overlaping anchors\n",
    "        return _anchors.reset_index(drop=True)\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d826356-0271-453f-9d74-8fc6129f43b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_filter_dict[\"mG1s_MEGA\"].query(\"chrom1 == 'chr1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dddc746-4f93-4b0a-aeb4-05d63b471b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_filter_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2db92c-581e-4071-9f1b-62c7714e78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedpe_to_anchors(dots_filter_dict[\"mG1s_MEGA\"], hg38_arms)\n",
    "bedpe_to_anchors(dots_filter_dict[\"dldmicroc\"], hg38_arms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175cd234-b6ef-488a-8f2a-c08b09dc2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir dot_anchors_10kb_MEGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ee1b7-feff-415c-b5c3-0ff298d266a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_filter_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76508b-553e-4ecb-884c-497d01b4e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedpe_to_anchors(dots_filter_dict[\"mG1s_MEGA\"], hg38_arms)[[\"chrom\", \"start\", \"end\", \"size\"]] \\\n",
    "    .to_csv(\"./dot_anchors_10kb_MEGA/mG1s_MEGA.bed\",index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980cfdeb-bd4a-4da7-ab0d-6ae9ae3da4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls dot*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78422058-2ac7-4dd5-b2d5-ccc758abe079",
   "metadata": {},
   "source": [
    "# What about other dots and their anchors ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a163087-49f9-4dfa-a7d3-ff2665b2888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls dots_10kb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29ab29-4360-418e-91b5-308e2e698e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_fnames = {\n",
    "    \"mega_ctrl\": \"dots_10kb_MEGA_samples/mG1s_MEGA_10kb_wheader.bedpe\",\n",
    "    \"mega_depl\": \"dots_10kb_MEGA_samples/pG1s_MEGA_10kb_wheader.bedpe\",\n",
    "    \"mega_mito\": \"dots_10kb_MEGA_samples/Ms_MEGA_10kb_wheader.bedpe\",\n",
    "    \"cyto\": \"dots_10kb_samples/mCyto_10kb_wheader.bedpe\",\n",
    "}\n",
    "\n",
    "# let's load them all into a dictionary ...\n",
    "dots_dict = {}\n",
    "for id_name, fname in dot_fnames.items():\n",
    "    dots_dict[id_name] = pd.read_csv(fname, sep=\"\\t\")\n",
    "    # ...\n",
    "    print(f\"loaded {len(dots_dict[id_name]):5d} dots {id_name:>20} in BEDPE format ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9390d-0622-4ef8-a850-e5bbf4fa53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crude_2d_overlap(df1,df2):\n",
    "\n",
    "    df1 = bioframe.expand(df1, pad=2_500, side='both', cols=(\"chrom1\",\"start1\",\"end1\"))\n",
    "    df1 = bioframe.expand(df1, pad=2_500, side='both', cols=(\"chrom2\",\"start2\",\"end2\"))\n",
    "    xxx = bioframe.overlap(\n",
    "        df1[bedpe_cols],\n",
    "        df2[bedpe_cols],\n",
    "        how='left',\n",
    "        return_input=True,\n",
    "        return_index=False,\n",
    "        return_overlap=False,\n",
    "        suffixes=('', '_'),\n",
    "        keep_order=None,\n",
    "        cols1=(\"chrom1\",\"start1\",\"end1\"),\n",
    "        cols2=(\"chrom1\",\"start1\",\"end1\"),\n",
    "        on=None,\n",
    "    )\n",
    "\n",
    "    xxx = xxx[~xxx.isna().any(axis=1)].reset_index(drop=True).astype(bedpe_dtype)\n",
    "    xxx = xxx.drop_duplicates(subset=bedpe_cols).reset_index(drop=True)\n",
    "\n",
    "    yyy = bioframe.overlap(\n",
    "        xxx[bedpe_cols],\n",
    "        df2[bedpe_cols],\n",
    "        how='left',\n",
    "        return_input=True,\n",
    "        return_index=False,\n",
    "        return_overlap=False,\n",
    "        suffixes=('', '_'),\n",
    "        keep_order=None,\n",
    "        cols1=(\"chrom2\",\"start2\",\"end2\"),\n",
    "        cols2=(\"chrom2\",\"start2\",\"end2\"),\n",
    "        on=None,\n",
    "    )\n",
    "\n",
    "    yyy = yyy[~yyy.isna().any(axis=1)].reset_index(drop=True).astype(bedpe_dtype)\n",
    "    yyy = yyy.drop_duplicates(subset=bedpe_cols).reset_index(drop=True)\n",
    "\n",
    "    return len(yyy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d53742-6b5e-4fe5-9b31-d6dbc6693b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = dots_dict[\"mMito\"]\n",
    "# df2 = dots_dict[\"m5hR1R2\"]\n",
    "\n",
    "# xxx = bioframe.overlap(\n",
    "#     df1[bedpe_cols],\n",
    "#     df2[bedpe_cols],\n",
    "#     how='left',\n",
    "#     return_input=True,\n",
    "#     return_index=False,\n",
    "#     return_overlap=False,\n",
    "#     suffixes=('', '_'),\n",
    "#     keep_order=None,\n",
    "#     cols1=(\"chrom1\",\"start1\",\"end1\"),\n",
    "#     cols2=(\"chrom1\",\"start1\",\"end1\"),\n",
    "#     on=None,\n",
    "# )\n",
    "\n",
    "# xxx = xxx[~xxx.isna().any(axis=1)].reset_index(drop=True).astype(bedpe_dtype)\n",
    "\n",
    "# xxx = xxx.drop_duplicates(subset=bedpe_cols).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# yyy = bioframe.overlap(\n",
    "#     xxx[bedpe_cols],\n",
    "#     df2[bedpe_cols],\n",
    "#     how='left',\n",
    "#     return_input=True,\n",
    "#     return_index=False,\n",
    "#     return_overlap=False,\n",
    "#     suffixes=('', '_'),\n",
    "#     keep_order=None,\n",
    "#     cols1=(\"chrom2\",\"start2\",\"end2\"),\n",
    "#     cols2=(\"chrom2\",\"start2\",\"end2\"),\n",
    "#     on=None,\n",
    "# )\n",
    "\n",
    "# yyy = yyy[~yyy.isna().any(axis=1)].reset_index(drop=True).astype(bedpe_dtype)\n",
    "# yyy = yyy.drop_duplicates(subset=bedpe_cols).reset_index(drop=True)\n",
    "\n",
    "# yyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d6951-da93-40e7-a2a7-8d06c821a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = np.zeros((len(pup_samples),len(pup_samples)))\n",
    "\n",
    "for i,s1 in enumerate(pup_samples):\n",
    "    for j,s2 in enumerate(pup_samples):\n",
    "        _num = crude_2d_overlap(dots_dict[s1],dots_dict[s2])\n",
    "        print(f\"{s1}-{s2}: {_num}\")\n",
    "        ccc[i,j] = _num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8614e77f-7e41-4a16-8705-4249669ea469",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ccc)\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(len(pup_samples)))\n",
    "ax.set_yticks(np.arange(len(pup_samples)))\n",
    "\n",
    "ax.set_xticklabels(pup_samples,rotation=90)\n",
    "ax.set_yticklabels(pup_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02207130-3250-48b9-a2e6-0856a3e71bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(ccc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08fd7f-289c-4728-afc1-57c5d3467e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dots_dict[\"mCyto\"]))\n",
    "print(len(dots_dict[\"mTelo\"]))\n",
    "\n",
    "\n",
    "print(crude_2d_overlap(dots_dict[\"mCyto\"],dots_dict[\"mTelo\"]))\n",
    "print(crude_2d_overlap(dots_dict[\"mTelo\"],dots_dict[\"mCyto\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f96009-21c5-47b9-aa25-098f5618a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dots_dict[\"mCyto\"]))\n",
    "print(len(dots_dict[\"mTelo\"]))\n",
    "\n",
    "\n",
    "xxx = bioframe.overlap(\n",
    "    dots_dict[\"mCyto\"][bedpe_cols],\n",
    "    dots_dict[\"mTelo\"][bedpe_cols],\n",
    "    how='left',\n",
    "    return_input=True,\n",
    "    return_index=False,\n",
    "    return_overlap=False,\n",
    "    suffixes=('', '_'),\n",
    "    keep_order=None,\n",
    "    cols1=(\"chrom1\",\"start1\",\"end1\"),\n",
    "    cols2=(\"chrom1\",\"start1\",\"end1\"),\n",
    "    on=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882fedc-eea4-4527-9c6b-afbbcad1d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(xxx[~xxx.isna().any(axis=1)].astype(bedpe_dtype)))\n",
    "\n",
    "\n",
    "\n",
    "yyy = bioframe.overlap(\n",
    "    xxx[~xxx.isna().any(axis=1)].astype(bedpe_dtype)[bedpe_cols],\n",
    "    dots_dict[\"mTelo\"][bedpe_cols],\n",
    "    how='left',\n",
    "    return_input=True,\n",
    "    return_index=False,\n",
    "    return_overlap=False,\n",
    "    suffixes=('', '_'),\n",
    "    keep_order=None,\n",
    "    cols1=(\"chrom2\",\"start2\",\"end2\"),\n",
    "    cols2=(\"chrom2\",\"start2\",\"end2\"),\n",
    "    on=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97724079-1fa2-44a9-ac75-488ab6157e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy[~yyy.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e717e-45b5-44d1-99a7-8071f58451b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dots_dict[\"mTelo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb478b77-3638-4327-ac1a-34cb6a786f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_dict[\"mCyto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ec50b-3721-4416-86dd-ed6df768c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"chrom1\",\n",
    "\"start1\",\n",
    "\"end1\",\n",
    "\"chrom2\",\n",
    "\"start2\",\n",
    "\"end2\","
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
