{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adeb24e-aa19-490c-bfc3-16b011e36a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from saddle import saddleplot\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "# Hi-C utilities imports:\n",
    "import cooler\n",
    "import bioframe\n",
    "import cooltools\n",
    "from cooltools.lib.numutils import fill_diag\n",
    "\n",
    "# Visualization imports:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import EngFormatter\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "# from ipywidgets import interact, fixed\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb4552-d8be-4c72-b14e-c95bb44b12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jscatter\n",
    "import scipy\n",
    "import logging\n",
    "import multiprocess as mp\n",
    "# bbi for stackups ...\n",
    "import bbi\n",
    "\n",
    "# functions and assets specific to this repo/project ...\n",
    "from data_catalog import bws, bws_vlim, telo_dict, mega_telo_dict, pubclr_dict\n",
    "from helper_func import (\n",
    "    get_stack,\n",
    "    show_stacks,\n",
    "    plot_stackups_lite,\n",
    "    plot_stackups_sets,\n",
    "    to_bigbed3,\n",
    "    merge_nested,\n",
    ")\n",
    "# from mypileup_module import trans_pileup\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import warnings\n",
    "import h5py\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import ConnectionPatch, Rectangle\n",
    "from mpl_toolkits.axes_grid1 import Divider, Size\n",
    "from mpl_toolkits.axes_grid1.inset_locator import BboxConnector\n",
    "from matplotlib import cm\n",
    "# from mpl_toolkits.axes_grid1.Size import Fixed\n",
    "\n",
    "\n",
    "# enable editable text ...\n",
    "mpl.rcParams[\"pdf.fonttype\"]=42\n",
    "mpl.rcParams[\"svg.fonttype\"]=\"none\"\n",
    "mpl.rcParams['axes.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6bd5ad-6fbd-4054-b972-0c02c654a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a specific region, and exposing importnat plotting parameters\n",
    "def rectangles_around_dots_ww(dots_bins_df, the_tile, loc=\"upper\", lw=1, ec=\"cyan\", fc=\"none\", halo=30_000, ext_width=0):\n",
    "    rectangle_kwargs = dict(lw=lw, ec=ec, fc=fc)\n",
    "    # parse the tile\n",
    "    _, tspan1, tspan2 = the_tile\n",
    "    # select only visible \"boxes\" :\n",
    "    _the_dots = dots_bins_df \\\n",
    "        .query(\"\"\"(@tspan1[0] - @halo < bin1_id < @tspan1[1] + @halo) & \\\n",
    "                  (@tspan2[0] - @halo < bin2_id < @tspan2[1] + @halo) \"\"\") \\\n",
    "        .eval(\"\"\"\n",
    "                b1 = bin1_id - @tspan1[0] - @ext_width\n",
    "                b2 = bin2_id - @tspan2[0] - @ext_width\n",
    "                bin1_width = bin1_width + @ext_width\n",
    "                bin2_width = bin2_width + @ext_width\n",
    "            \"\"\")\n",
    "    print(f\"{len(_the_dots)} pixels are visible out of {len(dots_bins_df)} ...\")\n",
    "    for b1, b2, w1, w2 in _the_dots[[\"b1\", \"b2\", \"bin1_width\", \"bin2_width\"]].itertuples(index=False):\n",
    "        if loc == \"upper\":\n",
    "            yield patches.Rectangle((b2, b1), w2+1, w1+1, **rectangle_kwargs)\n",
    "        elif loc == \"lower\":\n",
    "            yield patches.Rectangle((b1, b2), w1+1, w2+1, **rectangle_kwargs)\n",
    "        else:\n",
    "            raise ValueError(\"loc has to be uppper or lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d182b96d-0947-4a69-8283-3a8e533c72e7",
   "metadata": {},
   "source": [
    "# Pre-define relevant coolers just in case ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb55c46f-4b70-4b4a-a066-a87f611ea200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cooler files that we'll work on :\n",
    "binsize10 = 10_000\n",
    "telo_clrs10 = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize10}\") for _k, _path in telo_dict.items() }\n",
    "\n",
    "# cooler files that we'll work on :\n",
    "binsize25 = 25_000\n",
    "telo_clrs25 = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize25}\") for _k, _path in telo_dict.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef645cb-8dec-414b-87cc-32a4cbd2981d",
   "metadata": {},
   "source": [
    "# Chrom arms as a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5689161-6ec4-4d74-911d-70479f0d1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bioframe to fetch the genomic features from the UCSC.\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "hg38_arms_full = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "# # remove \"bad\" chromosomes and near-empty arms ...\n",
    "# excluded_arms = [\"chr13_p\", \"chr14_p\", \"chr15_p\", \"chr21_p\", \"chr22_p\", \"chrM_p\", \"chrY_p\", \"chrY_q\", \"chrX_p\", \"chrX_q\"]\n",
    "# hg38_arms = hg38_arms_full[~hg38_arms_full[\"name\"].isin(excluded_arms)].reset_index(drop=True)\n",
    "\n",
    "# can do 1 chromosome (or arm) as well ..\n",
    "included_arms = hg38_arms_full[\"name\"].to_list()[:44] # all autosomal ones ...\n",
    "hg38_arms = hg38_arms_full[hg38_arms_full[\"name\"].isin(included_arms)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76e50c-9801-4dee-b60e-9cb961cb4996",
   "metadata": {},
   "source": [
    "# There is a problem with our arms view of the chromosomes ...\n",
    "\n",
    "the way we do it now - end of p-arm is alsways equal to the start of q-arm ...\n",
    "\n",
    "After binning this could lead to the situation where last bin of p-arm is upstream of the first q-arm bin ...\n",
    "\n",
    "This makes `cooltools.api.is_valid_expected` crash ...\n",
    "\n",
    "Let's try solving that by adding 1 bp to the start of every q-arm ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa513d-c94f-41e0-9cd5-7d6543d3c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_arm_view(\n",
    "    view_df,\n",
    "    binsize,\n",
    "):\n",
    "    \"\"\"\n",
    "    adjust arm-based view of the genome to fix slightly overlapping p and q arms ...\n",
    "    \"\"\"\n",
    "    _iter_view = view_df.itertuples(index=False)\n",
    "    return pd.DataFrame(\n",
    "        [(c,s+binsize,e,n) if (\"q\" in n) else (c,s,e,n) for c,s,e,n in _iter_view],\n",
    "        columns=hg38_arms.columns\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4ef7a-e9fd-4523-a312-ce7a4699c10c",
   "metadata": {},
   "source": [
    "### Read pre-called native compartments\n",
    "## ... and Pick one list of anchors and annotate it with epigenetic marks ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bfd74-7d0f-483b-9061-9d061e14c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_anchor_fnames = {\n",
    "    \"mega_2X_enrichment\": \"ID_anchors/mega_2X_enrichment.fourth_mega.max_size.bed\",\n",
    "    \"5hr_2X_enrichment_old\": \"ID_anchors/5hr_2X_enrichment.second_bulk.max_size.bed\",\n",
    "    \"5hr_2X_enrichment\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.bed\",\n",
    "    \"5hr_2X_enrichment_nosing\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.no_singletons.bed\",\n",
    "    \"5hr_notinCyto_2X_enrichment_signal\": \"ID_anchors/p5notin_pCyto_anchors_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"5hr_2X_enrichment_signal\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"10hr_2X_enrichment_signal\": \"ID_anchors/10hrs_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"N93p5_2X_enrichment_signal\": \"ID_anchors/N93p5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"pCyto_2X_enrichment_signal\": \"ID_anchors/pCyto_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"mCyto_2X_enrichment_signal\": \"ID_anchors/mCyto_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"mega_3X_enrichment\": \"ID_anchors/mega_3X_enrichment.fifth_mega3x.max_size.bed\",\n",
    "    \"MEGA_2X_enrichment\": \"ID_anchors/MEGAp5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGA_weaker_2X_enrichment\": \"ID_anchors/MEGA_plus_weak_anchors_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGAN93_2X_enrichment\": \"ID_anchors/MEGAN93p5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGAminus_2X_enrichment\": \"ID_anchors/MEGA_minus_ctrl_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"cyto_2x_enrichment\": \"ID_anchors/cyto_2x_enrichment.third_mCyto.max_size.bed\",\n",
    "}\n",
    "\n",
    "id_anchors_dict = {}\n",
    "for id_name, fname in id_anchor_fnames.items():\n",
    "    id_anchors_dict[id_name] = pd.read_csv(fname, sep=\"\\t\")\n",
    "    # ...\n",
    "    print(f\"loaded {len(id_anchors_dict[id_name]):5d} ID anchors {id_name:>20} in BED format ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc207d77-90e5-48ab-aca7-0010217fffb0",
   "metadata": {},
   "source": [
    "## Pick one list of anchors and annotate it with epigenetic marks ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a32922-2c03-4848-a3cb-0a65f1781957",
   "metadata": {},
   "outputs": [],
   "source": [
    "_anchors = id_anchors_dict[\"5hr_2X_enrichment_signal\"]\n",
    "_anchors = _anchors.drop(columns=[\"size.1\",\"valency\",\"start\",\"end\"])\n",
    "bw_kyes_to_use = [\n",
    "    # \"mG.atac\",\n",
    "    # \"H3K27ac\",\n",
    "    # \"ctcf\",\n",
    "    \"dots\",\n",
    "]\n",
    "\n",
    "# summit annotation first ...\n",
    "# bws[\"dots\"] = \"mega_dots_anchors.bb\"\n",
    "bws[\"dots\"] = \"mega_final_dots_anchors.bb\"\n",
    "\n",
    "print(\"\\nannotating footprints ...\\n\")\n",
    "# additional anchor characterization - using footprint\n",
    "for k, bw in bws.items():\n",
    "    if k in [\"dots\",]:\n",
    "        # left anchor annotation ...\n",
    "        print(f\"working on peak {k} ...\")\n",
    "        _anchors[f\"peak_{k}\"] = bbi.stackup(\n",
    "                bw,\n",
    "                _anchors[\"chrom\"],\n",
    "                _anchors[\"peak_start\"] - 2_000,\n",
    "                _anchors[\"peak_end\"] + 2_000,\n",
    "                bins=1\n",
    "            ).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd2730-4816-496a-b4a4-644cbd8bd54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    [\n",
    "        _anchors.query(\"peak_dots == 0\")[\"size\"],\n",
    "        _anchors.query(\"peak_dots > 0\")[\"size\"],\n",
    "    ],\n",
    "    bins=np.linspace(20_000,250_000, 50),\n",
    "    stacked=True,\n",
    "    label=[\"peak_dots == 0\",\"peak_dots > 0\"]\n",
    "    # color = ['r','g']\n",
    ")\n",
    "plt.legend()\n",
    "plt.gca().set_xlabel(\"ID anchor footprint\")\n",
    "plt.gca().set_title(\"ID set: 5hr_2X_enrichment_signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fb037-11dc-4b6e-8ad2-bf232fb657d8",
   "metadata": {},
   "source": [
    "# We need to do more annotation for the `_anchors` to demonstrate pruning ...\n",
    "\n",
    "## Load dots and anchors to perform the ID-ID as a function of dot-overlap analysis ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2223de-ec1c-4a09-9c51-f78b4e1a110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls dots*\n",
    "# ! wc -l dots_10kb_samples/m5hR1R2_10kb_wheader.bedpe\n",
    "# ! wc -l dots_10kb_MEGA_samples/mG1s_MEGA_10kb_wheader.bedpe\n",
    "# ! wc -l dots_10kb/RGmR1R2_10kb_wheader.bedpe\n",
    "\n",
    "# ! wc -l dots_10kb/RGmR2_10kb_wheader.bedpe\n",
    "# ! wc -l dots_10kb/RGmR1_10kb_wheader.bedpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c0c92-3bb0-408b-957e-174425d36757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################################# anchors ...\n",
    "# anchor_fnames = {\n",
    "#     \"mega_ctrl\": \"dot_anchors_10kb_MEGA/mG1s_MEGA.bed\",\n",
    "# }\n",
    "# # ...\n",
    "# dot_anchors_dict = {}\n",
    "# for id_name, fname in anchor_fnames.items():\n",
    "#     dot_anchors_dict[id_name] = pd.read_csv(fname, sep=\"\\t\")\n",
    "#     # ...\n",
    "#     print(f\"loaded {len(dot_anchors_dict[id_name]):5d} ID anchors {id_name:>20} in BED format ...\")\n",
    "# # ...\n",
    "############################################# dots themselves ...\n",
    "dot_fnames = {\n",
    "    # \"mega_ctrl\": \"dots_10kb_MEGA_samples/mG1s_MEGA_10kb_wheader.bedpe\",\n",
    "    # \"mega_depl\": \"dots_10kb_MEGA_samples/pG1s_MEGA_10kb_wheader.bedpe\",\n",
    "    # \"mega_mito\": \"dots_10kb_MEGA_samples/Ms_MEGA_10kb_wheader.bedpe\",\n",
    "    \"mega_ctrl\": \"dots_10kb_MEGA_final/mG1s_MEGA_10kb_wheader_convergent.bedpe\",\n",
    "    \"mega_depl\": \"dots_10kb_MEGA_filtered_samples/pG1s_MEGA_10kb_wheader.bedpe\",\n",
    "    \"mega_mito\": \"dots_10kb_MEGA_filtered_samples/Ms_MEGA_10kb_wheader.bedpe\",\n",
    "    \"cyto\": \"dots_10kb_samples/mCyto_10kb_wheader.bedpe\",\n",
    "    \"m5\": \"dots_10kb_samples/m5hR1R2_10kb_wheader.bedpe\",\n",
    "}\n",
    "# ...\n",
    "# let's load them all into a dictionary ...\n",
    "dots_dict = {}\n",
    "for id_name, fname in dot_fnames.items():\n",
    "    dots_dict[id_name] = pd.read_csv(fname, sep=\"\\t\")\n",
    "    # ...\n",
    "    print(f\"loaded {len(dots_dict[id_name]):5d} dots {id_name:>20} in BEDPE format ...\")\n",
    "\n",
    "_select_dots = \"mega_ctrl\"\n",
    "# _select_dots = \"m5\"\n",
    "\n",
    "# # pick specific anchors and dots ...\n",
    "# _the_anchors = dot_anchors_dict[\"mega_ctrl\"]\n",
    "_the_dots = bioframe.sort_bedframe(\n",
    "    dots_dict[_select_dots],\n",
    "    view_df=hg38_arms_full,\n",
    "    cols=(\"chrom1\",\"start1\",\"end1\")\n",
    ")\n",
    "display(_the_dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1ba57-c216-4b49-8f9d-a064a20810b3",
   "metadata": {},
   "source": [
    "# Load domains\n",
    "merge nested and \"almost\" nested regions (regions overlapping a lot !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87daca4-9b99-4bf6-af06-057355ec4c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_domains = pd.read_csv(\n",
    "    \"extrusion_domains/mG1s_MEGA_10kb_double_filtered.bedpe\",\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "display(_domains.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051144b-2b0c-473e-8546-630558710b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43c9e6-f6df-47a9-bb78-f44dc27b4b5e",
   "metadata": {},
   "source": [
    "### assign domains to anchors ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674382a-f903-4d08-9c66-5b89cd0c9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "_anchor_cols = ('chrom', 'peak_start', 'peak_end')\n",
    "\n",
    "_anchors_domained = bioframe.overlap(\n",
    "    _anchors.eval(\"\"\"\n",
    "        peak_start = peak_start - 2_000\n",
    "        peak_end = peak_end + 2_000\n",
    "    \"\"\"),\n",
    "    _domains,\n",
    "    return_input=False,\n",
    "    return_index=True,\n",
    "    return_overlap=True,\n",
    "    suffixes=(\"\",\"_dom\"),\n",
    "    keep_order=True,\n",
    "    cols1=_anchor_cols,\n",
    ").fillna(\n",
    "    {\n",
    "        \"index_dom\": -1,\n",
    "        \"overlap_peak_start\": 0,\n",
    "        \"overlap_peak_end\": 0\n",
    "    }\n",
    ")\n",
    "\n",
    "# overlap statistics ..\n",
    "print(f\"total number of ID anchors {len(_anchors)}\")\n",
    "print(\n",
    "    \"Number of ID anchors that overlap >1 domain at once :\",\n",
    "    (_anchors_domained.groupby(\"index\").size() > 1).sum()\n",
    ")\n",
    "print(\n",
    "    \"Number of ID anchors that do not overlap any domains: \",\n",
    "    (_anchors_domained[\"index_dom\"]<0).sum()\n",
    ")\n",
    "\n",
    "# # make overlaps unique (THIS IS WRONG)...\n",
    "# _uniq_idx = _anchors_domained.eval(\"_over = overlap_peak_end - overlap_peak_start\").groupby(\"index\")[\"_over\"].idxmax()\n",
    "# _anchors_domained = _anchors_domained.loc[_uniq_idx].reset_index(drop=True)\n",
    "\n",
    "# keeping info about all overlaps ...\n",
    "print(\"assigning domain indices back to the table of anchors ...\")\n",
    "_anchors[\"index_dom\"] = _anchors_domained.groupby(\"index\")[\"index_dom\"].unique()\n",
    "print(_anchors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e10255-b52e-41ac-8eba-da97e36454b7",
   "metadata": {},
   "source": [
    "# Try to assign dots as well ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb456d-2ef5-4a13-94ac-fea7f9f395b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Characterize ID-anchors by their \"domainnes\" and \"dottedness\" ...\n",
    "_1 = _the_dots[[\"chrom2\",\"start2\",\"end2\"]].rename(columns={\"chrom2\":\"chrom\",\"start2\":\"start\",\"end2\":\"end\"}).reset_index()\n",
    "_2 = _the_dots[[\"chrom1\",\"start1\",\"end1\"]].rename(columns={\"chrom1\":\"chrom\",\"start1\":\"start\",\"end1\":\"end\"}).reset_index()\n",
    "\n",
    "_dot_anchors_redundant = bioframe.sort_bedframe(\n",
    "    pd.concat([_1, _2]).rename(columns={\"index\":\"index_dot\"}),\n",
    "    view_df=hg38_arms_full,\n",
    ")\n",
    "\n",
    "# dot overlaps anchors ...\n",
    "_dot_assigned = bioframe.overlap(\n",
    "    _anchors.eval(\"\"\"\n",
    "    peak_start = peak_start - 2_000\n",
    "    peak_end = peak_end + 2_000\n",
    "    \"\"\"),\n",
    "    _dot_anchors_redundant,\n",
    "    return_input=True,\n",
    "    return_index=False,\n",
    "    return_overlap=False,\n",
    "    suffixes=(\"\",\"_\"),\n",
    "    keep_order=True,\n",
    "    cols1=(\"chrom\", \"peak_start\", \"peak_end\"),\n",
    "    cols2=(\"chrom\", \"start\", \"end\"),\n",
    ")\n",
    "_dot_assigned[\"index_dot_\"] = _dot_assigned[\"index_dot_\"].fillna(-1).astype(int)\n",
    "_dot_assigned = _dot_assigned.groupby(\"cluster\")[\"index_dot_\"].unique()\n",
    "\n",
    "_anchors.loc[_dot_assigned.index, \"index_dot\"] = _dot_assigned\n",
    "_anchors\n",
    "# # _anchor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a967f-35c3-4b35-9684-94fb612af15e",
   "metadata": {},
   "source": [
    "## Now let's load HDF5 file with all of the pileups and anchor indices for the all-by-all dataframes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee4d34-9c83-4256-b10b-14ad8a73cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fr.items()\n",
    "def print_attrs(name, obj):\n",
    "    # Create indent\n",
    "    shift = name.count('/') * '    '\n",
    "    item_name = name.split(\"/\")[-1]\n",
    "    print(shift + item_name)\n",
    "    try:\n",
    "        for key, val in obj.attrs.items():\n",
    "            print(shift + '    ' + f\"{key}: {val}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "with h5py.File(\"/data/sergpolly/tmp/Pileups_ID_by_distance.hdf5\", 'r') as fr:\n",
    "    fr.visititems(print_attrs)\n",
    "\n",
    "    # check general metadata ...\n",
    "    _pileup_meta = dict(fr.attrs)\n",
    "    for k,v in _pileup_meta.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"...\")\n",
    "    print(\"restoring cis all-by-all table ...\")\n",
    "    # extract indices to recreate all-by-all in cis:\n",
    "    cis_left = fr.get(\"cis/indices\").get(\"anchor1\")[()]\n",
    "    cis_right = fr.get(\"cis/indices\").get(\"anchor2\")[()]\n",
    "    # assuming index and cluster - are the same ...\n",
    "    _df_intra_arm = pd.concat(\n",
    "        [\n",
    "            _anchors.iloc[cis_left].add_suffix(\"1\").reset_index(drop=True),\n",
    "            _anchors.iloc[cis_right].add_suffix(\"2\").reset_index(drop=True)\n",
    "        ],\n",
    "        axis=1\n",
    "     )\n",
    "    _df_intra_arm = _df_intra_arm.reset_index(drop=True)\n",
    "    _df_intra_arm[\"dist\"] = _df_intra_arm.eval(\".5*(peak_start2+peak_end2) - .5*(peak_start1+peak_end1)\")\n",
    "\n",
    "    print(\"restoring trans all-by-all table ...\")\n",
    "    # extract indices to recreate all-by-all in trans:\n",
    "    trans_left = fr.get(\"trans/indices\").get(\"anchor1\")[()]\n",
    "    trans_right = fr.get(\"trans/indices\").get(\"anchor2\")[()]\n",
    "    # assuming index and cluster - are the same ...\n",
    "    tr_feat = pd.concat(\n",
    "        [\n",
    "            _anchors.iloc[trans_left].add_suffix(\"1\").reset_index(drop=True),\n",
    "            _anchors.iloc[trans_right].add_suffix(\"2\").reset_index(drop=True)\n",
    "        ],\n",
    "        axis=1\n",
    "     )\n",
    "    tr_feat = tr_feat.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"extracting cis pileups as is...\")\n",
    "    # sort out the results per sample ...\n",
    "    fullstacks_cis = {}\n",
    "    cis_pileups_grp = fr.get(\"cis/pileups\")\n",
    "    for _sample in cis_pileups_grp.keys():\n",
    "        fullstacks_cis[_sample] = cis_pileups_grp.get(_sample)[()]\n",
    "\n",
    "\n",
    "    print(\"extracting trans pileups and calculating means ...\")\n",
    "    # create indexes for pileup groups\n",
    "    _dotless_idx = tr_feat.query(\"(peak_dots1==0)&(peak_dots2==0)\").index\n",
    "    _dotted_idx = tr_feat.query(\"(peak_dots1>0)&(peak_dots2>0)\").index\n",
    "    len(tr_feat), len(_dotless_idx), len(_dotted_idx)\n",
    "\n",
    "    # now average those sub-pileups :\n",
    "    stack_means = {}\n",
    "    trans_pileups_grp = fr.get(\"trans/pileups\")\n",
    "    for _sample in trans_pileups_grp.keys():\n",
    "        print(f\"    processing trans pileup {_sample} ...\")\n",
    "        #\n",
    "        _stack = trans_pileups_grp.get(_sample)[()]\n",
    "        stack_means[_sample] = [\n",
    "            np.nanmean(_stack[_dotless_idx], axis=0),\n",
    "            np.nanmean(_stack[_dotted_idx], axis=0),\n",
    "            np.nanmean(_stack, axis=0),\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925e50a-19ca-4101-ace8-e100a6bd8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _xxx = bioframe.overlap(\n",
    "#     _df_intra_arm,\n",
    "#     _domains,\n",
    "#     return_input=True,\n",
    "#     return_index=True,\n",
    "#     return_overlap=True,\n",
    "#     suffixes=('', '_dom'),\n",
    "#     keep_order=True,\n",
    "#     cols1=(\"chrom1\",\"peak_start1\",\"peak_end2\"),\n",
    "#     # cols2=None,\n",
    "#     # on=None,\n",
    "#     # ensure_int=True,\n",
    "# )\n",
    "\n",
    "# _yyy = _xxx.eval(\"\"\"\n",
    "#     over = overlap_peak_end2 - overlap_peak_start1\n",
    "#     dom_size = end_dom - start_dom\n",
    "#     id_size = peak_end2 - peak_start1\n",
    "# \"\"\")[[\n",
    "#     \"chrom1\",\n",
    "#     \"peak_start1\",\n",
    "#     # \"peak_end1\",\n",
    "#     # \"peak_start2\",\n",
    "#     \"peak_end2\",\n",
    "#     \"start_dom\",\n",
    "#     \"end_dom\",\n",
    "#     # \"overlap_peak_start1\",\n",
    "#     # \"overlap_peak_end2\",\n",
    "#     \"index\",\n",
    "#     \"index_dom\",\n",
    "#     \"dom_size\",\n",
    "#     \"id_size\",\n",
    "#     \"over\",\n",
    "# ]] \\\n",
    "#     .astype({\"over\":float, \"dom_size\":float, \"id_size\":float}) \\\n",
    "#     .eval(\"\"\"\n",
    "#     frac_dom = over / dom_size\n",
    "#     frac_id = over / id_size\n",
    "# \"\"\")\n",
    "\n",
    "# _dom_overs = _yyy.query(\"frac > 0.6\").groupby(\"index\").size()\n",
    "# _df_intra_arm.loc[_dom_overs.index, \"dom_over\"] = _dom_overs\n",
    "\n",
    "\n",
    "# _idid_domained = _df_intra_arm.eval(\n",
    "#     \"\"\"\n",
    "#     _inside_domain1 = ( index_dom1 >= 0 )\n",
    "#     _inside_domain2 = ( index_dom2 >= 0 )\n",
    "#     _same_domain = ((index_dom1 == index_dom2))\n",
    "#     _dotted1 = peak_dots1 > 0\n",
    "#     _dotted2 = peak_dots2 > 0\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "\n",
    "# _idid_domained[\"dot_status\"] = _idid_domained.apply(get_dotted_status, axis=1)\n",
    "# _idid_domained[\"dom_status\"] = _idid_domained.apply(get_domain_status, axis=1)\n",
    "# _idid_domained[\"dom_status\"].unique()\n",
    "# _idid_domained.query(\"dom_over.isnull()\")[\"dom_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948de4ce-eed6-451d-92ab-223352f175f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_intra_arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6b5ea-4dda-4761-828a-1cceb729303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _df_intra_arm[[\"index_dot1\",\"index_dot2\"]]\n",
    "def get_dot_order(_row):\n",
    "    _x1, _x2 = _row[\"index_dot1\"], _row[\"index_dot2\"]\n",
    "    if (-1 in _x1) or (-1 in _x2):\n",
    "        return -1\n",
    "    else:\n",
    "        return min( abs(dx[1] - dx[0]) for dx in product(_x1, _x2) )\n",
    "\n",
    "_df_intra_arm[\"dot_rank\"] = _df_intra_arm.apply(get_dot_order, axis=1)\n",
    "_dot_match_rank = _df_intra_arm[\"dot_rank\"]\n",
    "\n",
    "_dot_match_rank[_dot_match_rank > -1].value_counts().plot(marker=\"o\")\n",
    "plt.gca().set_ylabel(\"number of ID-ID with a given dot_order (min)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1e8f2-b3d7-4b02-b28a-347f3ea14bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing with domain ranking ...\n",
    "\n",
    "# _df_intra_arm[[\"index_dot1\",\"index_dot2\"]]\n",
    "def get_dom_order(_row):\n",
    "    _x1, _x2 = _row[\"index_dom1\"], _row[\"index_dom2\"]\n",
    "    if (-1 in _x1) or (-1 in _x2):\n",
    "        return -1\n",
    "    else:\n",
    "        return min( abs(dx[1] - dx[0]) for dx in product(_x1, _x2) )\n",
    "\n",
    "_df_intra_arm[\"dom_rank\"] = _df_intra_arm.apply(get_dom_order, axis=1)\n",
    "_dom_match_rank = _df_intra_arm[\"dom_rank\"]\n",
    "\n",
    "_dom_match_rank[_dom_match_rank > -1].value_counts().plot(marker=\"o\")\n",
    "plt.gca().set_ylabel(\"number of ID-ID with a given dom_order (min)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba863c2-fb1f-44ca-9802-8459a23c6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dotted_status(_row):\n",
    "    _exact = _row[\"dot_rank\"]\n",
    "    # if (0 <= _exact < 2):\n",
    "    if _exact == 0:\n",
    "        return \"dot-exact\"\n",
    "    else:\n",
    "        x = (_row[\"_dotted1\"], _row[\"_dotted2\"])\n",
    "        if x == (True, True):\n",
    "            return \"dot-anchor-2X\"\n",
    "        elif x == (False, True):\n",
    "            return \"dot-anchor-1X\"\n",
    "        elif x == (True, False):\n",
    "            return \"dot-anchor-1X\"\n",
    "        elif x == (False, False):\n",
    "            return \"dot-anchor-0X\"\n",
    "        else:\n",
    "            return \"blah\"\n",
    "\n",
    "def get_domain_status(_row):\n",
    "    # x = (_row[\"_inside_domain1\"], _row[\"_inside_domain2\"])\n",
    "    y = _row[\"dom_rank\"]\n",
    "    if y < 0:\n",
    "        return \"inter-domain<2X\"\n",
    "    elif y == 0:\n",
    "        return \"intra-domain\"\n",
    "    elif y > 0:\n",
    "        return \"inter-domain-2X\"\n",
    "    else:\n",
    "        return \"blah\"\n",
    "\n",
    "# lambda r: {\"dotted\": get_dotted_status(r), \"domain\": get_domain_status(r)}\n",
    "\n",
    "\n",
    "\n",
    "# # _idid_domained =\n",
    "# _grp = _df_intra_arm.eval(\n",
    "#     \"\"\"\n",
    "#     _inside_domain1 = ( index_dom1 >= 0 )\n",
    "#     _inside_domain2 = ( index_dom2 >= 0 )\n",
    "#     _same_domain = ((index_dom1 == index_dom2))\n",
    "#     _dotted1 = peak_dots1 > 0\n",
    "#     _dotted2 = peak_dots2 > 0\n",
    "#     \"\"\"\n",
    "# ).apply(\n",
    "#     lambda r: pd.Series({\"dot_status\": get_dotted_status(r), \"dom_status\": get_domain_status(r)}),\n",
    "#     axis=1\n",
    "# ).groupby([\"dom_status\", \"dot_status\"])\n",
    "_grp = _df_intra_arm.eval(\n",
    "    \"\"\"\n",
    "    _dotted1 = peak_dots1 > 0\n",
    "    _dotted2 = peak_dots2 > 0\n",
    "    \"\"\"\n",
    ").apply(\n",
    "    lambda r: pd.Series({\"dot_status\": get_dotted_status(r), \"dom_status\": get_domain_status(r)}),\n",
    "    axis=1\n",
    ").groupby([\"dom_status\", \"dot_status\"])\n",
    "\n",
    "_s = _grp.size()\n",
    "print(_s)\n",
    "_s[_s>20].plot(kind=\"barh\", figsize=(8,6))\n",
    "plt.tight_layout()\n",
    "# .groupby([\"_inside_domain1\",\"_inside_domain2\",\"_same_domain\"]).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45355439-8f35-4c44-8530-a582e5e921e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _idid_domained = _df_intra_arm.eval(\n",
    "#     \"\"\"\n",
    "#     _inside_domain1 = ( index_dom1 >= 0 )\n",
    "#     _inside_domain2 = ( index_dom2 >= 0 )\n",
    "#     _same_domain = ((index_dom1 == index_dom2))\n",
    "#     _dotted1 = peak_dots1 > 0\n",
    "#     _dotted2 = peak_dots2 > 0\n",
    "#     \"\"\"\n",
    "# )\n",
    "# _idid_domained[\"dot_status\"] = _idid_domained.apply(get_dotted_status, axis=1)\n",
    "# _idid_domained[\"dom_status\"] = _idid_domained.apply(get_domain_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7003cc-d39f-4677-a668-041b980f487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _select_df = _df_intra_arm.loc[_grp.get_group((\"inter-domain-2X\", \"dot-exact\")).index].query(\"dist < 311_000_000\")\n",
    "\n",
    "# display(\n",
    "#     _select_df[\n",
    "#         ['chrom1', 'peak_start1', 'peak_end2', 'dot_rank', 'index_dom1', 'index_dom2','index_dot1', 'index_dot2',\"dist\"]\n",
    "#     ]\n",
    "# )\n",
    "# #.iloc[98:]\n",
    "# # display(_select_df)\n",
    "# _select_single_domain = _select_df[['chrom1', 'peak_start1', 'peak_end2']].iloc[0]\n",
    "# _chrom, _start, _end, *_ = _select_single_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19016626-4fd3-41a0-8072-b4e1ca3395e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _select_df = _df_intra_arm.loc[_grp.get_group((\"inter-domain<2X\", \"dot-anchor-2X\")).index].query(\"dist < 4_000_000\")\n",
    "\n",
    "# display(\n",
    "#     _select_df[\n",
    "#         ['chrom1', 'peak_start1', 'peak_end2', 'dot_rank', 'index_dom1', 'index_dom2','index_dot1', 'index_dot2',\"dist\"]\n",
    "#     ]\n",
    "# )\n",
    "# #.iloc[98:]\n",
    "# # display(_select_df)\n",
    "# _select_single_domain = _select_df[['chrom1', 'peak_start1', 'peak_end2']].iloc[0]\n",
    "# _chrom, _start, _end, *_ = _select_single_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fcbd96-2fb3-4c6d-8978-49aabceb9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _select_single_domain = _df_intra_arm.loc[\n",
    "#     _grp.get_group((\"inter-domain<2X\", \"dot-exact\")).index\n",
    "# ][\n",
    "#     ['chrom1', 'peak_start1', 'peak_end2', 'dot_rank', 'index_dom1', 'index_dom2',]\n",
    "# ].iloc[100]\n",
    "# print(_select_single_domain)\n",
    "# _chrom, _start, _end, *_ = _select_single_domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49958cb6-4572-4d61-bcd9-1ccb4f020bde",
   "metadata": {},
   "source": [
    "# Explore some of the edge cases - visual checking ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3b2cc-ac5c-4538-95bb-94aa51b2a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sample = \"m5hR1R2\"\n",
    "clr = telo_clrs10[_sample]\n",
    "# Calculate domain defining dots ...\n",
    "\n",
    "_region1 = ('chr7', 27_275_000-2_750_000, 27_275_000+2_750_000)\n",
    "# _region1 = ('chr7', 38_000_000, 38_000_000+12_500_000)\n",
    "# # _region2 = ('chr7', 38_000_000, 38_000_000+12_500_000)\n",
    "# # _region1 = ('chr7', 20_500_000, 20_500_000+12_500_000)\n",
    "# # _region2 = ('chr7', 20_500_000, 20_500_000+12_500_000)\n",
    "# _region1 = (_chrom, _start-1_500_000, _end+1_500_000)\n",
    "# _region1 = ('chr1', 28_500_000-3_500_000, 28_910_000+3_500_000)\n",
    "_region2 = _region1\n",
    "\n",
    "# domains within selected region - turn it back to bedpe ...\n",
    "_domains_region = \\\n",
    "_domains.eval(\"\"\"\n",
    "    chrom1 = chrom\n",
    "    chrom2 = chrom\n",
    "    start1 = start\n",
    "    end1 = start + 10_000\n",
    "    start2 = end - 10_000\n",
    "    end2 = end\n",
    "\"\"\")[['chrom1', 'start1', 'end1', 'chrom2', 'start2', 'end2', 'n_intervals']]\n",
    "\n",
    "# select domains in the region ...\n",
    "_domains_region = bioframe.select(\n",
    "    bioframe.select(_domains_region, _region1, cols=(\"chrom1\",\"start1\",\"end1\")),\n",
    "    _region2, cols=(\"chrom2\",\"start2\",\"end2\"),\n",
    ").reset_index(drop=True)\n",
    "_domains_region[\"bin1_id\"] = _domains_region[[\"chrom1\",\"start1\",\"end1\"]].apply(clr.offset,axis=1,result_type=\"expand\")\n",
    "_domains_region[\"bin1_width\"] = _domains_region[[\"chrom1\",\"start1\",\"end1\"]].apply(clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "_domains_region[\"bin2_id\"] = _domains_region[[\"chrom2\",\"start2\",\"end2\"]].apply(clr.offset,axis=1,result_type=\"expand\")\n",
    "_domains_region[\"bin2_width\"] = _domains_region[[\"chrom2\",\"start2\",\"end2\"]].apply(clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "\n",
    "# select dots in the region ...\n",
    "_the_dots_region = bioframe.select(\n",
    "    bioframe.select(_the_dots, _region1, cols=(\"chrom1\",\"start1\",\"end1\")),\n",
    "    _region2, cols=(\"chrom2\",\"start2\",\"end2\"),\n",
    ").reset_index(drop=True)\n",
    "_the_dots_region[\"bin1_id\"] = _the_dots_region[[\"chrom1\",\"start1\",\"end1\"]].apply(clr.offset,axis=1,result_type=\"expand\")\n",
    "_the_dots_region[\"bin1_width\"] = _the_dots_region[[\"chrom1\",\"start1\",\"end1\"]].apply(clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "_the_dots_region[\"bin2_id\"] = _the_dots_region[[\"chrom2\",\"start2\",\"end2\"]].apply(clr.offset,axis=1,result_type=\"expand\")\n",
    "_the_dots_region[\"bin2_width\"] = _the_dots_region[[\"chrom2\",\"start2\",\"end2\"]].apply(clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "\n",
    "# select all-by-all ID domains in the region ...\n",
    "_bedpe_region = bioframe.select(\n",
    "    bioframe.select(_df_intra_arm, _region1, cols=(\"chrom1\",\"peak_start1\",\"peak_end1\")),\n",
    "    _region2, cols=(\"chrom2\",\"peak_start2\",\"peak_end2\"),\n",
    ").reset_index(drop=True)\n",
    "_bedpe_region[\"bin1_id\"] = _bedpe_region[[\"chrom1\",\"peak_start1\",\"peak_end1\"]].apply(clr.offset,axis=1,result_type=\"expand\")\n",
    "_bedpe_region[\"bin1_width\"] = _bedpe_region[[\"chrom1\",\"peak_start1\",\"peak_end1\"]].apply(clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "_bedpe_region[\"bin2_id\"] = _bedpe_region[[\"chrom2\",\"peak_start2\",\"peak_end2\"]].apply(clr.offset,axis=1,result_type=\"expand\")\n",
    "_bedpe_region[\"bin2_width\"] = _bedpe_region[[\"chrom2\",\"peak_start2\",\"peak_end2\"]].apply(clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "\n",
    "# # select ID domains to be highlighted in the region ...\n",
    "# _select_df_region = bioframe.select(\n",
    "#     bioframe.select(_select_df, _region1, cols=(\"chrom1\",\"peak_start1\",\"peak_end1\")),\n",
    "#     _region2, cols=(\"chrom2\",\"peak_start2\",\"peak_end2\"),\n",
    "# ).reset_index(drop=True)\n",
    "# _select_df_region[\"bin1_id\"] = _select_df_region[[\"chrom1\",\"peak_start1\",\"peak_end1\"]].apply(clr.offset,axis=1,result_type=\"expand\")\n",
    "# _select_df_region[\"bin1_width\"] = _select_df_region[[\"chrom1\",\"peak_start1\",\"peak_end1\"]].apply(clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n",
    "# _select_df_region[\"bin2_id\"] = _select_df_region[[\"chrom2\",\"peak_start2\",\"peak_end2\"]].apply(clr.offset,axis=1,result_type=\"expand\")\n",
    "# _select_df_region[\"bin2_width\"] = _select_df_region[[\"chrom2\",\"peak_start2\",\"peak_end2\"]].apply(clr.extent,axis=1,result_type=\"expand\").apply(np.diff,axis=1,result_type=\"expand\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e7799-4810-4808-8f05-8cfced54bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_the_dots_region.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4684e4-37f6-4379-a374-eac120a86091",
   "metadata": {},
   "outputs": [],
   "source": [
    "region1_name = bioframe.select(hg38_arms, _region1).iat[0,-1]\n",
    "region2_name = bioframe.select(hg38_arms, _region2).iat[0,-1]\n",
    "assert region1_name == region2_name\n",
    "region_name = region2_name\n",
    "\n",
    "tile_span_i = clr.extent(_region1)\n",
    "tile_span_j = clr.extent(_region2)\n",
    "_the_tile = (region_name, tile_span_i, tile_span_j )\n",
    "_reg1w = np.diff(tile_span_i).item()\n",
    "_reg2w = np.diff(tile_span_j).item()\n",
    "\n",
    "# observed matrix slice ...\n",
    "_mat = scipy.ndimage.gaussian_filter(\n",
    "    clr.matrix()[slice(*tile_span_i), slice(*tile_span_j)],\n",
    "    sigma=0.4,\n",
    "    order=0,\n",
    "    mode='reflect',\n",
    "    cval=0.0,\n",
    "    # radius=3,\n",
    "    truncate=1.0,\n",
    ")\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=0.0001, vmax=0.01),\n",
    "        cmap=\"YlOrBr\",\n",
    "        interpolation=\"nearest\",\n",
    "        # interpolation=\"none\",\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8) )\n",
    "ax.imshow(_mat, **imshow_kwargs)\n",
    "ax.set_xlim(0, _reg2w)\n",
    "ax.set_ylim(_reg1w, 0)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# draw boxes around clustered pixels ...\n",
    "_big_boxes_kwargs = dict(loc=\"upper\", lw=1.5, ec=\"k\", fc=\"none\", halo=0, ext_width=0)\n",
    "for box in rectangles_around_dots_ww( _bedpe_region, _the_tile, **_big_boxes_kwargs ):\n",
    "    ax.add_patch(box)\n",
    "# draw boxes around clustered pixels ...\n",
    "_big_boxes_kwargs = dict(loc=\"upper\", lw=1.5, ec=\"blue\", fc=\"none\", halo=0, ext_width=0)\n",
    "for box in rectangles_around_dots_ww( _the_dots_region, _the_tile, **_big_boxes_kwargs ):\n",
    "    ax.add_patch(box)\n",
    "# draw boxes around clustered pixels ...\n",
    "_big_boxes_kwargs = dict(loc=\"upper\", lw=1.5, ec=\"red\", fc=\"none\", halo=0, ext_width=0)\n",
    "for box in rectangles_around_dots_ww( _domains_region, _the_tile, **_big_boxes_kwargs ):\n",
    "    ax.add_patch(box)\n",
    "\n",
    "\n",
    "# # draw boxes around clustered pixels ...\n",
    "# _big_boxes_kwargs = dict(loc=\"upper\", lw=1.5, ec=\"green\", fc=\"none\", halo=0, ext_width=1)\n",
    "# for box in rectangles_around_dots_ww( _select_df_region, _the_tile, **_big_boxes_kwargs ):\n",
    "#     ax.add_patch(box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07a4e2-560a-4a32-930d-53a35625da74",
   "metadata": {},
   "source": [
    "## plotting - individual pups ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2e73d-9fe1-4d81-b3a6-3bba3c67cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pileup select samples only !\n",
    "_select_sample_groups = [\n",
    "    [\n",
    "        \"mMito\",\n",
    "        \"mTelo\",\n",
    "        \"mCyto\",\n",
    "        \"m5hR1R2\",\n",
    "        \"m10hR1R2\"\n",
    "    ],\n",
    "    # # p-ones\n",
    "    [\n",
    "        \"pMito\",\n",
    "        \"pTelo\",\n",
    "        \"pCyto\",\n",
    "        \"p5hR1R2\",\n",
    "        \"p10hR1R2\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b559b6-bdf1-493a-86f7-32c0246f6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mb(bp_val):\n",
    "    # check MB\n",
    "    if np.mod(bp_val, 1_000_000):\n",
    "        # just give 1 decimal if not even Mb\n",
    "        return f\"{bp_val/1_000_000:.1f}\"\n",
    "    else:\n",
    "        return f\"{bp_val//1_000_000}\"\n",
    "\n",
    "# given the range - generate pretty axis name\n",
    "def _get_name(_left, _right, _amount):\n",
    "    if np.isclose(_left, 0.0):\n",
    "        return f\"<{to_mb(_right)} Mb: {_amount}\"\n",
    "    elif _right > 80_000_000:\n",
    "        return f\">{to_mb(_left)} Mb: {_amount}\"\n",
    "    else:\n",
    "        return f\"{to_mb(_left)}-{to_mb(_right)} Mb: {_amount}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebc6f4-171c-4fcc-95cb-99c5ee29df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "_the_clr_m5 = telo_clrs10[\"m5hR1R2\"]\n",
    "_the_clr_p5 = telo_clrs10[\"p5hR1R2\"]\n",
    "\n",
    "# _the_clr_mm = mega_clrs10[\"dldmicroc\"]\n",
    "# _the_clr_m5 = mega_clrs10[\"mG1s_MEGA\"]\n",
    "# _the_clr_p5 = mega_clrs10[\"pG1s_MEGA\"]\n",
    "\n",
    "# ['N93pG1s_MEGA', 'N93mG1s_MEGA', 'pG1s_MEGA', 'Ms_MEGA', 'mG1s_MEGA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316ea4f-62f4-47b6-ad39-4585e30658dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(\n",
    "    mat,\n",
    "    hw_in=2,\n",
    "    hw_out=2\n",
    "):\n",
    "    \"\"\"\n",
    "    get pileup enrichment score ...\n",
    "    \"\"\"\n",
    "    _mid, _ = mat.shape\n",
    "    _mid = (_mid - 1)//2\n",
    "    # deal with the center - enriched part\n",
    "    _from ,_to = _mid-hw_in, _mid+hw_in+1\n",
    "    mid_mat = mat[ _from:_to, _from:_to]\n",
    "    # deal with the periphery - \"background\" part\n",
    "    _from ,_to = _mid-hw_out, _mid+hw_out+1\n",
    "    mat_copy = mat.copy()\n",
    "    mat_copy[_from:_to] = np.nan\n",
    "    mat_copy[:, _from:_to] = np.nan\n",
    "    # ...\n",
    "    return np.nanmean(mid_mat)/np.nanmean(mat_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f40c1-c3ca-4e95-8fb1-423d12d008b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "21-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a3774-cc56-4ac2-bbcc-8a4b174d6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dom_status       dot_status\n",
    "# inter-domain-2X  dot-anchor-0X     1076\n",
    "#                  dot-anchor-1X    15059\n",
    "#                  dot-anchor-2X    50258\n",
    "#                  dot-exact            1\n",
    "# inter-domain<2X  dot-anchor-0X      822\n",
    "#                  dot-anchor-1X     4792\n",
    "#                  dot-anchor-2X      233\n",
    "#                  dot-exact            4\n",
    "# intra-domain     dot-anchor-0X       18\n",
    "#                  dot-anchor-1X      286\n",
    "#                  dot-anchor-2X      744\n",
    "#                  dot-exact          677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab844987-e1f1-41db-9f80-41639bf395a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! head idid_scores.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed670bac-429b-46e0-a6e5-33098870b420",
   "metadata": {},
   "source": [
    "# Make 5F pruning subpanel ... the all by all versus the dot sizes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439fc83-bf77-4c7a-be03-00f4752eaf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_sizes = _the_dots.eval(\"end2 - end1\").to_numpy()\n",
    "# [0, 250_000, 500_000, 1_000_000, 2_500_000, 5_000_000, 10_000_000, 25_000_000, 50_000_000]\n",
    "f, ax = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    "    figsize=(2.5,2.5),\n",
    ")\n",
    "\n",
    "ym = pd.DataFrame(_qtable).query(\"label=='all-all'\")[\"m5hR1R2\"]\n",
    "yp = pd.DataFrame(_qtable).query(\"label=='all-all'\")[\"p5hR1R2\"]\n",
    "\n",
    "ax.plot(_distX, ym, label=k, marker=\".\", color=\"blue\")\n",
    "ax.plot(_distX, yp, label=k, marker=\".\", color=\"red\")\n",
    "# ax.plot(_trans_idx, mmm_list[-1], label=k, marker=\".\", color=color)\n",
    "ax.set_xscale(\"log\")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "ax.set_yticks([1,1.5,2], minor=False)\n",
    "ax.set_yticks([], minor=True)\n",
    "ax.set_ylim((0.95, 2.175))\n",
    "ax.set_xlim((_distX[0]*0.7, _trans_idx*1.2))\n",
    "# ax.set_xticks(np.append(_distX, _trans_idx), labels=[], minor=True)\n",
    "ax.set_xticks(\n",
    "    np.append(_distX, _trans_idx),\n",
    "    labels=[ f\"{_d/1_000_000:.2f}\" if not _i%2 else \"\" for _i,_d in enumerate(_distX)]+[\"trans\"],\n",
    "    minor=True,\n",
    "    rotation=90,\n",
    ")\n",
    "_90th = np.percentile(dot_sizes, 90)\n",
    "ax.set_xticks([_90th], labels=[\"90th\"], minor=False)\n",
    "ax.grid(visible=True, which=\"major\")\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "ax_hist = ax.twinx()  # instantiate a second Axes that shares the same x-axis\n",
    "# ax2.plot(t, data2, color=color)\n",
    "# ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax_hist.hist(\n",
    "    dot_sizes,\n",
    "    bins=np.geomspace(90_000, 20_000_000, 20),\n",
    "    histtype='stepfilled',\n",
    "    color='darkgoldenrod',\n",
    "    edgecolor='k',\n",
    "    alpha=0.5\n",
    ");\n",
    "\n",
    "# ax_hist.\n",
    "# # _the_dots.eval(\"end2 - end1\").hist(bins=np.r_[300_000, np.geomspace(1_000_000, 10_000_000, 50)])\n",
    "# # plt.gca().set_xscale(\"log\")\n",
    "# np.geomspace(10_000, 10_000_000, 100)\n",
    "ax.set_zorder(1)  # default zorder is 0 for ax1 and ax2\n",
    "ax.patch.set_visible(False)  # prevents ax1 from hiding ax2\n",
    "\n",
    "\n",
    "plt.savefig(\"Fig5F.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e85549-b6b7-4c23-8b1c-fb3bb520c1c5",
   "metadata": {},
   "source": [
    "# Make 5G pruning subpanel ... timecourse quantifications ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492fbe5-c51c-4d23-a9db-d25af04242c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_flank = 100_000\n",
    "# dist_bins = [0, 300_000, 1_000_000, 2_500_000, 5_000_000, 10_000_000, 50_000_000]\n",
    "dist_bins = [0, 250_000, 500_000, 1_000_000, 2_500_000, 5_000_000, 10_000_000, 25_000_000, 50_000_000]\n",
    "\n",
    "\n",
    "# dist_bins = (np.asarray([0.125, 0.375, 0.75, 1.75, 3.75, 7.50, 17.5, 37.5, 300])*1_000_000).astype(int)\n",
    "# # 0.125, 0.375, 0.75, 1.75, 3.75, 7.50, 17.5, 37.5\n",
    "\n",
    "# pileup select samples only !\n",
    "quant_sample_groups = [\n",
    "    [\n",
    "        \"mMito\",\n",
    "        \"mTelo\",\n",
    "        \"mCyto\",\n",
    "        \"m5hR1R2\",\n",
    "        # \"m10hR1R2\",\n",
    "    ],\n",
    "    # # p-ones\n",
    "    [\n",
    "        \"pMito\",\n",
    "        \"pTelo\",\n",
    "        \"pCyto\",\n",
    "        \"p5hR1R2\",\n",
    "        # \"p10hR1R2\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "_oo = np.asarray(dist_bins)\n",
    "_distX = (_oo[:-1]+_oo[1:])/2\n",
    "# _oo[0] = _oo[1]\n",
    "# # _www = (_distX[-1] - _distX[0])\n",
    "# _distX = np.sqrt((_oo[:-1])*(_oo[1:]))\n",
    "# _distX_trans = np.append(_distX, 70_000_000)\n",
    "\n",
    "quant_cat_dict = {}\n",
    "\n",
    "qcat_name = \"all-all\"\n",
    "quant_cat_dict[qcat_name] = _df_intra_arm.loc[:]\n",
    "\n",
    "qcat_name = \"dotted\"\n",
    "_groups_of_interest = [ _g for _g in _grp.groups.keys() if (_g[1]!=\"dot-anchor-0X\") ]\n",
    "_index_of_interest = np.concatenate([_grp.indices[_g] for _g in _groups_of_interest])\n",
    "quant_cat_dict[qcat_name] = _df_intra_arm.loc[_index_of_interest]\n",
    "\n",
    "qcat_name = \"dotless\"\n",
    "_groups_of_interest = [ _g for _g in _grp.groups.keys() if _g[1]==\"dot-anchor-0X\" ]\n",
    "_index_of_interest = np.concatenate([_grp.indices[_g] for _g in _groups_of_interest])\n",
    "quant_cat_dict[qcat_name] = _df_intra_arm.loc[_index_of_interest]\n",
    "\n",
    "\n",
    "_qtable = {}\n",
    "_qtable[\"label\"] = []\n",
    "_qtable[\"dist_min\"] = []\n",
    "_qtable[\"dist_max\"] = []\n",
    "for _kkk in sum(quant_sample_groups, []):\n",
    "    _qtable[_kkk] = []\n",
    "\n",
    "\n",
    "_trans_idx = 70_000_000\n",
    "\n",
    "for _name, _df in quant_cat_dict.items():\n",
    "    ggg = _df.groupby(pd.cut( _df[\"dist\"], dist_bins ))\n",
    "    nquants = len(ggg)\n",
    "    f, axs = plt.subplots(\n",
    "        nrows=1,\n",
    "        ncols=len(quant_sample_groups[0]),\n",
    "        figsize=(10,2.5),\n",
    "        sharey=True,\n",
    "        sharex=True,\n",
    "    )\n",
    "    # ...\n",
    "    for _sample_group in quant_sample_groups:\n",
    "        for ax, k in zip(axs, _sample_group):\n",
    "            # ... samples ...\n",
    "            _stacks = fullstacks_cis[k]\n",
    "            mmm_list = []\n",
    "            for _dist_min, _dist_max, (_q, _mtx) in zip(dist_bins[:-1], dist_bins[1:], ggg.groups.items()):\n",
    "                # ... groupings (by dist, or whatever ...)\n",
    "                mmm = np.nanmean(_stacks[_mtx], axis=0)\n",
    "                _score = get_score( mmm, hw_in=2, hw_out=4)\n",
    "                # print(k, _q, _score)\n",
    "                mmm_list.append(_score)\n",
    "                # ...\n",
    "                _qtable[k].append(_score)\n",
    "                if k == quant_sample_groups[0][0]:\n",
    "                    _qtable[\"label\"].append(_name)\n",
    "                    _qtable[\"dist_min\"].append(_dist_min)\n",
    "                    _qtable[\"dist_max\"].append(_dist_max)\n",
    "                # ...\n",
    "            # # add trans score right after\n",
    "            if _name == \"all-all\":\n",
    "                mmm = stack_means[k][2]\n",
    "            elif _name == \"dotted\":\n",
    "                mmm = stack_means[k][1]\n",
    "            elif _name == \"dotless\":\n",
    "                mmm = stack_means[k][0]\n",
    "            else:\n",
    "                raise(\"wtf ?!\")\n",
    "            # do the score ...\n",
    "            _score = get_score( mmm, hw_in=0, hw_out=2)\n",
    "            mmm_list.append(_score)\n",
    "            if k.startswith(\"m\"):\n",
    "                ax.set_title(k.lstrip(\"m\").rstrip(\"R12\"))\n",
    "                color=\"blue\"\n",
    "            else:\n",
    "                color=\"red\"\n",
    "            ax.plot(_distX, mmm_list[:-1], label=k, marker=\".\", color=color)\n",
    "            ax.plot(_trans_idx, mmm_list[-1], label=k, marker=\".\", color=color)\n",
    "            ax.set_xscale(\"log\")\n",
    "            # ax.set_yscale(\"log\")\n",
    "            ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "            ax.set_yticks([1,1.5,2], minor=False)\n",
    "            ax.set_yticks([], minor=True)\n",
    "            ax.set_ylim((0.95, 2.175))\n",
    "            ax.set_xlim((_distX[0]*0.8, _trans_idx*1.2))\n",
    "            ax.set_xticks(\n",
    "                np.append(_distX, _trans_idx),\n",
    "                labels=[ f\"{_d/1_000_000:.2f}\" if not _i%2 else \"\" for _i,_d in enumerate(_distX)]+[\"trans\"],\n",
    "                minor=True,\n",
    "                rotation=90,\n",
    "            )\n",
    "            ax.set_xticks([_90th], labels=[\"90th\"], minor=False)\n",
    "            ax.grid(visible=True, which=\"major\")\n",
    "            ax.spines[['right', 'top']].set_visible(False)\n",
    "    # # add trans score right after\n",
    "    plt.savefig(f\"Fig5G_{_name}.svg\")\n",
    "    # ...\n",
    "    # _qtable[]\n",
    "# #\n",
    "# # save this as a table ...\n",
    "# pd.DataFrame(_qtable).to_csv(\"idid_scores.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# plt.savefig(\"Fig5F.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a6a72-162b-48ad-bf81-7075ee12733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ f\"{_d/1_000_000:.2f}\" if not _i%2 else \"\" for _i,_d in enumerate(_distX)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717d856-a5de-4807-a5f8-21af1aea0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "_distX[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e123ab0d-10ea-437e-ac4c-2451774d8d55",
   "metadata": {},
   "source": [
    "# Make 5F pruning subpanel ... the all by all versus the dot sizes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e65faf-02e5-4fea-9b38-b2e0ebef9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_sizes = _the_dots.eval(\"end2 - end1\").to_numpy()\n",
    "# [0, 250_000, 500_000, 1_000_000, 2_500_000, 5_000_000, 10_000_000, 25_000_000, 50_000_000]\n",
    "f, ax = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    "    figsize=(2.5,2.5),\n",
    ")\n",
    "\n",
    "ym = pd.DataFrame(_qtable).query(\"label=='all-all'\")[\"m5hR1R2\"]\n",
    "yp = pd.DataFrame(_qtable).query(\"label=='all-all'\")[\"p5hR1R2\"]\n",
    "\n",
    "ax.plot(_distX, ym, label=k, marker=\".\", color=\"blue\")\n",
    "ax.plot(_distX, yp, label=k, marker=\".\", color=\"red\")\n",
    "# ax.plot(_trans_idx, mmm_list[-1], label=k, marker=\".\", color=color)\n",
    "ax.set_xscale(\"log\")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "ax.set_yticks([1,1.5,2], minor=False)\n",
    "ax.set_yticks([], minor=True)\n",
    "ax.set_ylim((0.95, 2.175))\n",
    "ax.set_xlim((_distX[0]*0.7, _trans_idx*1.2))\n",
    "ax.set_xticks(np.append(_distX, _trans_idx), labels=[], minor=True)\n",
    "# np.percentile(dot_sizes, 90)\n",
    "ax.set_xticks([910000], labels=[\"0.91\"], minor=False)\n",
    "ax.grid(visible=True, which=\"major\")\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "ax_hist = ax.twinx()  # instantiate a second Axes that shares the same x-axis\n",
    "# ax2.plot(t, data2, color=color)\n",
    "# ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax_hist.hist(\n",
    "    dot_sizes,\n",
    "    bins=np.geomspace(90_000, 20_000_000, 20),\n",
    "    histtype='stepfilled',\n",
    "    color='darkgoldenrod',\n",
    "    edgecolor='k',\n",
    "    alpha=0.5\n",
    ");\n",
    "\n",
    "# ax_hist.\n",
    "# # _the_dots.eval(\"end2 - end1\").hist(bins=np.r_[300_000, np.geomspace(1_000_000, 10_000_000, 50)])\n",
    "# # plt.gca().set_xscale(\"log\")\n",
    "# np.geomspace(10_000, 10_000_000, 100)\n",
    "ax.set_zorder(1)  # default zorder is 0 for ax1 and ax2\n",
    "ax.patch.set_visible(False)  # prevents ax1 from hiding ax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c37f6-711c-4b29-9603-9f7ae3fb06b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37352e-9602-42bc-af49-f96632dcdcca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fead872-9b25-4deb-9c9d-b9239554d934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b0090-bab0-42ec-b39a-fe2076e0d9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bec2a5-6848-4e96-9a18-33d5723cd762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c847a7c-99eb-42b1-b5f5-a1fbb8737b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346b1bf-1944-40bb-8012-49ac5577e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_flank = 100_000\n",
    "# dist_bins = [0, 300_000, 1_000_000, 2_500_000, 5_000_000, 10_000_000, 50_000_000]\n",
    "dist_bins = [0, 250_000, 500_000, 1_000_000, 2_500_000, 5_000_000, 10_000_000, 25_000_000, 50_000_000]\n",
    "\n",
    "_oo = np.asarray(dist_bins)\n",
    "_distX = (_oo[:-1]+_oo[1:])/2\n",
    "_www = (_distX[-1] - _distX[0])\n",
    "\n",
    "_dfff_dict = {}\n",
    "\n",
    "_dfff_id = \"all-all\"\n",
    "# all ID-IDs\n",
    "_dfff_dict[_dfff_id] = _df_intra_arm.loc[:]\n",
    "\n",
    "_dfff_id = \"inter-dotted\"\n",
    "# inter-domain dotted (X2 and >0):\n",
    "_groups_of_interest = [('inter-domain-2X', 'dot-anchor-2X'), ]\n",
    "_index_of_interest = np.concatenate([_grp.indices[_g] for _g in _groups_of_interest])\n",
    "_dfff_dict[_dfff_id] = _df_intra_arm.loc[_index_of_interest]\n",
    "\n",
    "_dfff_id = \"inter-dotless\"\n",
    "# inter-domain not-dotted (X2 and >0):\n",
    "_groups_of_interest = [('inter-domain-2X', 'dot-anchor-0X'), ('inter-domain<2X', 'dot-anchor-0X')]\n",
    "_index_of_interest = np.concatenate([_grp.indices[_g] for _g in _groups_of_interest])\n",
    "_dfff_dict[_dfff_id] = _df_intra_arm.loc[_index_of_interest]\n",
    "\n",
    "_dfff_id = \"intra-dotted\"\n",
    "# intra-domain dotted (X2):\n",
    "_groups_of_interest = [('intra-domain', 'dot-anchor-2X'), ('intra-domain', 'dot-anchor-1X')]\n",
    "_index_of_interest = np.concatenate([_grp.indices[_g] for _g in _groups_of_interest])\n",
    "_dfff_dict[_dfff_id] = _df_intra_arm.loc[_index_of_interest]\n",
    "\n",
    "\n",
    "_dfff_id = \"intra-exact\"\n",
    "# intra-domain dot exact:\n",
    "_groups_of_interest = [('intra-domain', 'dot-exact'), ]\n",
    "_index_of_interest = np.concatenate([_grp.indices[_g] for _g in _groups_of_interest])\n",
    "_dfff_dict[_dfff_id] = _df_intra_arm.loc[_index_of_interest]\n",
    "\n",
    "\n",
    "_table = {}\n",
    "_table[\"label\"] = []\n",
    "_table[\"dist_min\"] = []\n",
    "_table[\"dist_max\"] = []\n",
    "for _kkk in sum(_select_sample_groups, []):\n",
    "    _table[_kkk] = []\n",
    "\n",
    "\n",
    "for _id, _dfff in _dfff_dict.items():\n",
    "    ggg = _dfff.groupby(pd.cut( _dfff[\"dist\"], dist_bins ))\n",
    "    nquants = len(ggg)\n",
    "    f, axs = plt.subplots(\n",
    "        nrows=1,\n",
    "        ncols=len(_select_sample_groups[0]),\n",
    "        figsize=(15,2.5),\n",
    "        sharey=True,\n",
    "        sharex=True,\n",
    "    )\n",
    "    # ...\n",
    "    for _sample_group in _select_sample_groups:\n",
    "        for ax, k in zip(axs, _sample_group):\n",
    "            # ... samples ...\n",
    "            _stacks = fullstacks_cis[k]\n",
    "            mmm_list = []\n",
    "            for _dist_min, _dist_max, (_q, _mtx) in zip(dist_bins[:-1], dist_bins[1:], ggg.groups.items()):\n",
    "                # ... groupings (by dist, or whatever ...)\n",
    "                mmm = np.nanmean(_stacks[_mtx], axis=0)\n",
    "                _score = get_score( mmm, hw_in=2, hw_out=4)\n",
    "                # print(k, _q, _score)\n",
    "                mmm_list.append(_score)\n",
    "                # ...\n",
    "                _table[k].append(_score)\n",
    "                if k == _select_sample_groups[0][0]:\n",
    "                    _table[\"label\"].append(_id)\n",
    "                    _table[\"dist_min\"].append(_dist_min)\n",
    "                    _table[\"dist_max\"].append(_dist_max)\n",
    "                # ...\n",
    "            ax.plot(_distX, mmm_list, label=k, marker=\".\")\n",
    "            # ax.legend(frameon=False)\n",
    "            if k.startswith(\"m\"):\n",
    "                ax.set_title(k.lstrip(\"m\").rstrip(\"R12\"))\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "            ax.set_ylim((0.9, 3.0))\n",
    "            ax.set_xlim((_distX[0]*0.8, _distX[-1]*1.2))\n",
    "    #\n",
    "    # ...\n",
    "    # _table[]\n",
    "# #\n",
    "# # save this as a table ...\n",
    "# pd.DataFrame(_table).to_csv(\"idid_scores.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d12499-3e56-468f-95c6-287f8f998f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789356c-f66d-4bcd-af44-6bd5350777cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21e871b0-31f9-43b8-a272-9f41790f9c18",
   "metadata": {},
   "source": [
    "# Actual figure plotting for publication ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc15b66-c275-468b-8339-e7a57888ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2\n",
    "tcourse_spacing = 0.1\n",
    "matw = 0.35\n",
    "cbarh = 0.07\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"nearest\",\n",
    ")\n",
    "\n",
    "# timecourse_samples = [\"Mito\", \"Telo\", \"Cyto\", \"5hR1R2\", \"10hR1R2\"]\n",
    "timecourse_samples = [\"Mito\", \"Telo\", \"Cyto\", \"5hR1R2\"]\n",
    "_nsamples = len(timecourse_samples)\n",
    "\n",
    "_plot_conditions = [\n",
    "    \"inter-dotless\",\n",
    "    \"inter-dotted\",\n",
    "    \"intra-dotted\",\n",
    "    \"intra-exact\",\n",
    "]\n",
    "_nconds = len(_plot_conditions)\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = [ Size.Fixed(margin) ] + \\\n",
    "    (_nsamples-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(tcourse_spacing) ] + \\\n",
    "    (_nsamples-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(margin) ] + [ Size.Fixed(matw), Size.Fixed(margin) ]\n",
    "# goes from bottom to the top ...\n",
    "v = [ Size.Fixed(margin), Size.Fixed(cbarh), Size.Fixed(0.5*margin), ] + \\\n",
    "    (_nconds-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin), ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(margin), ]\n",
    "# ...\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "# ...\n",
    "axs_m = {}\n",
    "axs_p = {}\n",
    "for i, _sample in enumerate(timecourse_samples):\n",
    "    axs_p[_sample] = {}\n",
    "    axs_m[_sample] = {}\n",
    "    nxm = 2*i + 1\n",
    "    nxp = 2*(i+_nsamples) + 1\n",
    "    for j, _cond in enumerate(_plot_conditions):\n",
    "        ny = 2*(j+1) + 1\n",
    "        axs_p[_sample][_cond] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=nxp, ny=ny))\n",
    "        axs_m[_sample][_cond] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=nxm, ny=ny))\n",
    "\n",
    "\n",
    "# ...\n",
    "axq = {}\n",
    "nx = 4*_nsamples + 1\n",
    "for j, _cond in enumerate(_plot_conditions):\n",
    "    ny = 2*(j+1) + 1\n",
    "    axq[_cond] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=nx, ny=ny))\n",
    "\n",
    "\n",
    "for ax in (\n",
    "        sum( [list(_d.values()) for c,_d in axs_m.items()], start=[] ) +\n",
    "        sum( [list(_d.values()) for c,_d in axs_p.items()], start=[] ) +\n",
    "        list( axq.values() )\n",
    "    ):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "cbar_ax = fig.add_axes(\n",
    "    divider.get_position(),\n",
    "    axes_locator=divider.new_locator(nx=nxp, ny=1)\n",
    ")\n",
    "cbar_ax.set_xticks([])\n",
    "cbar_ax.set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "for i, _sample in enumerate(timecourse_samples):\n",
    "    for j, _cond in enumerate(_plot_conditions):\n",
    "        axp = axs_p[_sample][_cond]\n",
    "        axm = axs_m[_sample][_cond]\n",
    "        # ...\n",
    "        _mtx = _dfff_dict[_cond].index\n",
    "        # going over groupings (by dist, or whatever ...)\n",
    "        Cm = np.nanmean(fullstacks_cis[f'm{_sample}'][_mtx], axis=0)\n",
    "        Cp = np.nanmean(fullstacks_cis[f'p{_sample}'][_mtx], axis=0)\n",
    "        _ccc = axm.imshow( Cm, **imshow_kwargs )\n",
    "        _ccc.cmap.set_over(\"#300000\")\n",
    "        _ccc = axp.imshow( Cp, **imshow_kwargs )\n",
    "        _ccc.cmap.set_over(\"#300000\")\n",
    "        # ...\n",
    "        for _ax in [axp, axm,]:\n",
    "            _ax.set_xticks([])\n",
    "            _ax.set_yticks([])\n",
    "        # ylabel\n",
    "        if i == 0:\n",
    "            axm.set_ylabel(f\"{_cond}\", fontsize=4, labelpad=1)\n",
    "        if j == len(_plot_conditions) - 1:\n",
    "            axm.set_title(f\"m{_sample}\", fontsize=4, pad=1)\n",
    "            axp.set_title(f\"p{_sample}\", fontsize=4, pad=1)\n",
    "        # add ticks ...\n",
    "        _mat_size = Cm.shape[0]\n",
    "        if j == 0:\n",
    "            axm.set_xticks([0-0.5, _mat_size/2-0.5, _mat_size-0.5])\n",
    "            axm.set_xticklabels([-_flank//1000, 0, _flank//1000], fontsize=4)\n",
    "            axm.tick_params(length=1.5, pad=1)\n",
    "            for _tidx, tick in enumerate(axm.xaxis.get_majorticklabels()):\n",
    "                if _tidx == 0:\n",
    "                    tick.set_horizontalalignment(\"left\")\n",
    "                elif _tidx == 2:\n",
    "                    tick.set_horizontalalignment(\"right\")\n",
    "                else:\n",
    "                    tick.set_horizontalalignment(\"center\")\n",
    "            axp.set_xticks([0-0.5, _mat_size/2-0.5, _mat_size-0.5])\n",
    "            axp.set_xticklabels([-_flank//1000, 0, _flank//1000], fontsize=4)\n",
    "            axp.tick_params(length=1.5, pad=1)\n",
    "            for _tidx, tick in enumerate(axp.xaxis.get_majorticklabels()):\n",
    "                if _tidx == 0:\n",
    "                    tick.set_horizontalalignment(\"left\")\n",
    "                elif _tidx == 2:\n",
    "                    tick.set_horizontalalignment(\"right\")\n",
    "                else:\n",
    "                    tick.set_horizontalalignment(\"center\")\n",
    "        # for the very last one ... - do ticks again ...\n",
    "        if i == len(timecourse_samples) - 1:\n",
    "            axp.yaxis.tick_right()\n",
    "            axp.set_yticks(\n",
    "                [0-0.5, _mat_size/2-0.5, _mat_size-0.5],\n",
    "                labels=[-_flank//1000, 0, _flank//1000],\n",
    "                rotation=90,\n",
    "                fontsize=4,\n",
    "            )\n",
    "            axp.tick_params(length=1.5, pad=1)\n",
    "            for _tidx, tick in enumerate(axp.yaxis.get_majorticklabels()):\n",
    "                if _tidx == 0:\n",
    "                    tick.set_verticalalignment(\"top\")\n",
    "                elif _tidx == 2:\n",
    "                    tick.set_verticalalignment(\"bottom\")\n",
    "                else:\n",
    "                    tick.set_verticalalignment(\"center\")\n",
    "\n",
    "\n",
    "_timepoints = [0,1,2,4]\n",
    "_tp_labels = [\"M\",\"T\",\"C\",\"G1\"]\n",
    "for j, _cond in enumerate(_plot_conditions):\n",
    "    ax = axq[_cond]\n",
    "    _mtx = _dfff_dict[_cond].index\n",
    "    m_course = []\n",
    "    p_course = []\n",
    "    for i, _sample in enumerate(timecourse_samples):\n",
    "        # going over groupings (by dist, or whatever ...)\n",
    "        Cm = np.nanmean(fullstacks_cis[f'm{_sample}'][_mtx], axis=0)\n",
    "        Cp = np.nanmean(fullstacks_cis[f'p{_sample}'][_mtx], axis=0)\n",
    "        m_course.append( get_score( Cm, hw_in=2, hw_out=4) )\n",
    "        p_course.append( get_score( Cp, hw_in=2, hw_out=4) )\n",
    "        _score = get_score( Cm, hw_in=2, hw_out=4)\n",
    "    # put number of items overhere ...\n",
    "    ax.text(0.5, 0.5, f'#{len(_mtx)}', ha='center', va='center', fontsize=6, transform = ax.transAxes)\n",
    "    ax.plot(_timepoints, m_course, lw=0.5, color=\"blue\")\n",
    "    ax.plot(_timepoints, p_course, lw=0.5, color=\"red\")\n",
    "    ax.set_ylim(1.125, 2.275)\n",
    "    ax.set_yticks(\n",
    "        [1.125, 1.7, 2.275],\n",
    "        labels=[\"1.1\", \"1.7\", \"2.3\"],\n",
    "        rotation=90,\n",
    "        fontsize=4,\n",
    "    )\n",
    "    ax.tick_params(length=1.0, pad=0.0)\n",
    "    for _tidx, tick in enumerate(ax.yaxis.get_majorticklabels()):\n",
    "        if _tidx == 0:\n",
    "            tick.set_verticalalignment(\"bottom\")\n",
    "        elif _tidx ==1:\n",
    "            tick.set_verticalalignment(\"center\")\n",
    "        else:\n",
    "            tick.set_verticalalignment(\"top\")\n",
    "    ax.set_xlim(_timepoints[0], _timepoints[-1])\n",
    "    if j == 0:\n",
    "        ax.tick_params(axis=\"x\", length=1.5, pad=1)\n",
    "        ax.set_xticks(\n",
    "            _timepoints,\n",
    "            labels=_tp_labels,\n",
    "            fontsize=4,\n",
    "        )\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax], fontsize=5)\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "for _tidx, tick in enumerate(cbar_ax.xaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_horizontalalignment(\"left\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_horizontalalignment(\"right\")\n",
    "    else:\n",
    "        tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "\n",
    "plt.savefig(\"fig5H_timecourse.svg\", dpi=300)\n",
    "\n",
    "! cairosvg --format pdf -o fig5H_timecourse.pdf fig5H_timecourse.svg\n",
    "! cairosvg --format png --background white -o fig5H_timecourse.png fig5H_timecourse.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0bb75e-4d04-45fa-8c5f-29373de4f151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788542b5-f14f-405b-bbe7-e7c7941cf1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9a7a5-ef9c-4750-a599-4982c308e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2\n",
    "tcourse_spacing = 0.1\n",
    "matw = 0.35\n",
    "cbarh = 0.07\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"nearest\",\n",
    ")\n",
    "\n",
    "timecourse_samples = [\"N93m5\", \"N93p5\"]\n",
    "# timecourse_samples = [\"N93m5\",\"N93m10\", \"N93p5\", \"N93p10\"]\n",
    "_nsamples = len(timecourse_samples)\n",
    "\n",
    "_plot_conditions = [\n",
    "    \"inter-dotless\",\n",
    "    \"inter-dotted\",\n",
    "    \"intra-dotted\",\n",
    "    \"intra-exact\",\n",
    "]\n",
    "_nconds = len(_plot_conditions)\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = [ Size.Fixed(margin) ] + \\\n",
    "    (_nsamples-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(margin)  ]\n",
    "# goes from bottom to the top ...\n",
    "v = [ Size.Fixed(margin), Size.Fixed(cbarh), Size.Fixed(0.5*margin), ] + \\\n",
    "    (_nconds-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin), ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(margin), ]\n",
    "# ...\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "# ...\n",
    "axs = {}\n",
    "for i, _sample in enumerate(timecourse_samples):\n",
    "    axs[_sample] = {}\n",
    "    nx = 2*i + 1\n",
    "    for j, _cond in enumerate(_plot_conditions):\n",
    "        ny = 2*(j+1) + 1\n",
    "        axs[_sample][_cond] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=nx, ny=ny))\n",
    "\n",
    "\n",
    "for ax in sum( [list(_d.values()) for c,_d in axs.items()], start=[] ):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "cbar_ax = fig.add_axes(\n",
    "    divider.get_position(),\n",
    "    axes_locator=divider.new_locator(nx=nx, ny=1)\n",
    ")\n",
    "cbar_ax.set_xticks([])\n",
    "cbar_ax.set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "for i, _sample in enumerate(timecourse_samples):\n",
    "    for j, _cond in enumerate(_plot_conditions):\n",
    "        ax = axs[_sample][_cond]\n",
    "        _mtx = _dfff_dict[_cond].index\n",
    "        # going over groupings (by dist, or whatever ...)\n",
    "        C = np.nanmean(fullstacks_cis[_sample][_mtx], axis=0)\n",
    "        _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "        _ccc.cmap.set_over(\"#300000\")\n",
    "        # ...\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # ylabel\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f\"{_cond}\", fontsize=4, labelpad=1)\n",
    "        if j == len(_plot_conditions) - 1:\n",
    "            ax.set_title(f\"{_sample}\", fontsize=4, pad=1)\n",
    "        # add ticks ...\n",
    "        _mat_size = C.shape[0]\n",
    "        if j == 0:\n",
    "            ax.set_xticks([0-0.5, _mat_size/2-0.5, _mat_size-0.5])\n",
    "            ax.set_xticklabels([-_flank//1000, 0, _flank//1000], fontsize=4)\n",
    "            ax.tick_params(length=1.5, pad=1)\n",
    "            for _tidx, tick in enumerate(ax.xaxis.get_majorticklabels()):\n",
    "                if _tidx == 0:\n",
    "                    tick.set_horizontalalignment(\"left\")\n",
    "                elif _tidx == 2:\n",
    "                    tick.set_horizontalalignment(\"right\")\n",
    "                else:\n",
    "                    tick.set_horizontalalignment(\"center\")\n",
    "        # for the very last one ... - do ticks again ...\n",
    "        if i == len(timecourse_samples) - 1:\n",
    "            ax.yaxis.tick_right()\n",
    "            ax.set_yticks(\n",
    "                [0-0.5, _mat_size/2-0.5, _mat_size-0.5],\n",
    "                labels=[-_flank//1000, 0, _flank//1000],\n",
    "                rotation=90,\n",
    "                fontsize=4,\n",
    "            )\n",
    "            ax.tick_params(length=1.5, pad=1)\n",
    "            for _tidx, tick in enumerate(ax.yaxis.get_majorticklabels()):\n",
    "                if _tidx == 0:\n",
    "                    tick.set_verticalalignment(\"top\")\n",
    "                elif _tidx == 2:\n",
    "                    tick.set_verticalalignment(\"bottom\")\n",
    "                else:\n",
    "                    tick.set_verticalalignment(\"center\")\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax], fontsize=5)\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "for _tidx, tick in enumerate(cbar_ax.xaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_horizontalalignment(\"left\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_horizontalalignment(\"right\")\n",
    "    else:\n",
    "        tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "\n",
    "plt.savefig(\"figExt5D_nup.svg\", dpi=300)\n",
    "\n",
    "! cairosvg --format pdf -o figExt5D_nup.pdf figExt5D_nup.svg\n",
    "! cairosvg --format png --background white -o figExt5D_nup.png figExt5D_nup.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d31b5c-679a-4c99-bf32-2618fc99b024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315bce9b-b305-48f8-8649-9576337056de",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_intra_arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111ed1a-8829-460e-91ac-e5bb8dee2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2\n",
    "tcourse_spacing = 0.1\n",
    "matw = 0.35\n",
    "cbarh = 0.07\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"nearest\",\n",
    ")\n",
    "\n",
    "timecourse_samples = list(reversed([\"m10hR1R2\", \"p10hR1R2\", \"mp10hR1R2\",]))\n",
    "_nsamples = len(timecourse_samples)\n",
    "\n",
    "_plot_conditions_sbgrp1 = [\n",
    "    \"short\",\n",
    "    \"mid\",\n",
    "    \"long\",\n",
    "    \"trans\",\n",
    "]\n",
    "\n",
    "# deal with short and long range stuff ...\n",
    "dist_bins = [0, 1_000_000, 10_000_000, 300_000_000]\n",
    "\n",
    "_plot_conditions_sbgrp2 = [\n",
    "    \"inter-dotless\",\n",
    "    \"inter-dotted\",\n",
    "    \"intra-dotted\",\n",
    "    \"intra-exact\",\n",
    "]\n",
    "_plot_conditions_sbgrp2 = list(reversed(_plot_conditions_sbgrp2))\n",
    "_nconds1 = len(_plot_conditions_sbgrp1)\n",
    "_nconds2 = len(_plot_conditions_sbgrp2)\n",
    "_nconds = _nconds1 + _nconds2\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = [ Size.Fixed(margin) ] + \\\n",
    "    (_nconds1-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(tcourse_spacing) ] + \\\n",
    "    (_nconds2-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(margin) ]\n",
    "# goes from bottom to the top ...\n",
    "v = [ Size.Fixed(margin), Size.Fixed(cbarh), Size.Fixed(0.5*margin), ] + \\\n",
    "    (_nsamples-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin), ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(margin), ]\n",
    "# ...\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "# ...\n",
    "axs = {}\n",
    "for i, _cond in enumerate((_plot_conditions_sbgrp1 + _plot_conditions_sbgrp2)):\n",
    "    axs[_cond] = {}\n",
    "    nx = 2*i + 1\n",
    "    for j, _sample in enumerate(timecourse_samples):\n",
    "        ny = 2*(j+1) + 1\n",
    "        axs[_cond][_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=nx, ny=ny))\n",
    "\n",
    "\n",
    "for ax in sum( [list(_d.values()) for c,_d in axs.items()], start=[] ):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "cbar_ax = fig.add_axes(\n",
    "    divider.get_position(),\n",
    "    axes_locator=divider.new_locator(nx=nx, ny=1)\n",
    ")\n",
    "cbar_ax.set_xticks([])\n",
    "cbar_ax.set_yticks([])\n",
    "\n",
    "# stack_means[_sample]\n",
    "\n",
    "_trans_idx = 2  # all !\n",
    "\n",
    "for i, _cond in enumerate(_plot_conditions_sbgrp1 + _plot_conditions_sbgrp2):\n",
    "    for j, _sample in enumerate(timecourse_samples):\n",
    "        ax = axs[_cond][_sample]\n",
    "        if _cond.startswith(\"in\"):\n",
    "            _mtx = _dfff_dict[_cond].index\n",
    "            # going over groupings (by dist, or whatever ...)\n",
    "            C = np.nanmean(fullstacks_cis[_sample][_mtx], axis=0)\n",
    "            _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "            _ccc.cmap.set_over(\"#300000\")\n",
    "        elif _cond == \"trans\":\n",
    "            C = stack_means[_sample][_trans_idx]\n",
    "            _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "            _ccc.cmap.set_over(\"#300000\")\n",
    "        elif _cond == \"short\":\n",
    "            _mtx = _df_intra_arm.query(\" dist < @dist_bins[1] \").index\n",
    "            C = np.nanmean(fullstacks_cis[_sample][_mtx], axis=0)\n",
    "            _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "            _ccc.cmap.set_over(\"#300000\")\n",
    "        elif _cond == \"mid\":\n",
    "            _mtx = _df_intra_arm.query(\" @dist_bins[1] < dist < @dist_bins[2] \").index\n",
    "            C = np.nanmean(fullstacks_cis[_sample][_mtx], axis=0)\n",
    "            _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "            _ccc.cmap.set_over(\"#300000\")\n",
    "        elif _cond == \"long\":\n",
    "            _mtx = _df_intra_arm.query(\" @dist_bins[2] < dist \").index\n",
    "            C = np.nanmean(fullstacks_cis[_sample][_mtx], axis=0)\n",
    "            _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "            _ccc.cmap.set_over(\"#300000\")\n",
    "        # ylabel\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f\"{_sample}\", fontsize=4, labelpad=1)\n",
    "        if j == len(timecourse_samples) - 1:\n",
    "            ax.set_title(f\"{_cond}\", fontsize=4, pad=1)\n",
    "            if _cond == \"short\":\n",
    "                ax.set_title(f\"{_cond}: <{dist_bins[1]//1000000}Mb\", fontsize=4, pad=1)\n",
    "            elif _cond == \"mid\":\n",
    "                ax.set_title(f\"{_cond}: {dist_bins[1]//1000000}-{dist_bins[2]//1000000}Mb\", fontsize=4, pad=1)\n",
    "            elif _cond == \"long\":\n",
    "                ax.set_title(f\"{_cond}: >{dist_bins[2]//1000000}Mb\", fontsize=4, pad=1)\n",
    "        # add ticks ...\n",
    "        _mat_size = C.shape[0]\n",
    "        if j == 0:\n",
    "            ax.set_xticks([0-0.5, _mat_size/2-0.5, _mat_size-0.5])\n",
    "            ax.set_xticklabels([-_flank//1000, 0, _flank//1000], fontsize=4)\n",
    "            ax.tick_params(length=1.5, pad=1)\n",
    "            for _tidx, tick in enumerate(ax.xaxis.get_majorticklabels()):\n",
    "                if _tidx == 0:\n",
    "                    tick.set_horizontalalignment(\"left\")\n",
    "                elif _tidx == 2:\n",
    "                    tick.set_horizontalalignment(\"right\")\n",
    "                else:\n",
    "                    tick.set_horizontalalignment(\"center\")\n",
    "        # for the very last one ... - do ticks again ...\n",
    "        if i == _nconds - 1:\n",
    "            ax.yaxis.tick_right()\n",
    "            ax.set_yticks(\n",
    "                [0-0.5, _mat_size/2-0.5, _mat_size-0.5],\n",
    "                labels=[-_flank//1000, 0, _flank//1000],\n",
    "                rotation=90,\n",
    "                fontsize=4,\n",
    "            )\n",
    "            ax.tick_params(length=1.5, pad=1)\n",
    "            for _tidx, tick in enumerate(ax.yaxis.get_majorticklabels()):\n",
    "                if _tidx == 0:\n",
    "                    tick.set_verticalalignment(\"top\")\n",
    "                elif _tidx == 2:\n",
    "                    tick.set_verticalalignment(\"bottom\")\n",
    "                else:\n",
    "                    tick.set_verticalalignment(\"center\")\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax], fontsize=5)\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "for _tidx, tick in enumerate(cbar_ax.xaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_horizontalalignment(\"left\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_horizontalalignment(\"right\")\n",
    "    else:\n",
    "        tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "\n",
    "plt.savefig(\"figExt7H_pileups.svg\", dpi=300)\n",
    "\n",
    "# ! cairosvg --format pdf -o figExt7H_pileups.pdf figExt7H_pileups.svg\n",
    "# ! cairosvg --format png --background white -o figExt7H_pileups.png figExt7H_pileups.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10365d37-8666-41e6-829c-054be1171940",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2\n",
    "tcourse_spacing = 0.1\n",
    "matw = 0.35\n",
    "cbarh = 0.07\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"nearest\",\n",
    ")\n",
    "\n",
    "timecourse_samples = list(reversed([\"m10hR1R2\", \"p10hR1R2\", \"mp10hR1R2\",]))\n",
    "_nsamples = len(timecourse_samples)\n",
    "\n",
    "_plot_conditions_sbgrp1 = [\n",
    "    \"short\",\n",
    "    \"long\",\n",
    "    \"trans\",\n",
    "]\n",
    "\n",
    "# deal with short and long range stuff ...\n",
    "dist_bins = [0, 1_000_000, 300_000_000]\n",
    "\n",
    "_plot_conditions_sbgrp2 = [\n",
    "    \"inter-dotless\",\n",
    "    \"inter-dotted\",\n",
    "    \"intra-dotted\",\n",
    "    \"intra-exact\",\n",
    "]\n",
    "_plot_conditions_sbgrp2 = list(reversed(_plot_conditions_sbgrp2))\n",
    "_nconds1 = len(_plot_conditions_sbgrp1)\n",
    "_nconds2 = len(_plot_conditions_sbgrp2)\n",
    "_nconds = _nconds1 + _nconds2\n",
    "\n",
    "# The first items are for padding and the second items are for the axes, sizes are in inch.\n",
    "h = [ Size.Fixed(margin) ] + \\\n",
    "    (_nconds1-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(tcourse_spacing) ] + \\\n",
    "    (_nconds2-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin) ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(margin) ]\n",
    "# goes from bottom to the top ...\n",
    "v = [ Size.Fixed(margin), Size.Fixed(cbarh), Size.Fixed(0.5*margin), ] + \\\n",
    "    (_nsamples-1)*[ Size.Fixed(matw), Size.Fixed(0.25*margin), ] + \\\n",
    "    [ Size.Fixed(matw), Size.Fixed(margin), ]\n",
    "# ...\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "# ...\n",
    "axs = {}\n",
    "for i, _cond in enumerate((_plot_conditions_sbgrp1 + _plot_conditions_sbgrp2)):\n",
    "    axs[_cond] = {}\n",
    "    nx = 2*i + 1\n",
    "    for j, _sample in enumerate(timecourse_samples):\n",
    "        ny = 2*(j+1) + 1\n",
    "        axs[_cond][_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=nx, ny=ny))\n",
    "\n",
    "\n",
    "for ax in sum( [list(_d.values()) for c,_d in axs.items()], start=[] ):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "cbar_ax = fig.add_axes(\n",
    "    divider.get_position(),\n",
    "    axes_locator=divider.new_locator(nx=nx, ny=1)\n",
    ")\n",
    "cbar_ax.set_xticks([])\n",
    "cbar_ax.set_yticks([])\n",
    "\n",
    "# stack_means[_sample]\n",
    "\n",
    "_trans_idx = 2  # all !\n",
    "\n",
    "for i, _cond in enumerate(_plot_conditions_sbgrp1 + _plot_conditions_sbgrp2):\n",
    "    for j, _sample in enumerate(timecourse_samples):\n",
    "        ax = axs[_cond][_sample]\n",
    "        if _cond.startswith(\"in\"):\n",
    "            _mtx = _dfff_dict[_cond].index\n",
    "            # going over groupings (by dist, or whatever ...)\n",
    "            C = np.nanmean(fullstacks_cis[_sample][_mtx], axis=0)\n",
    "            _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "            _ccc.cmap.set_over(\"#300000\")\n",
    "        elif _cond == \"trans\":\n",
    "            C = stack_means[_sample][_trans_idx]\n",
    "            _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "            _ccc.cmap.set_over(\"#300000\")\n",
    "        elif _cond == \"short\":\n",
    "            _mtx = _df_intra_arm.query(\" dist < @dist_bins[1] \").index\n",
    "            C = np.nanmean(fullstacks_cis[_sample][_mtx], axis=0)\n",
    "            _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "            _ccc.cmap.set_over(\"#300000\")\n",
    "        elif _cond == \"long\":\n",
    "            _mtx = _df_intra_arm.query(\" @dist_bins[1] < dist \").index\n",
    "            C = np.nanmean(fullstacks_cis[_sample][_mtx], axis=0)\n",
    "            _ccc = ax.imshow( C, **imshow_kwargs )\n",
    "            _ccc.cmap.set_over(\"#300000\")\n",
    "        # ylabel\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f\"{_sample}\", fontsize=4, labelpad=1)\n",
    "        if j == len(timecourse_samples) - 1:\n",
    "            ax.set_title(f\"{_cond}\", fontsize=4, pad=1)\n",
    "            if _cond == \"short\":\n",
    "                ax.set_title(f\"{_cond}: <{dist_bins[1]//1000000}Mb\", fontsize=4, pad=1)\n",
    "            elif _cond == \"long\":\n",
    "                ax.set_title(f\"{_cond}: >{dist_bins[1]//1000000}Mb\", fontsize=4, pad=1)\n",
    "            else:\n",
    "                pass\n",
    "        # add ticks ...\n",
    "        _mat_size = C.shape[0]\n",
    "        if j == 0:\n",
    "            ax.set_xticks([0-0.5, _mat_size/2-0.5, _mat_size-0.5])\n",
    "            ax.set_xticklabels([-_flank//1000, 0, _flank//1000], fontsize=4)\n",
    "            ax.tick_params(length=1.5, pad=1)\n",
    "            for _tidx, tick in enumerate(ax.xaxis.get_majorticklabels()):\n",
    "                if _tidx == 0:\n",
    "                    tick.set_horizontalalignment(\"left\")\n",
    "                elif _tidx == 2:\n",
    "                    tick.set_horizontalalignment(\"right\")\n",
    "                else:\n",
    "                    tick.set_horizontalalignment(\"center\")\n",
    "        # for the very last one ... - do ticks again ...\n",
    "        if i == _nconds - 1:\n",
    "            ax.yaxis.tick_right()\n",
    "            ax.set_yticks(\n",
    "                [0-0.5, _mat_size/2-0.5, _mat_size-0.5],\n",
    "                labels=[-_flank//1000, 0, _flank//1000],\n",
    "                rotation=90,\n",
    "                fontsize=4,\n",
    "            )\n",
    "            ax.tick_params(length=1.5, pad=1)\n",
    "            for _tidx, tick in enumerate(ax.yaxis.get_majorticklabels()):\n",
    "                if _tidx == 0:\n",
    "                    tick.set_verticalalignment(\"top\")\n",
    "                elif _tidx == 2:\n",
    "                    tick.set_verticalalignment(\"bottom\")\n",
    "                else:\n",
    "                    tick.set_verticalalignment(\"center\")\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "cbar_ax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cbar_ax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax], fontsize=5)\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.5, pad=1)  #,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "for _tidx, tick in enumerate(cbar_ax.xaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_horizontalalignment(\"left\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_horizontalalignment(\"right\")\n",
    "    else:\n",
    "        tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "\n",
    "plt.savefig(\"figExt7H_pileups.svg\", dpi=300)\n",
    "\n",
    "# ! cairosvg --format pdf -o figExt7H_pileups.pdf figExt7H_pileups.svg\n",
    "# ! cairosvg --format png --background white -o figExt7H_pileups.png figExt7H_pileups.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9369c-7236-425b-88e5-7e0933419eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be449fc3-50b8-4fbe-b5af-77a566c99718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88741a5-d8ee-4231-9d26-3b9d23052e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5390a64-e77d-4c6b-bc46-fc95a99ee2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad455aa-2df5-4c41-850f-eda9e05a21a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f588d3-10ec-4398-85a5-155373dff825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd0704-1402-499d-8042-0a5e079f3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_flank = 100_000\n",
    "# dist_bins = [0, 250_000, 1_500_000, 15_000_000, 100_000_000]\n",
    "dist_bins = [0, 300_000_000]\n",
    "\n",
    "# reusing the same groups from _dfff_dict ...\n",
    "\n",
    "f, axs = plt.subplots(\n",
    "    nrows=len(_dfff_dict),\n",
    "    ncols=1,\n",
    "    figsize=(2.5,12),\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    ")\n",
    "\n",
    "\n",
    "for ax, (_id, _dfff) in zip(axs, _dfff_dict.items()):\n",
    "    print(_id)\n",
    "    ggg = _dfff.groupby(pd.cut( _dfff[\"dist\"], dist_bins ))\n",
    "    nquants = len(ggg)\n",
    "    # ...\n",
    "    # ...\n",
    "    for _sample_group in _select_sample_groups:\n",
    "        _tp = []\n",
    "        for i, k in enumerate(_sample_group):\n",
    "            # going over samples ...\n",
    "            _stacks = fullstacks_cis[k]\n",
    "            for j, (_q, _mtx) in enumerate(ggg.groups.items()):\n",
    "                # going over groupings (by dist, or whatever ...)\n",
    "                mmm = np.nanmean(_stacks[_mtx], axis=0)\n",
    "                _score = get_score( mmm, hw_in=2, hw_out=4)\n",
    "                _tp.append(_score)\n",
    "        ax.plot(_tp)\n",
    "        ax.set_title(_id)\n",
    "        ax.set_xticks([0,1,2,3,4])\n",
    "        ax.set_xticklabels([\"m\",\"t\",\"c\",\"5\",\"10\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3dbe6-986f-470e-99de-f28469c22917",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s.lstrip(\"m\") for s in _select_sample_groups[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e0103-669e-4aaf-a081-4ab648078b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "_flank = 100_000\n",
    "# dist_bins = [0, 250_000, 1_500_000, 15_000_000, 100_000_000]\n",
    "dist_bins = [0, 300_000_000]\n",
    "\n",
    "# reusing the same groups from _dfff_dict ...\n",
    "\n",
    "f, axs = plt.subplots(\n",
    "    nrows=len(_dfff_dict),\n",
    "    ncols=len(_select_sample_groups[0]),\n",
    "    figsize=(12,12),\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, (_axs, (_id, _dfff)) in enumerate(zip(axs, _dfff_dict.items())):\n",
    "    print(_id)\n",
    "    ggg = _dfff.groupby(pd.cut( _dfff[\"dist\"], dist_bins ))\n",
    "    nquants = len(ggg)\n",
    "    # going over samples ...\n",
    "    for j, k in enumerate([s.lstrip(\"m\") for s in _select_sample_groups[0]]):\n",
    "        ax = _axs[j]\n",
    "        for _q, _mtx in ggg.groups.items():\n",
    "            # going over groupings (by dist, or whatever ...)\n",
    "            mmmm = np.nanmean(fullstacks_cis[f'm{k}'][_mtx], axis=0)\n",
    "            mmmp = np.nanmean(fullstacks_cis[f'p{k}'][_mtx], axis=0)\n",
    "            # _score = get_score( mmm, hw_in=2, hw_out=4)\n",
    "            # _tp.append(_score)\n",
    "            _ccc = ax.imshow(\n",
    "                mmmm/mmmp,\n",
    "                cmap='RdBu_r',\n",
    "                # cmap='coolwarm',\n",
    "                norm=LogNorm(vmin=1/2.25,vmax=2.25),\n",
    "            )\n",
    "            _ccc.cmap.set_over(\"#400000\")\n",
    "            ticks_pixels = np.linspace(0, _flank*2//binsize10, 5)\n",
    "            ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*binsize10//1000).astype(int)\n",
    "            if j == 0:\n",
    "                # top row\n",
    "                ax.set_ylabel(f\"{_id}: m/p\", fontsize=12)\n",
    "            if i == 0:\n",
    "                ax.set_title(k)\n",
    "            if i == len(_dfff_dict)-1:\n",
    "                ax.set_xticks(ticks_pixels, ticks_kbp)\n",
    "                ax.set_xlabel('relative position, kbp')\n",
    "            ax.set_yticks(ticks_pixels, ticks_kbp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847aa7bb-ab4d-4da6-8f58-e9edad7dfd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggg.groups.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e91e86-f728-48f0-99fe-0bc335bc84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_flank = 100_000\n",
    "# dist_bins = [0, 250_000, 1_500_000, 15_000_000, 100_000_000]\n",
    "dist_bins = [0, 300_000_000]\n",
    "\n",
    "# reusing the same groups from _dfff_dict ...\n",
    "\n",
    "\n",
    "\n",
    "for _id, _dfff in _dfff_dict.items():\n",
    "    ggg = _dfff.groupby(pd.cut( _dfff[\"dist\"], dist_bins ))\n",
    "    nquants = len(ggg)\n",
    "    # f, axs = plt.subplots(\n",
    "    #     nrows=1,\n",
    "    #     ncols=len(_select_sample_groups[0]),\n",
    "    #     figsize=(15,2.5),\n",
    "    #     sharey=True,\n",
    "    #     sharex=True,\n",
    "    # )\n",
    "    # # ...\n",
    "    for _sample_group in [_select_sample_groups[0]]:\n",
    "        f, axs = plt.subplots(\n",
    "            ncols=len(_sample_group),\n",
    "            nrows=len(ggg),\n",
    "            figsize=(3*len(_sample_group), 3*len(ggg)),\n",
    "            # width_ratios=[1]*nquants,\n",
    "            sharex=True,\n",
    "            sharey=True,\n",
    "            squeeze=False,\n",
    "        )\n",
    "        # gs = axs[0, -1].get_gridspec()\n",
    "        # # remove axes for the last column ...\n",
    "        # for ax in axs[:, -1]:\n",
    "        #     ax.remove()\n",
    "        #\n",
    "        # axcb = f.add_subplot(gs[1:3, -1])\n",
    "        #\n",
    "        for i, (_axs, k) in enumerate(zip(axs.T,_sample_group)):\n",
    "            # going over samples ...\n",
    "            _stacks = fullstacks_cis[k]\n",
    "            print(k)\n",
    "            for j, (ax, (_q, _mtx)) in enumerate(zip(_axs, ggg.groups.items())):\n",
    "                # going over groupings (by dist, or whatever ...)\n",
    "                _ccc = ax.imshow(\n",
    "                    np.nanmean(_stacks[_mtx], axis=0),\n",
    "                    cmap='RdBu_r',\n",
    "                    norm=LogNorm(vmin=1/2.5,vmax=2.5),\n",
    "                    # norm=LogNorm(vmin=1/1250,vmax=1250),\n",
    "                    # norm=LogNorm(vmin=1/3,vmax=3),\n",
    "                )\n",
    "                _ccc.cmap.set_over(\"#400000\")\n",
    "                ticks_pixels = np.linspace(0, _flank*2//binsize10, 5)\n",
    "                ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*binsize10//1000).astype(int)\n",
    "                if j == 0:\n",
    "                    # top row\n",
    "                    ax.set_title(f\"{k}\", fontsize=14)\n",
    "                if i == 0:\n",
    "                    _axname = _get_name(_q.left, _q.right, len(_mtx))\n",
    "                    ax.set_ylabel(f\"{_id}::{_axname}\")\n",
    "                if i == len(_sample_group)-1:\n",
    "                    ax.set_xticks(ticks_pixels, ticks_kbp)\n",
    "                    ax.set_xlabel('relative position, kbp')\n",
    "                ax.set_yticks(ticks_pixels, ticks_kbp)\n",
    "                # if j<1:\n",
    "                #     ax.set_title(f\"{k}\", fontsize=14)\n",
    "                #\n",
    "        # plt.colorbar(_ccc, label=\"obs/exp\", cax=axcb)\n",
    "    # cs.cmap.set_under('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d423bc0-e39f-43cd-b118-d27f35bba0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680ba04-4410-4242-a4e3-f3d5471493b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a25fcc-05c1-45af-b34c-2efae46ee798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pileup select samples only !\n",
    "_select_sample_groups = [\n",
    "    [\n",
    "        \"m10hR1R2\",\n",
    "        \"p10hR1R2\",\n",
    "        \"mp10hR1R2\",\n",
    "        \"N93m5\",\n",
    "        \"N93m10\",\n",
    "        \"N93p5\",\n",
    "        \"N93p10\",\n",
    "        \"N93mp10\",\n",
    "    ],\n",
    "    # # # p-ones\n",
    "    # [\n",
    "    #     \"pMito\",\n",
    "    #     \"pTelo\",\n",
    "    #     \"pCyto\",\n",
    "    #     \"p5hR1R2\",\n",
    "    #     \"p10hR1R2\",\n",
    "    # ],\n",
    "]\n",
    "\n",
    "\n",
    "_flank = 100_000\n",
    "# dist_bins = [0, 250_000, 1_500_000, 15_000_000, 100_000_000]\n",
    "dist_bins = [0, 300_000_000]\n",
    "\n",
    "# reusing the same groups from _dfff_dict ...\n",
    "\n",
    "\n",
    "\n",
    "for _id, _dfff in _dfff_dict.items():\n",
    "    ggg = _dfff.groupby(pd.cut( _dfff[\"dist\"], dist_bins ))\n",
    "    nquants = len(ggg)\n",
    "    # f, axs = plt.subplots(\n",
    "    #     nrows=1,\n",
    "    #     ncols=len(_select_sample_groups[0]),\n",
    "    #     figsize=(15,2.5),\n",
    "    #     sharey=True,\n",
    "    #     sharex=True,\n",
    "    # )\n",
    "    # # ...\n",
    "    for _sample_group in [_select_sample_groups[0]]:\n",
    "        f, axs = plt.subplots(\n",
    "            ncols=len(_sample_group),\n",
    "            nrows=len(ggg),\n",
    "            figsize=(3*len(_sample_group), 3*len(ggg)),\n",
    "            # width_ratios=[1]*nquants,\n",
    "            sharex=True,\n",
    "            sharey=True,\n",
    "            squeeze=False,\n",
    "        )\n",
    "        # gs = axs[0, -1].get_gridspec()\n",
    "        # # remove axes for the last column ...\n",
    "        # for ax in axs[:, -1]:\n",
    "        #     ax.remove()\n",
    "        #\n",
    "        # axcb = f.add_subplot(gs[1:3, -1])\n",
    "        #\n",
    "        for i, (_axs, k) in enumerate(zip(axs.T,_sample_group)):\n",
    "            # going over samples ...\n",
    "            _stacks = fullstacks_cis[k]\n",
    "            print(k)\n",
    "            for j, (ax, (_q, _mtx)) in enumerate(zip(_axs, ggg.groups.items())):\n",
    "                # going over groupings (by dist, or whatever ...)\n",
    "                _ccc = ax.imshow(\n",
    "                    np.nanmean(_stacks[_mtx], axis=0),\n",
    "                    cmap='RdBu_r',\n",
    "                    norm=LogNorm(vmin=1/2.25,vmax=2.25),\n",
    "                    # norm=LogNorm(vmin=1/1250,vmax=1250),\n",
    "                    # norm=LogNorm(vmin=1/3,vmax=3),\n",
    "                )\n",
    "                _ccc.cmap.set_over(\"#400000\")\n",
    "                ticks_pixels = np.linspace(0, _flank*2//binsize10, 5)\n",
    "                ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*binsize10//1000).astype(int)\n",
    "                if j == 0:\n",
    "                    # top row\n",
    "                    ax.set_title(f\"{k}\", fontsize=14)\n",
    "                if i == 0:\n",
    "                    _axname = _get_name(_q.left, _q.right, len(_mtx))\n",
    "                    ax.set_ylabel(f\"{_id}::{_axname}\")\n",
    "                if i == len(_sample_group)-1:\n",
    "                    ax.set_xticks(ticks_pixels, ticks_kbp)\n",
    "                    ax.set_xlabel('relative position, kbp')\n",
    "                ax.set_yticks(ticks_pixels, ticks_kbp)\n",
    "                # if j<1:\n",
    "                #     ax.set_title(f\"{k}\", fontsize=14)\n",
    "                #\n",
    "        # plt.colorbar(_ccc, label=\"obs/exp\", cax=axcb)\n",
    "    # cs.cmap.set_under('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51094b-8c96-483b-b44d-b63f8bf3c769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
