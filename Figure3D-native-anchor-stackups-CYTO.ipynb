{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9fef6-8b4c-43ff-a807-8ff097f5c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of threads for many common libraries\n",
    "from os import environ\n",
    "N_THREADS = '1'\n",
    "environ['OMP_NUM_THREADS'] = N_THREADS\n",
    "environ['OPENBLAS_NUM_THREADS'] = N_THREADS\n",
    "\n",
    "environ['MKL_NUM_THREADS'] = N_THREADS\n",
    "environ['VECLIB_MAXIMUM_THREADS'] = N_THREADS\n",
    "environ['NUMEXPR_NUM_THREADS'] = N_THREADS\n",
    "\n",
    "# https://superfastpython.com/numpy-number-blas-threads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d52a96-52d5-4b0a-b50e-d3b5ae0f7649",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from saddle import saddleplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77a148-ef01-4d12-938b-7e27bbe92e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "# Hi-C utilities imports:\n",
    "import cooler\n",
    "import bioframe\n",
    "import cooltools\n",
    "from cooltools.lib.numutils import fill_diag\n",
    "\n",
    "# Visualization imports:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import EngFormatter\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "# from ipywidgets import interact, fixed\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# enable editable text ...\n",
    "mpl.rcParams[\"pdf.fonttype\"]=42\n",
    "mpl.rcParams[\"svg.fonttype\"]=\"none\"\n",
    "mpl.rcParams['axes.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1518684-b18d-427f-a8ac-4dc9196da45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade --no-cache --no-deps --ignore-install cooler\n",
    "# ls /home/dekkerlab/dots-test\n",
    "# import higlass as hg\n",
    "# import jscatter\n",
    "import scipy\n",
    "import logging\n",
    "import multiprocess as mp\n",
    "# import mpire for nested multi-processing\n",
    "from mpire import WorkerPool\n",
    "# bbi for stackups ...\n",
    "import bbi\n",
    "from data_catalog import bws, bws_vlim, telo_dict\n",
    "from helper_func import get_stack, show_stacks, plot_stackups_lite, plot_stackups_sets, to_bigbed3\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba3fb11-3c0e-4213-91a4-62d32303f187",
   "metadata": {},
   "source": [
    "### arms here just in case ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913bc019-e027-4cd1-8d2c-1b480839fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define genomic view that will be used to call dots and pre-compute expected\n",
    "\n",
    "# Use bioframe to fetch the genomic features from the UCSC.\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "hg38_arms_full = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "# autosomal only ...\n",
    "included_arms = hg38_arms_full[\"name\"].to_list()[:44]\n",
    "hg38_arms = hg38_arms_full[hg38_arms_full[\"name\"].isin(included_arms)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61b886-642a-4ab9-9660-bdab319b5c72",
   "metadata": {},
   "source": [
    "# Read pre-called Intrinsic Domain anchors - ID anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f169671-ae27-4fa1-b62e-11ced9238e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_anchor_fnames = {\n",
    "    \"mega_2X_enrichment\": \"ID_anchors/mega_2X_enrichment.fourth_mega.max_size.bed\",\n",
    "    \"5hr_2X_enrichment_old\": \"ID_anchors/5hr_2X_enrichment.second_bulk.max_size.bed\",\n",
    "    \"5hr_2X_enrichment\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.bed\",\n",
    "    \"5hr_2X_enrichment_nosing\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.no_singletons.bed\",\n",
    "    \"5hr_notinCyto_2X_enrichment_signal\": \"ID_anchors/p5notin_pCyto_anchors_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"5hr_2X_enrichment_signal\": \"ID_anchors/5hr_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"10hr_2X_enrichment_signal\": \"ID_anchors/10hrs_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"N93p5_2X_enrichment_signal\": \"ID_anchors/N93p5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"pCyto_2X_enrichment_signal\": \"ID_anchors/pCyto_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"mCyto_2X_enrichment_signal\": \"ID_anchors/mCyto_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"mega_3X_enrichment\": \"ID_anchors/mega_3X_enrichment.fifth_mega3x.max_size.bed\",\n",
    "    \"MEGA_2X_enrichment\": \"ID_anchors/MEGAp5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGA_weaker_2X_enrichment\": \"ID_anchors/MEGA_plus_weak_anchors_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGAN93_2X_enrichment\": \"ID_anchors/MEGAN93p5_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"MEGAminus_2X_enrichment\": \"ID_anchors/MEGA_minus_ctrl_2X_enrichment.pixel_derived.signal_peaks.bed\",\n",
    "    \"cyto_2x_enrichment\": \"ID_anchors/cyto_2x_enrichment.third_mCyto.max_size.bed\",\n",
    "}\n",
    "\n",
    "id_anchors_dict = {}\n",
    "for id_name, fname in id_anchor_fnames.items():\n",
    "    id_anchors_dict[id_name] = pd.read_csv(fname, sep=\"\\t\")\n",
    "    # ...\n",
    "    print(f\"loaded {len(id_anchors_dict[id_name]):5d} ID anchors {id_name:>20} in BED format ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b820cf19-aff1-43a4-b4f4-08790b38bfc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T16:02:31.706805Z",
     "iopub.status.busy": "2023-09-18T16:02:31.706321Z",
     "iopub.status.idle": "2023-09-18T16:02:31.709187Z",
     "shell.execute_reply": "2023-09-18T16:02:31.708731Z",
     "shell.execute_reply.started": "2023-09-18T16:02:31.706787Z"
    }
   },
   "source": [
    "### To stackups now ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a67b20-afff-4d01-80c1-59cfa5dbfa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create of the stackup, the flanks are +- 50 Kb, number of bins is 100 :\n",
    "_flank = 100_000 # Length of flank to one side from the boundary, in basepairs\n",
    "_nbins = 200   # Number of bins to split the region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efde0a2-d1ae-479e-a35c-3c79a0721aa1",
   "metadata": {},
   "source": [
    "## predefine few bigwigs and bigbed derivatives of Hi-C for stacking ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906c095-019c-4a7b-95e4-d0495dcb66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls ev_bigwig\n",
    "# bws\n",
    "bws[\"evm\"] = \"ev_bigwig/m5hR1R2.10kb.bw\"\n",
    "bws[\"evp\"] = \"ev_bigwig/p5hR1R2.10kb.bw\"\n",
    "bws[\"idcov\"] = \"pix_clust_cov.bw\"\n",
    "# bws[\"dots\"] = \"mega_dots_anchors.bb\"\n",
    "bws[\"dots\"] = \"mega_final_dots_anchors.bb\"\n",
    "\n",
    "# # plug insulation there jus for fun ...\n",
    "# bws[\"evm\"] = \"ranGAP1-0-G1s-R1R2.hg38.mapq_30.1000.b10000.insul.w50000.bw\"\n",
    "# bws[\"evp\"] = \"ranGAP1-7-G1s-R1R2.hg38.mapq_30.1000.b10000.insul.w50000.bw\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c31237-88f9-418e-8801-f6ede0a9e884",
   "metadata": {},
   "source": [
    "# Create a dictionary with sets of anchors for the Fig 3D plot\n",
    "## Cyto-specific and G1-specific ones ...\n",
    "### the definitive step by step procedure ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1be690-ac1c-4de7-9218-fcce7f111b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcytodf = id_anchors_dict[\"mCyto_2X_enrichment_signal\"]\n",
    "# p10hrdf = id_anchors_dict[\"10hr_2X_enrichment_signal\"]\n",
    "# n93p5hrdf = id_anchors_dict[\"N93p5_2X_enrichment_signal\"]\n",
    "# megadf = id_anchors_dict[\"MEGA_2X_enrichment\"]\n",
    "# megaN93df = id_anchors_dict[\"MEGAN93_2X_enrichment\"]\n",
    "# megaminusdf = id_anchors_dict[\"MEGAminus_2X_enrichment\"]\n",
    "\n",
    "# cooler files that we'll work on :\n",
    "binsize = 10_000\n",
    "telo_clrs = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize}\") for _k, _path in telo_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29705b5-b3e6-480f-a7ff-31d0c354b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc -l \"ID_anchors/pCyto_2X_enrichment.pixel_derived.signal_peaks.bed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4365d32b-38ed-4566-8a36-772a9e03db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_Cyto_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ff7d7-150e-43c6-a863-9d8df1565a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_G1_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ae94c-3b23-4a92-a254-493361812142",
   "metadata": {},
   "outputs": [],
   "source": [
    "_Cyto_anchors = id_anchors_dict[\"pCyto_2X_enrichment_signal\"]\n",
    "_G1_anchors = id_anchors_dict[\"5hr_2X_enrichment_signal\"]\n",
    "\n",
    "\n",
    "cyto_not_in_g1 = bioframe.setdiff(  # Cyto specific one ...\n",
    "    _Cyto_anchors.eval(\n",
    "        \"\"\"\n",
    "        peak_start = peak_start - 100\n",
    "        peak_end = peak_end + 100\n",
    "        \"\"\"\n",
    "    ),\n",
    "    _G1_anchors,\n",
    "    cols1=[\"chrom\",\"peak_start\",\"peak_end\"],\n",
    "    cols2=[\"chrom\",\"peak_start\",\"peak_end\"],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "\n",
    "_Cyto_spec_anchors = bioframe.setdiff(  # Cyto specific one ...\n",
    "    _Cyto_anchors,\n",
    "    cyto_not_in_g1,\n",
    "    cols1=[\"chrom\",\"peak_start\",\"peak_end\"],\n",
    "    cols2=[\"chrom\",\"peak_start\",\"peak_end\"],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "_G1_spec_anchors = bioframe.setdiff(  # G1 5hr specific one ...\n",
    "    _G1_anchors,\n",
    "    _Cyto_anchors,\n",
    "    cols1=[\"chrom\",\"peak_start\",\"peak_end\"],\n",
    "    cols2=[\"chrom\",\"peak_start\",\"peak_end\"],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "len(_Cyto_spec_anchors) , len(_G1_spec_anchors), len(_Cyto_spec_anchors)+len(_G1_spec_anchors)\n",
    "# we need bins/pixels for plotting - instead of genomic coordinates ...\n",
    "\n",
    "# need a reference cooler for that to do genomic coords -> bins:\n",
    "_clr = telo_clrs[\"m5hR1R2\"]\n",
    "# doing that using clr.offset and clr.extent functionality:\n",
    "_G1_spec_anchors[\"bin_id\"] = _G1_spec_anchors[['chrom', 'peak_start', 'peak_end']].apply(_clr.offset, axis=1, result_type=\"expand\")\n",
    "_G1_spec_anchors[\"bin_width\"] = _G1_spec_anchors[['chrom', 'peak_start', 'peak_end']] \\\n",
    "    .apply(_clr.extent, axis=1, result_type=\"expand\") \\\n",
    "    .apply(np.diff, axis=1, result_type=\"expand\")[0]\n",
    "\n",
    "# doing that using clr.offset and clr.extent functionality:\n",
    "_Cyto_spec_anchors[\"bin_id\"] = _Cyto_spec_anchors[['chrom', 'peak_start', 'peak_end']].apply(_clr.offset, axis=1, result_type=\"expand\")\n",
    "_Cyto_spec_anchors[\"bin_width\"] = _Cyto_spec_anchors[['chrom', 'peak_start', 'peak_end']] \\\n",
    "    .apply(_clr.extent, axis=1, result_type=\"expand\") \\\n",
    "    .apply(np.diff, axis=1, result_type=\"expand\")[0]\n",
    "\n",
    "# ...\n",
    "anchor_dict = {\n",
    "    \"pcyto\" : _Cyto_spec_anchors,\n",
    "    \"p5_wo_pCyto\" : _G1_spec_anchors,\n",
    "}\n",
    "# just print numbers ...\n",
    "(\n",
    "    len(anchor_dict[\"pcyto\"]),\n",
    "    len(anchor_dict[\"p5_wo_pCyto\"]),\n",
    "    len(anchor_dict[\"pcyto\"])+len(anchor_dict[\"p5_wo_pCyto\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a694a0-d239-4c01-bb04-ba985693367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_kyes_to_use = [\n",
    "    'mG.atac',\n",
    "    'H3K4me3',\n",
    "    'H3K27ac',\n",
    "    'H3K27me3',\n",
    "    # 'ctcf',\n",
    "    \"evm\",\n",
    "    \"evp\",\n",
    "    # \"ids\",\n",
    "    \"dots\",\n",
    "    \"rg0r1fwd\",\n",
    "    \"rg0r1rev\",\n",
    "]\n",
    "\n",
    "\n",
    "def _job(packed_data, bw_sample):\n",
    "    # unpack shared data\n",
    "    flank, nbins, track_dict, bed_df = packed_data\n",
    "    bw_track = track_dict[bw_sample]\n",
    "    stack_kwargs = dict(kind=\"mid\", flank=flank, nbins=nbins)\n",
    "    from helper_func import get_stack\n",
    "    return (\n",
    "        bw_sample,\n",
    "        get_stack(bw_track, bed_df, **stack_kwargs),\n",
    "    )\n",
    "\n",
    "stackups_anchor_dict = {}\n",
    "for anchor_name, anchors_df in anchor_dict.items():\n",
    "    print(f\"pulling {len(anchors_df)} anchors {anchor_name} ...\")\n",
    "\n",
    "    _shared = (\n",
    "        _flank,\n",
    "        _nbins,\n",
    "        bws,\n",
    "        anchors_df,\n",
    "    )\n",
    "\n",
    "    with WorkerPool(\n",
    "        n_jobs=len(bws),\n",
    "        shared_objects=_shared,\n",
    "        start_method=\"forkserver\",  # little faster than spawn, fork is the fastest\n",
    "        use_dill=True,\n",
    "    ) as wpool:\n",
    "        results = wpool.map(_job, bw_kyes_to_use, progress_bar=True)\n",
    "\n",
    "    # sort out the results ...\n",
    "    stackups_anchor_dict[anchor_name] = {sample: _pstack for sample, _pstack in results}\n",
    "\n",
    "    # Combine RNA + and - into a single stack ...\n",
    "    ## Let's combine RNA-seq in a special way: fwd + rev[::-1]\n",
    "    # ...\n",
    "    # redefine RNA-seq track by combining fwd and rev tracks in a special way:\n",
    "    _rna_fwd = stackups_anchor_dict[anchor_name].pop(\"rg0r1fwd\")\n",
    "    _rna_rev = stackups_anchor_dict[anchor_name].pop(\"rg0r1rev\")\n",
    "    #\n",
    "    stackups_anchor_dict[anchor_name][\"rna\"] = _rna_fwd + _rna_rev[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25946473-f638-44dd-97fd-abeb8264680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bws_vlim = {\n",
    "    \"mM.atac\": dict(vmin=0.2,vmax=1.),\n",
    "    # \"mT.atac\": dict(vmin=0.005,vmax=0.3),\n",
    "    \"mG.atac\": dict(vmin=0.2,vmax=1.),\n",
    "    # \"pM.atac\": dict(vmin=0.005,vmax=0.3),\n",
    "    # # \"pT.atac\": dict(vmin=0.005,vmax=0.3),\n",
    "    \"pG.atac\": dict(vmin=0.2,vmax=1.),\n",
    "    \"H3K36me3\": dict(vmin=0.03,vmax=0.08),\n",
    "    \"H3K4me1\": dict(vmin=0.04,vmax=0.1),\n",
    "    \"MED1\": dict(vmin=0.04,vmax=0.15),\n",
    "    \"H3K27me3\": dict(vmin=0.2,vmax=1),\n",
    "    \"H3K9me3\": dict(vmin=0.2,vmax=1),\n",
    "    \"H3K4me3\": dict(vmin=1,vmax=14),\n",
    "    \"H3K27ac\": dict(vmin=1,vmax=14),\n",
    "    \"ctcf\": dict(vmin=2,vmax=5),\n",
    "    # some rna-seq - Async rangap control and depletion ...\n",
    "    \"rg0r1fwd\": dict(vmin=0.5,vmax=12),\n",
    "    \"rg0r1rev\": dict(vmin=0.5,vmax=12),\n",
    "    \"rg8r1fwd\": dict(vmin=0.5,vmax=12),\n",
    "    \"rg8r1rev\": dict(vmin=0.5,vmax=12),\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "bws_vlim[\"mM.atac\"] = dict(vmin=0.1,vmax=1.)\n",
    "bws_vlim[\"mG.atac\"] = dict(vmin=0.15,vmax=1.)\n",
    "bws_vlim[\"pG.atac\"] = dict(vmin=0.1,vmax=1.)\n",
    "bws_vlim[\"H3K27me3\"] = dict(vmin=0.15,vmax=0.85)\n",
    "bws_vlim[\"H3K9me3\"] = dict(vmin=0.15,vmax=1)\n",
    "bws_vlim[\"H3K4me3\"] = dict(vmin=0.5,vmax=14)\n",
    "bws_vlim[\"H3K27ac\"] = dict(vmin=0.9,vmax=18)\n",
    "bws_vlim[\"ctcf\"] = dict(vmin=1.8,vmax=6)\n",
    "bws_vlim[\"evm\"] = dict(vmin=-1.3,vmax=1.3)\n",
    "bws_vlim[\"evp\"] = dict(vmin=-1.3,vmax=1.3)\n",
    "bws_vlim[\"dots\"] = dict(vmin=0,vmax=0.3)\n",
    "# # # some rna-seq - Async rangap control and depletion ...\n",
    "bws_vlim[\"rna\"] = dict(vmin=0.5,vmax=40)\n",
    "bws_vlim[\"rg0r1fwd\"] = dict(vmin=0.5,vmax=35)\n",
    "bws_vlim[\"rg0r1rev\"] = dict(vmin=0.5,vmax=35)\n",
    "bws_vlim[\"rg8r1fwd\"] = dict(vmin=0.5,vmax=35)\n",
    "bws_vlim[\"rg8r1rev\"] = dict(vmin=0.5,vmax=35)\n",
    "\n",
    "\n",
    "from palettable.scientific import sequential\n",
    "lajolla_r = sequential.LaJolla_10_r.get_mpl_colormap()\n",
    "bilbao_r = sequential.Bilbao_20_r.get_mpl_colormap()\n",
    "batlow_r = sequential.Batlow_20_r.get_mpl_colormap()\n",
    "devon_r = sequential.Devon_20_r.get_mpl_colormap()\n",
    "davos_r = sequential.Davos_20_r.get_mpl_colormap()\n",
    "# fall_cmap = fall\n",
    "lajolla = sequential.LaJolla_10.get_mpl_colormap()\n",
    "bilbao = sequential.Bilbao_20.get_mpl_colormap()\n",
    "batlow = sequential.Batlow_20.get_mpl_colormap()\n",
    "devon = sequential.Devon_20.get_mpl_colormap()\n",
    "davos = sequential.Davos_20.get_mpl_colormap()\n",
    "\n",
    "imola_r = sequential.Imola_20_r.get_mpl_colormap()\n",
    "imola = sequential.Imola_20.get_mpl_colormap()\n",
    "\n",
    "nuuk_r = sequential.Nuuk_20_r.get_mpl_colormap()\n",
    "nuuk = sequential.Nuuk_20.get_mpl_colormap()\n",
    "\n",
    "hawaii_r = sequential.Hawaii_20_r.get_mpl_colormap()\n",
    "hawaii = sequential.Hawaii_20.get_mpl_colormap()\n",
    "\n",
    "oleron_r = sequential.Oleron_20_r.get_mpl_colormap()\n",
    "oleron = sequential.Oleron_20.get_mpl_colormap()\n",
    "\n",
    "oslo_r = sequential.Oslo_20_r.get_mpl_colormap()\n",
    "oslo = sequential.Oslo_20.get_mpl_colormap()\n",
    "\n",
    "bamako_r = sequential.Bamako_20_r.get_mpl_colormap()\n",
    "bamako = sequential.Bamako_20.get_mpl_colormap()\n",
    "\n",
    "grayc_r = sequential.GrayC_20_r.get_mpl_colormap()\n",
    "grayc = sequential.GrayC_20.get_mpl_colormap()\n",
    "\n",
    "lapaz_r = sequential.LaPaz_20_r.get_mpl_colormap()\n",
    "lapaz = sequential.LaPaz_20.get_mpl_colormap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad065a-9085-4d30-9a35-79fa2e6afb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f0d74-cede-4be7-b297-01d4a7e1b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_func import _get_norms, _get_hms_nested_shape, _fillmissing_hms, _get_profiles\n",
    "\n",
    "\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import ConnectionPatch, Rectangle\n",
    "from mpl_toolkits.axes_grid1 import Divider, Size\n",
    "from mpl_toolkits.axes_grid1.inset_locator import BboxConnector\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "def _get_norm(scale, vlims):\n",
    "    \"\"\"\n",
    "    given a scale and vlims - return norm !\n",
    "    \"\"\"\n",
    "    # try to extract vmin , vmax ...\n",
    "    try:\n",
    "        vmin, vmax = vlims\n",
    "    except Exception:\n",
    "        vmin, vmax = None, None\n",
    "    # depending on scale ...\n",
    "    if scale == \"log\":\n",
    "        return mpl.colors.LogNorm(vmin, vmax)\n",
    "    else:\n",
    "        return mpl.colors.Normalize(vmin, vmax)\n",
    "\n",
    "# profile_height=0.35\n",
    "# margin_h=0.2\n",
    "# margin_v=0.2\n",
    "# spacing_h=0.02\n",
    "# spacing_v=0.15\n",
    "# cbarh_spacing_v = 0.05\n",
    "# fig_fontsize=6\n",
    "# cbarh = 0.1\n",
    "\n",
    "def plot_stackups_sets_new(\n",
    "    num_extra_plots,\n",
    "    hms_dict_dict,  # heatmaps dict, that controls the order, the amount etc etc ...\n",
    "    scales,\n",
    "    vlims,\n",
    "    titles,\n",
    "    cmaps,\n",
    "    binsizes,\n",
    "    fillmissing=False,\n",
    "    extra_plots_position=\"left\",\n",
    "    len_per_thousand=0.75,\n",
    "    width_per_stack=0.35,\n",
    "    profile_height=0.35,\n",
    "    cbar_height = 0.1,\n",
    "    spacing_v=.5,  # fixed distance between axes (vertically)\n",
    "    spacing_h=.2,  # fixed distance between axes (horizontally)\n",
    "    # **plot_kwargs,\n",
    "    fig_fontsize=6,\n",
    "    **imshow_kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    plot a buch of stackups ...\n",
    "    \"\"\"\n",
    "    # rewrite everyhting assuming hms_dict_dict is a dict of stackup groups !\n",
    "    # groups are plotted on top of each other ...\n",
    "\n",
    "    if num_extra_plots:\n",
    "        num_extra_plots = int(num_extra_plots)\n",
    "    else:\n",
    "        num_extra_plots = 0\n",
    "\n",
    "    # inspect provided stacks and define figure with all of the panels ...\n",
    "    num_stackup_groups, stackup_samples, stackup_group_heights, stack_width = _get_hms_nested_shape(hms_dict_dict)\n",
    "    num_cols = len(stackup_samples) + num_extra_plots\n",
    "\n",
    "    # in inches\n",
    "    margin_h=0.2\n",
    "    margin_v=0.2\n",
    "    profile_spacing_v = 0.075\n",
    "    cbarh_spacing_v = 0.05\n",
    "    profile_color = \"dimgray\"\n",
    "    imshow_kwargs = dict(interpolation=\"antialiased\", interpolation_stage=\"data\", filternorm=False)\n",
    "    # imshow_kwargs = dict(interpolation=\"antialiased\", interpolation_stage=\"rgba\", filternorm=True)\n",
    "\n",
    "    # horizontal splitting layout\n",
    "    h_split = []\n",
    "    h_split.append( Size.Fixed(margin_h) )\n",
    "    h_split += [Size.Fixed(width_per_stack), Size.Fixed(spacing_h)]*(num_cols-1)\n",
    "    h_split += [Size.Fixed(width_per_stack), Size.Fixed(margin_h)]\n",
    "\n",
    "    # vertical splitting layout\n",
    "    v_split = []\n",
    "    v_split.append( Size.Fixed(margin_v) )\n",
    "    v_split.append( Size.Fixed(cbar_height) )\n",
    "    v_split.append( Size.Fixed(cbarh_spacing_v) )\n",
    "    for _i, _num_row_per_stack in enumerate(stackup_group_heights.values()):\n",
    "        v_split.append( Size.Fixed(len_per_thousand*(_num_row_per_stack/1_000)) )\n",
    "        if _i < len(stackup_group_heights)-1:\n",
    "            v_split.append( Size.Fixed(spacing_v) )\n",
    "        else:\n",
    "            v_split.append( Size.Fixed(spacing_v+profile_spacing_v) )\n",
    "    profile_spacing_v\n",
    "    v_split.append( Size.Fixed(profile_height) )\n",
    "    v_split.append( Size.Fixed(margin_v) )\n",
    "\n",
    "\n",
    "    # set figsize based on the tiling provided - i.e. post factum ...\n",
    "    fig_width = sum(_h.fixed_size for _h in h_split)\n",
    "    fig_height = sum(_v.fixed_size for _v in v_split)\n",
    "    fig = plt.figure(\n",
    "        figsize=(fig_width, fig_height),\n",
    "        layout=\"none\",\n",
    "        # facecolor='lightblue'\n",
    "    )\n",
    "    print(f\"figure overall is {fig_width=} {fig_height=}\")\n",
    "\n",
    "    divider = Divider(fig, (0, 0, 1, 1), h_split, v_split, aspect=False)\n",
    "    _div_pos = divider.get_position()\n",
    "\n",
    "\n",
    "    ax_profile = {}\n",
    "    ax_stackup = {}\n",
    "    ax_xtra = []\n",
    "    ax_cbar = {}\n",
    "    # define nest dict of axes ...\n",
    "    # provide extra axes at the end ...\n",
    "    if extra_plots_position == \"left\":\n",
    "        # extra plots on the left ...\n",
    "        for jdx in range(num_extra_plots):\n",
    "            for idx, group_k in enumerate(hms_dict_dict):\n",
    "                # ax_xtra.append([fig.add_subplot(gs[_i+1,jdx]) for _i in range(num_stackup_groups)])\n",
    "                idx += 1  # adjust by 1, since there is a cbar at the bottom\n",
    "                _stack_group_locator = divider.new_locator(nx=2*jdx+1, ny=2*idx+1)\n",
    "                ax_xtra.append(fig.add_axes(_div_pos, axes_locator=_stack_group_locator))\n",
    "        for jdx, sample in enumerate(stackup_samples):\n",
    "            jdx += num_extra_plots  # adjust steps by the extract plots in front\n",
    "            _cbar_locator = divider.new_locator(nx=2*jdx+1, ny=1)\n",
    "            ax_cbar[sample] = fig.add_axes(_div_pos, axes_locator=_cbar_locator)\n",
    "            ax_stackup[sample] = {}\n",
    "            for idx, group_k in enumerate(hms_dict_dict):\n",
    "                idx += 1  # adjust by 1, since there is a cbar at the bottom\n",
    "                _stack_group_locator = divider.new_locator(nx=2*jdx+1, ny=2*idx+1)\n",
    "                ax_stackup[sample][group_k] = fig.add_axes(_div_pos, axes_locator=_stack_group_locator)\n",
    "            # profile ny is simply the next one :\n",
    "            _profile_locator = divider.new_locator(nx=2*jdx+1, ny=2*(idx+1)+1)\n",
    "            ax_profile[sample] = fig.add_axes(_div_pos, axes_locator=_profile_locator)\n",
    "    # # provide extra axes at the end ...\n",
    "    # if extra_plots_position == \"right\":\n",
    "    else:  # RIGHT ...\n",
    "        # start with the stacks\n",
    "        for jdx, sample in enumerate(stackup_samples):\n",
    "            _cbar_locator = divider.new_locator(nx=2*jdx+1, ny=1)\n",
    "            ax_cbar[sample] = fig.add_axes(_div_pos, axes_locator=_cbar_locator)\n",
    "            ax_stackup[sample] = {}\n",
    "            for idx, group_k in enumerate(hms_dict_dict):\n",
    "                idx += 1  # adjust by 1, since there is a cbar at the bottom\n",
    "                _stack_group_locator = divider.new_locator(nx=2*jdx+1, ny=2*idx+1)\n",
    "                ax_stackup[sample][group_k] = fig.add_axes(_div_pos, axes_locator=_stack_group_locator)\n",
    "            # profile ny is simply the next one :\n",
    "            _profile_locator = divider.new_locator(nx=2*jdx+1, ny=2*(idx+1)+1)\n",
    "            ax_profile[sample] = fig.add_axes(_div_pos, axes_locator=_profile_locator)\n",
    "        # add extra plots in the end (on the right) ...\n",
    "        for jdx in range(len(stackup_samples), len(stackup_samples)+num_extra_plots):\n",
    "            for idx, group_k in enumerate(hms_dict_dict):\n",
    "                idx += 1  # adjust by 1, since there is a cbar at the bottom\n",
    "                _stack_group_locator = divider.new_locator(nx=2*jdx+1, ny=2*idx+1)\n",
    "                ax_xtra.append(fig.add_axes(_div_pos, axes_locator=_stack_group_locator))\n",
    "\n",
    "    # fill missing if needed and calculate profiles (per group) ...\n",
    "    hms_dict_dict_copy = {}\n",
    "    profile_hm = {}\n",
    "    for group_k, hms_dict in hms_dict_dict.items():\n",
    "        hms_dict_dict_copy[group_k] = _fillmissing_hms(hms_dict, how=\"col mean\") if fillmissing else hms_dict\n",
    "        # use modified stacks to calculate profiles ...\n",
    "        profile_hm[group_k] = _get_profiles(hms_dict_dict_copy[group_k], scales)\n",
    "    # replace hms_dict_dict with the updated copy ...\n",
    "    hms_dict_dict = hms_dict_dict_copy\n",
    "    # get norms - they are just per sample - regardless of the group ...\n",
    "    norms = {k: _get_norm(scales[k], vlims[k]) for k in stackup_samples}\n",
    "\n",
    "    last_group_k = list(hms_dict_dict.keys())[-1]\n",
    "    first_sample = stackup_samples[0]\n",
    "\n",
    "    # start plotting ...\n",
    "    for group_k, hms_dict in hms_dict_dict.items():\n",
    "        # we've checked that samples go in the same order ...\n",
    "        for sample, hm in hms_dict.items():\n",
    "            ax_profile[sample].plot(profile_hm[group_k][sample], linewidth=1)\n",
    "            stack_hm = ax_stackup[sample][group_k].imshow(\n",
    "                              hm,\n",
    "                              norm=norms[sample],\n",
    "                              aspect=\"auto\",\n",
    "                              cmap=cmaps[sample],\n",
    "                              **imshow_kwargs,\n",
    "            )\n",
    "            # beautify ...\n",
    "            ax_stackup[sample][group_k].set_xticks([])\n",
    "            ax_stackup[sample][group_k].set_xticklabels([])\n",
    "            ax_stackup[sample][group_k].set_yticks([])\n",
    "            ax_stackup[sample][group_k].set_yticklabels([])\n",
    "            ax_stackup[sample][group_k].minorticks_off()\n",
    "            # #\n",
    "            # if sample == first_sample:\n",
    "            #     ax_stackup[sample][group_k].set_ylabel(group_k,fontsize=fig_fontsize)\n",
    "\n",
    "            if group_k == last_group_k:\n",
    "                # beautify ...\n",
    "                # we have to do it for every samples - but not for every group ...\n",
    "                first_bin = -.5\n",
    "                center_bin = stack_width/2 - .5\n",
    "                last_bin = stack_width - .5\n",
    "                _xticklength = 1\n",
    "                flank_in_kb = int( (center_bin+.5)*binsizes[sample]/1000 )\n",
    "                flank_ticks = [first_bin, center_bin, last_bin]\n",
    "                flank_ticklabels = [-flank_in_kb, \"\", flank_in_kb]\n",
    "                #\n",
    "                ax_profile[sample].set_title(titles[sample],fontsize=fig_fontsize, pad=2.5)\n",
    "                # ax_profile[sample].set_title(titles[sample])\n",
    "                ax_profile[sample].minorticks_off()\n",
    "                ax_profile[sample].set_xlim([first_bin, last_bin])\n",
    "                ax_profile[sample].set_xticks(flank_ticks)\n",
    "                ax_profile[sample].tick_params(axis=\"x\", length=_xticklength, pad=0.5)\n",
    "                ax_profile[sample].set_xticklabels(flank_ticklabels,fontsize=fig_fontsize)\n",
    "                for _tidx, tick in enumerate(ax_profile[sample].xaxis.get_majorticklabels()):\n",
    "                    if _tidx == 0:\n",
    "                        tick.set_horizontalalignment(\"left\")\n",
    "                    elif _tidx == 2:\n",
    "                        tick.set_horizontalalignment(\"right\")\n",
    "                    else:\n",
    "                        tick.set_horizontalalignment(\"center\")\n",
    "                ax_profile[sample].set_ylim(vlims[sample])\n",
    "                ax_profile[sample].tick_params(axis=\"y\", length=0, direction=\"in\", pad=-5)\n",
    "                ax_profile[sample].set_yticks(vlims[sample])\n",
    "                ax_profile[sample].set_yticklabels(vlims[sample],fontsize=fig_fontsize)\n",
    "                for _tidx, tick in enumerate(ax_profile[sample].yaxis.get_majorticklabels()):\n",
    "                    tick.set_horizontalalignment(\"left\")\n",
    "                    if _tidx == 0:\n",
    "                        tick.set_verticalalignment(\"bottom\")\n",
    "                    elif _tidx == 1:\n",
    "                        tick.set_verticalalignment(\"top\")\n",
    "\n",
    "                # # bottom one - show ticks for now ...\n",
    "                # ax_stackup[sample][group_k].set_xticks(flank_ticks)\n",
    "                # ax_stackup[sample][group_k].set_xticklabels(flank_ticklabels,fontsize=fig_fontsize)\n",
    "                # ax_stackup[sample][group_k].tick_params(axis=\"x\", length=6)\n",
    "                # ax_stackup[sample][group_k].set_yticks([])\n",
    "                # ax_stackup[sample][group_k].set_yticklabels([])\n",
    "                # for _tidx, tick in enumerate(ax_stackup[sample][group_k].xaxis.get_majorticklabels()):\n",
    "                #     if _tidx == 0:\n",
    "                #         tick.set_horizontalalignment(\"left\")\n",
    "                #     elif _tidx == 2:\n",
    "                #         tick.set_horizontalalignment(\"right\")\n",
    "                #     else:\n",
    "                #         tick.set_horizontalalignment(\"center\")\n",
    "                # # colorbar - draw them one time per sample only !\n",
    "                plt.colorbar(stack_hm,\n",
    "                            cax=ax_cbar[sample],\n",
    "                            orientation=\"horizontal\",\n",
    "                            ticks=vlims[sample])\n",
    "                ax_cbar[sample].minorticks_off()\n",
    "                ax_cbar[sample].tick_params(axis=\"x\", length=_xticklength, pad=0.5)\n",
    "                ax_cbar[sample].set_xticklabels(vlims[sample],fontsize=fig_fontsize)\n",
    "                for _tidx, tick in enumerate(ax_cbar[sample].xaxis.get_majorticklabels()):\n",
    "                    if _tidx == 0:\n",
    "                        tick.set_horizontalalignment(\"left\")\n",
    "                    elif _tidx == 1:\n",
    "                        tick.set_horizontalalignment(\"right\")\n",
    "\n",
    "    return ax_xtra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c2244-26fa-497e-9768-224fa22acc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,df in anchor_dict.items():\n",
    "    print(k,len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ce56f-eba3-48f5-b5eb-e5fa8e8bb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_display = [ 'mG.atac', 'H3K4me3', 'H3K27ac', 'H3K27me3', \"rna\", \"evm\",\"evp\", \"dots\"]\n",
    "\n",
    "hms_dict = {}\n",
    "# for _group_name in ['p5_wo_pCyto', 'pcyto']:\n",
    "# # for _group_name, g in mega_anchor_dict.items():\n",
    "#     g = mega_anchor_dict[_group_name]\n",
    "#     stackups_anchor = stackups_anchor_dict[_group_name]\n",
    "#     # define ordering ...\n",
    "#     _idx = stackups_anchor[\"rna\"][g.index].mean(axis=1).argsort()\n",
    "#     # _idx = g[\"valency\"].argsort()\n",
    "#     # _idx = g[\"size\"].argsort()\n",
    "#     hms_dict[_group_name] = {k: stackups_anchor[k][_idx] for k in keys_to_display}\n",
    "for _group_name in ['p5_wo_pCyto', 'pcyto']:\n",
    "    g = anchor_dict[_group_name]\n",
    "    stackups_anchor = stackups_anchor_dict[_group_name]\n",
    "    # define ordering ...\n",
    "    _idx = stackups_anchor[\"rna\"][g.index].mean(axis=1).argsort()\n",
    "    # _idx = g[\"valency\"].argsort()\n",
    "    # _idx = g[\"size\"].argsort()\n",
    "    hms_dict[_group_name] = {k: stackups_anchor[k][_idx] for k in keys_to_display}\n",
    "\n",
    "# ...\n",
    "scales = {k: \"log\" for k in keys_to_display}\n",
    "vlims = {k: (bws_vlim[k][\"vmin\"], bws_vlim[k][\"vmax\"]) for k in keys_to_display}\n",
    "titles = {k: k for k in keys_to_display}\n",
    "cmaps = {k: davos_r for k in keys_to_display}\n",
    "binsizes = {k: ((2*_flank) // _nbins) for k in keys_to_display}\n",
    "\n",
    "for _evk in [\"evm\",\"evp\",\"dots\"]:\n",
    "    scales[_evk] = \"linear\"\n",
    "    cmaps[_evk] = \"RdBu_r\"\n",
    "\n",
    "cmaps[\"dots\"] = davos_r\n",
    "\n",
    "axx = plot_stackups_sets_new(\n",
    "    0,\n",
    "    hms_dict,  # heatmaps dict, that controls the order, the amount etc etc ...\n",
    "    scales,\n",
    "    vlims,\n",
    "    titles,\n",
    "    cmaps,\n",
    "    binsizes,\n",
    "    fillmissing=True,\n",
    "    len_per_thousand=0.73,\n",
    "    width_per_stack=0.33,\n",
    "    profile_height=0.33,\n",
    "    cbar_height = 0.07,\n",
    "    spacing_v=.03,  # fixed distance between axes (vertically)\n",
    "    spacing_h=.03,  # fixed distance between axes (horizontally)\n",
    "    fig_fontsize=6,\n",
    "    # **imshow_kwargs,\n",
    ")\n",
    "\n",
    "plt.savefig(\"Fig3d-2way_stackup.svg\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286557f8-7aaa-4788-af8c-bee163c18e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c840ca1-a443-4a39-a75a-55ca2e2f7c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5de95-0df9-45ea-b623-ba0428f302a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c39fde-4239-4805-8792-0478381763a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbe9df-34a0-4fd0-9142-33317f2e2c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ffbce-4a8c-4247-a4a7-36acb91745cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f7c2e-3651-468f-a825-5aaa365e5cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efdf7c1-cdaf-4277-a151-b0c3ecc88190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ea26e-73e2-4a8f-ba0e-6b000dc943fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa0bfa73-e499-4c33-bbc6-42e8c9207a65",
   "metadata": {},
   "source": [
    "# Legacy stuff ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11365e3-4425-4a63-9b5d-60db0c2adc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_extra_plots,\n",
    "# hms_dict_dict,\n",
    "# ...\n",
    "scales = {k: \"linear\" for k in keys_to_display}\n",
    "vlims = {k: (bws_vlim[k][\"vmin\"], bws_vlim[k][\"vmax\"]) for k in keys_to_display}\n",
    "titles = {k: k for k in keys_to_display}\n",
    "cmaps = {k: davos_r for k in keys_to_display}\n",
    "# cmaps = {k: \"Blues\" for k in keys_to_display}\n",
    "binsizes = {k: ((2*_flank) // _nbins) for k in keys_to_display}\n",
    "# modify EV-related things ...\n",
    "for _evk in [\"evm\",\"evp\"]:\n",
    "    scales[_evk] = \"linear\"\n",
    "    cmaps[_evk] = \"RdBu_r\"\n",
    "\n",
    "\n",
    "fillmissing=True\n",
    "# fill missing if needed and calculate profiles (per group) ...\n",
    "hms_dict_copy = {}\n",
    "profile_hm = {}\n",
    "for group_k, _hms in hms_dict.items():\n",
    "    hms_dict_copy[group_k] = _fillmissing_hms(_hms, how=\"col mean\") if fillmissing else _hms\n",
    "    # use modified stacks to calculate profiles ...\n",
    "    profile_hm[group_k] = _get_profiles(hms_dict_copy[group_k], scales)\n",
    "# replace hms_dict_dict with the updated copy ...\n",
    "# _hms = hms_dict_copy\n",
    "# # get norms - they are just per sample - regardless of the group ...\n",
    "# norms = _get_norms(scales, vlims)\n",
    "# last_group_k = list(hms_dict_dict.keys())[-1]\n",
    "# first_sample = stackup_samples[0]\n",
    "_stacks_dict , = list(hms_dict_copy.values())\n",
    "\n",
    "\n",
    "# ...\n",
    "norms = {k: _get_norm(scales[k], vlims[k]) for k in keys_to_display}\n",
    "num_stackup_groups, stackup_samples, stackup_group_heights, stack_width = _get_hms_nested_shape({\"grp1\": _stacks_dict})\n",
    "num_stacks = len(stackup_samples)\n",
    "num_stack_rows = sum(stackup_group_heights.values())\n",
    "\n",
    "# in inches\n",
    "len_per_thousand=0.75\n",
    "width_per_stack=0.35\n",
    "# len_per_thousand=5.9\n",
    "# width_per_stack=2.7\n",
    "profile_height=0.35\n",
    "margin_h=0.2\n",
    "margin_v=0.2\n",
    "spacing_h=0.02\n",
    "spacing_v=0.15\n",
    "cbarh_spacing_v = 0.05\n",
    "fig_fontsize=6\n",
    "cbarh = 0.1\n",
    "profile_color = \"dimgray\"\n",
    "\n",
    "imshow_kwargs = dict(interpolation=\"antialiased\", interpolation_stage=\"data\", filternorm=False)\n",
    "# imshow_kwargs = dict(interpolation=\"antialiased\", interpolation_stage=\"rgba\", filternorm=True)\n",
    "\n",
    "w = num_stacks*width_per_stack + (num_stacks-1)*spacing_h + 2*margin_h\n",
    "h = 2*margin_v + spacing_v + cbarh_spacing_v + \\\n",
    "    len_per_thousand*(num_stack_rows/1_000) + \\\n",
    "    profile_height + cbarh\n",
    "\n",
    "print(f\"figure size is {w=} {h=}\")\n",
    "fig = plt.figure(\n",
    "    figsize=(w, h),\n",
    "    layout=\"none\",\n",
    "    # facecolor='lightblue',\n",
    ")\n",
    "\n",
    "# horizontal splitting layout\n",
    "h_split = []\n",
    "h_split.append( Size.Fixed(margin_h) )\n",
    "h_split += [Size.Fixed(width_per_stack), Size.Fixed(spacing_h)]*(num_stacks-1)\n",
    "h_split += [Size.Fixed(width_per_stack), Size.Fixed(margin_h)]\n",
    "\n",
    "# vertical splitting layout\n",
    "v_split = []\n",
    "v_split.append( Size.Fixed(margin_v) )\n",
    "v_split.append( Size.Fixed(cbarh) )\n",
    "v_split.append( Size.Fixed(cbarh_spacing_v) )\n",
    "for _num_row_per_stack in group_sizes:\n",
    "    v_split.append( Size.Fixed(len_per_thousand*(_num_row_per_stack/1_000)) )\n",
    "    v_split.append( Size.Fixed(spacing_v) )\n",
    "v_split.append( Size.Fixed(profile_height) )\n",
    "v_split.append( Size.Fixed(margin_v) )\n",
    "\n",
    "divider = Divider(fig, (0, 0, 1, 1), h_split, v_split, aspect=False)\n",
    "\n",
    "axs_profile = [ fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=5)) for i in range(num_stacks)]\n",
    "axs_stack = [ fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=3)) for i in range(num_stacks)]\n",
    "axs_cbar = [ fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=2*i+1, ny=1)) for i in range(num_stacks)]\n",
    "\n",
    "for _i, _sample in enumerate(stackup_samples):\n",
    "    hm = _stacks_dict[_sample]\n",
    "    axs_profile[_i].plot(np.nanmean(hm,axis=0), linewidth=1, color=profile_color)\n",
    "    stack_hm = axs_stack[_i].imshow(\n",
    "                      hm,\n",
    "                      norm=norms[_sample],\n",
    "                      aspect=\"auto\",\n",
    "                      cmap=cmaps[_sample],\n",
    "                      **imshow_kwargs,\n",
    "    )\n",
    "    # beautify ...\n",
    "    # we have to do it for every samples - but not for every group ...\n",
    "    first_bin = -.5\n",
    "    center_bin = stack_width/2 - .5\n",
    "    last_bin = stack_width - .5\n",
    "    _xticklength = 1\n",
    "    flank_in_kb = int( (center_bin+.5)*binsizes[_sample]/1000 )\n",
    "    flank_ticks = [first_bin, center_bin, last_bin]\n",
    "    flank_ticklabels = [-flank_in_kb, \"\", f\"+{flank_in_kb}\"]\n",
    "    axs_profile[_i].set_title(titles[_sample],fontsize=fig_fontsize, pad=2.5)\n",
    "    axs_profile[_i].minorticks_off()\n",
    "    axs_profile[_i].set_xlim([first_bin, last_bin])\n",
    "    axs_profile[_i].set_xticks(flank_ticks)\n",
    "    axs_profile[_i].tick_params(axis=\"x\", length=_xticklength, pad=0.5)\n",
    "    axs_profile[_i].set_xticklabels(flank_ticklabels,fontsize=fig_fontsize)\n",
    "    for _tidx, tick in enumerate(axs_profile[_i].xaxis.get_majorticklabels()):\n",
    "        if _tidx == 0:\n",
    "            tick.set_horizontalalignment(\"left\")\n",
    "        elif _tidx == 2:\n",
    "            tick.set_horizontalalignment(\"right\")\n",
    "        else:\n",
    "            tick.set_horizontalalignment(\"center\")\n",
    "    axs_profile[_i].set_ylim(vlims[_sample])\n",
    "    axs_profile[_i].tick_params(axis=\"y\", length=0, direction=\"in\", pad=-3)\n",
    "    axs_profile[_i].set_yticks(vlims[_sample])\n",
    "    axs_profile[_i].set_yticklabels(vlims[_sample],fontsize=fig_fontsize)\n",
    "    # axs_profile[_i].set_yscale(\"log\")\n",
    "    for _tidx, tick in enumerate(axs_profile[_i].yaxis.get_majorticklabels()):\n",
    "        tick.set_horizontalalignment(\"left\")\n",
    "        if _tidx == 0:\n",
    "            tick.set_verticalalignment(\"bottom\")\n",
    "        elif _tidx == 1:\n",
    "            tick.set_verticalalignment(\"top\")\n",
    "    # bottom one - show ticks for now ...\n",
    "    axs_stack[_i].set_xticks(flank_ticks)\n",
    "    # axs_stack[_i].set_xticklabels(flank_ticklabels,fontsize=fig_fontsize)\n",
    "    axs_stack[_i].set_xticklabels([])\n",
    "    axs_stack[_i].tick_params(axis=\"x\", length=_xticklength)\n",
    "    axs_stack[_i].set_yticks([])\n",
    "    axs_stack[_i].set_yticklabels([])\n",
    "    for _tidx, tick in enumerate(axs_stack[_i].xaxis.get_majorticklabels()):\n",
    "        if _tidx == 0:\n",
    "            tick.set_horizontalalignment(\"left\")\n",
    "        elif _tidx == 2:\n",
    "            tick.set_horizontalalignment(\"right\")\n",
    "        else:\n",
    "            tick.set_horizontalalignment(\"center\")\n",
    "    # colorbar - draw them one time per sample only !\n",
    "    plt.colorbar(stack_hm,\n",
    "                cax=axs_cbar[_i],\n",
    "                orientation=\"horizontal\",\n",
    "                ticks=vlims[_sample])\n",
    "    axs_cbar[_i].minorticks_off()\n",
    "    axs_cbar[_i].tick_params(axis=\"x\", length=_xticklength, pad=0.5)\n",
    "    axs_cbar[_i].set_xticklabels(vlims[_sample], fontsize=fig_fontsize)\n",
    "    for _tidx, tick in enumerate(axs_cbar[_i].xaxis.get_majorticklabels()):\n",
    "        if _tidx == 0:\n",
    "            tick.set_horizontalalignment(\"left\")\n",
    "        elif _tidx == 1:\n",
    "            tick.set_horizontalalignment(\"right\")\n",
    "\n",
    "# # fig.savefig(\"Fig2C_stackup.svg\", dpi=300)\n",
    "# fig.savefig(\"Fig2C_stackup.svg\", format=\"svg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202bd13-856f-4297-bb95-fef64aef6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _idx_order = id_anchors_dict[\"pcyto\"][\"size\"].argsort()\n",
    "# # _idx_order = ov[\"size\"].argsort()\n",
    "# # _idx_order = nov[\"size\"].argsort()\n",
    "\n",
    "stackups_anchor = stackups_anchor_dict[\"pcyto\"]\n",
    "_idx_order = stackups_anchor[\"dots\"].sum(axis=1).argsort()\n",
    "\n",
    "\n",
    "kkk = ['mG.atac', 'H3K27me3', 'H3K4me3', 'H3K27ac']\n",
    "# kkk = ['mM.atac', 'mG.atac', 'pG.atac', 'H3K27me3', 'H3K4me3', 'H3K27ac', 'ctcf']\n",
    "\n",
    "# hms_dict = {k: stackups_anchor[k][order_by_len_idx] for k in kkk}\n",
    "hms_dict = {k: stackups_anchor[k][_idx_order] for k in kkk}\n",
    "scales = {k: \"log\" for k in kkk}\n",
    "vlims = {k: (bws_vlim[k][\"vmin\"], bws_vlim[k][\"vmax\"]) for k in kkk}\n",
    "titles = {k: k for k in kkk}\n",
    "cmaps = {k: davos_r for k in kkk}\n",
    "# cmaps[\"H3K4me3\"] = \"Reds\"\n",
    "binsizes = {k: ((2*_flank) // _nbins) for k in kkk}\n",
    "\n",
    "subtract_shoulders = False\n",
    "kkk.append(\"evm\")\n",
    "kkk.append(\"evp\")\n",
    "for _evk in [\"evm\",\"evp\"]:\n",
    "    _smat = stackups_anchor[_evk][_idx_order]\n",
    "    if subtract_shoulders:\n",
    "        _shoulders = np.nanmean(np.c_[_smat[:,:25], _smat[:,-25:]], axis=1)[:,None]\n",
    "        hms_dict[_evk] = _smat - _shoulders\n",
    "    else:\n",
    "        hms_dict[_evk] = _smat\n",
    "    scales[_evk] = \"linear\"\n",
    "    # vlims[_evk] = (-0.25,0.25)\n",
    "    vlims[_evk] = (-1.1,1.1)\n",
    "    titles[_evk] = _evk\n",
    "    cmaps[_evk] = \"RdBu_r\"\n",
    "    binsizes[_evk] = ((2*_flank) // _nbins)\n",
    "\n",
    "\n",
    "# kkk.append(\"idcov\")\n",
    "kkk.append(\"dots\")\n",
    "# _kkk = \"idcov\"\n",
    "# hms_dict[_kkk] = stackups_anchor[_kkk][_idx_order]\n",
    "# scales[_kkk] = \"linear\"\n",
    "# vlims[_kkk] = (1,25)\n",
    "# titles[_kkk] = _kkk\n",
    "# cmaps[_kkk] = davos_r\n",
    "# binsizes[_kkk] = ((2*_flank) // _nbins)\n",
    "\n",
    "_kkk = \"dots\"\n",
    "hms_dict[_kkk] = stackups_anchor[_kkk][_idx_order]\n",
    "scales[_kkk] = \"linear\"\n",
    "vlims[_kkk] = (0,0.5)\n",
    "titles[_kkk] = _kkk\n",
    "cmaps[_kkk] = davos_r\n",
    "binsizes[_kkk] = ((2*_flank) // _nbins)\n",
    "\n",
    "plot_stackups_lite(\n",
    "    None,\n",
    "    hms_dict,  # heatmaps dict, that controls the order, the amount etc etc ...\n",
    "    scales,\n",
    "    vlims,\n",
    "    titles,\n",
    "    cmaps,\n",
    "    binsizes,\n",
    "    fillmissing=False,\n",
    "    len_per_thousand=4.9,\n",
    "    width_per_stack=3.2,\n",
    "    extra_height=3.,  # height that goes toward the profile and colorbar\n",
    "    interpolation=\"gaussian\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684f54d-4378-4438-b25e-d58b7e2633ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_display = [ 'mG.atac', 'H3K4me3', 'H3K27ac', 'H3K27me3', \"rna\", \"evm\",\"evp\", \"dots\"]\n",
    "\n",
    "hms_dict = {}\n",
    "for name, g in mega_anchor_dict.items():\n",
    "    stackups_anchor = stackups_anchor_dict[name]\n",
    "    # define ordering ...\n",
    "    _idx = stackups_anchor[\"rna\"][g.index].mean(axis=1).argsort()\n",
    "    # _idx = g[\"valency\"].argsort()\n",
    "    # _idx = g[\"size\"].argsort()\n",
    "    hms_dict[name] = {k: stackups_anchor[k][_idx] for k in keys_to_display}\n",
    "\n",
    "# ...\n",
    "scales = {k: \"log\" for k in keys_to_display}\n",
    "vlims = {k: (bws_vlim[k][\"vmin\"], bws_vlim[k][\"vmax\"]) for k in keys_to_display}\n",
    "titles = {k: k for k in keys_to_display}\n",
    "cmaps = {k: davos_r for k in keys_to_display}\n",
    "binsizes = {k: ((2*_flank) // _nbins) for k in keys_to_display}\n",
    "\n",
    "for _evk in [\"evm\",\"evp\",\"dots\"]:\n",
    "    scales[_evk] = \"linear\"\n",
    "    cmaps[_evk] = \"RdBu_r\"\n",
    "\n",
    "cmaps[\"dots\"] = davos_r\n",
    "\n",
    "_xfsize = 12\n",
    "axx = plot_stackups_sets(\n",
    "    None,\n",
    "    hms_dict,\n",
    "    scales,\n",
    "    vlims,\n",
    "    titles,\n",
    "    cmaps,\n",
    "    binsizes,\n",
    "    fillmissing=False,\n",
    "    len_per_thousand=6.9,\n",
    "    width_per_stack=3.,\n",
    "    extra_height=3.,  # height that goes toward the profile and colorbar\n",
    "    delta_h=.3,  # fixed distance between axes (vertically)\n",
    "    delta_w=.5,  # fixed distance between axes (horizontal\n",
    "    fig_fontsize=_xfsize,\n",
    "    interpolation=\"gaussian\",\n",
    ")\n",
    "\n",
    "\n",
    "plt.savefig(\"Fig3d-2way_stackup.svg\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7596b-8561-4690-890e-bc872123769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keys_to_display = [ 'H3K27me3',  'H3K9me3', 'mM.atac', 'mG.atac', 'pG.atac', 'H3K4me3', 'H3K27ac', \"ctcf\", \"rg0r1fwd\", \"rg0r1rev\"]\n",
    "# keys_to_display = [ 'H3K9me3','H3K27me3','mG.atac', 'H3K4me3', 'H3K27ac', \"ctcf\", \"rg0r1fwd\", \"rg0r1rev\"]\n",
    "# # hms_dict = {k: stackups_anchor[k][order_by_len_idx] for k in keys_to_display}\n",
    "# # hms_dict = {k: stackups_anchor[k][_idx_order] for k in keys_to_display}\n",
    "\n",
    "# hms_dict = {}\n",
    "# for name, g in mega_anchor_dict.items():\n",
    "#     stackups_anchor = stackups_anchor_dict[name]\n",
    "#     # _idx = (stackups_anchor[\"rg0r1fwd\"].mean(axis=1) + stackups_anchor[\"rg0r1rev\"].mean(axis=1)).argsort()\n",
    "#     _idx = stackups_anchor[\"dots\"][:, 100-25:100+25].mean(axis=1).argsort()\n",
    "#     # _idx = stackups_anchor[\"dots\"].mean(axis=1).argsort()\n",
    "#     # _idx = stackups_anchor[\"evp\"].mean(axis=1).argsort()\n",
    "#     # _idx = g[\"valency\"].argsort()\n",
    "#     if name == \"nov\":\n",
    "#         hms_dict[name] = {k: stackups_anchor[k][_idx] for k in keys_to_display}\n",
    "#     else:\n",
    "#         hms_dict[name] = {k: stackups_anchor[k][_idx] for k in keys_to_display}\n",
    "#     # add ev\n",
    "#     for _evk in [\"evm\",\"evp\", \"idcov\", \"dots\"]:\n",
    "#         if name == \"nov\":\n",
    "#             _smat = stackups_anchor[_evk][_idx]\n",
    "#         else:\n",
    "#             _smat = stackups_anchor[_evk][_idx]\n",
    "#         hms_dict[name][_evk] = _smat\n",
    "\n",
    "# # ...\n",
    "# scales = {k: \"log\" for k in keys_to_display}\n",
    "# vlims = {k: (bws_vlim[k][\"vmin\"], bws_vlim[k][\"vmax\"]) for k in keys_to_display}\n",
    "# titles = {k: k for k in keys_to_display}\n",
    "# cmaps = {k: davos_r for k in keys_to_display}\n",
    "# binsizes = {k: ((2*_flank) // _nbins) for k in keys_to_display}\n",
    "\n",
    "# for _evk in [\"evm\",\"evp\"]:\n",
    "#     keys_to_display.append(_evk)\n",
    "#     scales[_evk] = \"linear\"\n",
    "#     vlims[_evk] = (-1.2,1.2)\n",
    "#     titles[_evk] = _evk\n",
    "#     cmaps[_evk] = \"RdBu_r\"\n",
    "#     binsizes[_evk] = ((2*_flank) // _nbins)\n",
    "\n",
    "\n",
    "# keys_to_display.append(\"idcov\")\n",
    "# keys_to_display.append(\"dots\")\n",
    "# _kkk = \"idcov\"\n",
    "# scales[_kkk] = \"linear\"\n",
    "# vlims[_kkk] = (1,25)\n",
    "# titles[_kkk] = _kkk\n",
    "# cmaps[_kkk] = davos_r\n",
    "# binsizes[_kkk] = ((2*_flank) // _nbins)\n",
    "# _kkk = \"dots\"\n",
    "# scales[_kkk] = \"linear\"\n",
    "# vlims[_kkk] = (0,0.5)\n",
    "# titles[_kkk] = _kkk\n",
    "# cmaps[_kkk] = davos_r\n",
    "# binsizes[_kkk] = ((2*_flank) // _nbins)\n",
    "\n",
    "# _xfsize = 12\n",
    "# axx = plot_stackups_sets(\n",
    "#     None,\n",
    "#     hms_dict,\n",
    "#     scales,\n",
    "#     vlims,\n",
    "#     titles,\n",
    "#     cmaps,\n",
    "#     binsizes,\n",
    "#     fillmissing=False,\n",
    "#     len_per_thousand=6.9,\n",
    "#     width_per_stack=3.,\n",
    "#     extra_height=3.,  # height that goes toward the profile and colorbar\n",
    "#     delta_h=.3,  # fixed distance between axes (vertically)\n",
    "#     delta_w=.5,  # fixed distance between axes (horizontal)\n",
    "#     fig_fontsize=_xfsize,\n",
    "#     interpolation=\"gaussian\",\n",
    "# )\n",
    "\n",
    "# plt.savefig(\"3way_stackup.svg\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75daf7d6-d758-4b51-aa69-e3e953bc687a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea65e7d-4723-4927-86a6-3f5a4d24c0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
