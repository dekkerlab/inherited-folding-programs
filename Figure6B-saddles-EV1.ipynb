{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saddleplots - plotting only !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os, subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python package for working with cooler files and tools for analysis\n",
    "import cooler\n",
    "import cooltools.lib.plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from saddle import saddleplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test data\n",
    "# this file is 145 Mb, and may take a few seconds to download\n",
    "import bbi\n",
    "import cooltools\n",
    "import bioframe\n",
    "from matplotlib.colors import LogNorm\n",
    "from helper_func import saddleplot\n",
    "from data_catalog import bws, bws_vlim, telo_dict\n",
    "\n",
    "import saddle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import h5py\n",
    "\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import ConnectionPatch, Rectangle\n",
    "from mpl_toolkits.axes_grid1 import Divider, Size\n",
    "from mpl_toolkits.axes_grid1.inset_locator import BboxConnector\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "# from mpl_toolkits.axes_grid1.Size import Fixed\n",
    "\n",
    "\n",
    "# enable editable text ...\n",
    "mpl.rcParams[\"pdf.fonttype\"]=42\n",
    "mpl.rcParams[\"svg.fonttype\"]=\"none\"\n",
    "mpl.rcParams['axes.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating per-chromosome compartmentalization\n",
    "\n",
    "We first load the Hi-C data at 100 kbp resolution. \n",
    "\n",
    "Note that the current implementation of eigendecomposition in cooltools assumes that individual regions can be held in memory-- for hg38 at 100kb this is either a 2422x2422 matrix for chr2, or a 3255x3255 matrix for the full cooler here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define genomic view that will be used to call dots and pre-compute expected\n",
    "\n",
    "# Use bioframe to fetch the genomic features from the UCSC.\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "hg38_arms_full = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "# # remove \"bad\" chromosomes and near-empty arms ...\n",
    "included_arms = hg38_arms_full[\"name\"].to_list()[:44] # all autosomal ones ...\n",
    "hg38_arms = hg38_arms_full[hg38_arms_full[\"name\"].isin(included_arms)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls *.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls *.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_attrs(name, obj):\n",
    "    # Create indent\n",
    "    shift = name.count('/') * '    '\n",
    "    item_name = name.split(\"/\")[-1]\n",
    "    print(shift + item_name)\n",
    "    try:\n",
    "        for key, val in obj.attrs.items():\n",
    "            print(shift + '    ' + f\"{key}: {val}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# load EV saddles asis ...\n",
    "print(\"loading EV saddles, along with some metadata ...\")\n",
    "print()\n",
    "\n",
    "\n",
    "# create a track sample map to pass to the multiprocessing job ...\n",
    "track_sample_map = {}\n",
    "with h5py.File(\"saddles_EV_by_distance.hdf5\", 'r') as fr:\n",
    "    # fr.visititems(print_attrs)\n",
    "\n",
    "    # check general metadata ...\n",
    "    _saddle_meta = dict(fr.attrs)\n",
    "\n",
    "    # # sort out the results ...\n",
    "    # interaction_sums_trans_asis = {}\n",
    "    # interaction_counts_trans_asis = {}\n",
    "    # # sort out the results ...\n",
    "    # _counts = fr.get(\"counts_trans\")\n",
    "    # for _sample in _counts.keys():\n",
    "    #     interaction_counts_trans_asis[_sample] = _counts.get(_sample)[()]\n",
    "    # _sums = fr.get(\"sums_trans\")\n",
    "    # for _sample in _sums.keys():\n",
    "    #     interaction_sums_trans_asis[_sample] = _sums.get(_sample)[()]\n",
    "\n",
    "    interaction_sums = {}\n",
    "    interaction_counts = {}\n",
    "    # sort out the results ...\n",
    "    _counts = fr.get(\"counts\")\n",
    "    for _sample in _counts.keys():\n",
    "        _cds = _counts.get(_sample)\n",
    "        # extracting sample to track_sample mapping from HDF5 itself ...\n",
    "        track_sample_map[_sample] = _cds.attrs[\"track\"]\n",
    "        interaction_counts[_sample] = _cds[()]\n",
    "    _sums = fr.get(\"sums\")\n",
    "    for _sample in _sums.keys():\n",
    "        _sds = _sums.get(_sample)\n",
    "        interaction_sums[_sample] = _sds[()]\n",
    "\n",
    "\n",
    "print(f\"loaded {_saddle_meta=}\")\n",
    "print(f\"loaded sample to track sample map {track_sample_map=}\")\n",
    "\n",
    "# unpack metadata ...\n",
    "Q_LO = _saddle_meta[\"Q_LO\"]\n",
    "Q_HI = _saddle_meta[\"Q_HI\"]\n",
    "N_GROUPS = _saddle_meta[\"N_GROUPS\"]\n",
    "binsize = _saddle_meta[\"cis_binsize\"]\n",
    "\n",
    "\n",
    "#######################################\n",
    "#   load control saddles here ...\n",
    "########################################\n",
    "# create a track sample map to pass to the multiprocessing job ...\n",
    "track_ctrl_sample_map = {}\n",
    "with h5py.File(\"saddles_ctrlEV_by_distance.hdf5\", 'r') as fr:\n",
    "    # fr.visititems(print_attrs)\n",
    "\n",
    "    # check general metadata ...\n",
    "    _saddle_ctrl_meta = dict(fr.attrs)\n",
    "\n",
    "    # # sort out the results ...\n",
    "    # interaction_sums_trans_asis = {}\n",
    "    # interaction_counts_trans_asis = {}\n",
    "    # # sort out the results ...\n",
    "    # _counts = fr.get(\"counts_trans\")\n",
    "    # for _sample in _counts.keys():\n",
    "    #     interaction_counts_trans_asis[_sample] = _counts.get(_sample)[()]\n",
    "    # _sums = fr.get(\"sums_trans\")\n",
    "    # for _sample in _sums.keys():\n",
    "    #     interaction_sums_trans_asis[_sample] = _sums.get(_sample)[()]\n",
    "\n",
    "    interaction_ctrl_sums = {}\n",
    "    interaction_ctrl_counts = {}\n",
    "    # sort out the results ...\n",
    "    _counts = fr.get(\"counts\")\n",
    "    for _sample in _counts.keys():\n",
    "        _cds = _counts.get(_sample)\n",
    "        # extracting sample to track_sample mapping from HDF5 itself ...\n",
    "        track_ctrl_sample_map[_sample] = _cds.attrs[\"track\"]\n",
    "        interaction_ctrl_counts[_sample] = _cds[()]\n",
    "    _sums = fr.get(\"sums\")\n",
    "    for _sample in _sums.keys():\n",
    "        _sds = _sums.get(_sample)\n",
    "        interaction_ctrl_sums[_sample] = _sds[()]\n",
    "\n",
    "\n",
    "print(f\"loaded {_saddle_ctrl_meta=}\")\n",
    "print(f\"loaded sample to track sample map {track_ctrl_sample_map=}\")\n",
    "\n",
    "# Make control ones were generated using the same parameters ...\n",
    "print(Q_LO == _saddle_ctrl_meta[\"Q_LO\"])\n",
    "print(Q_HI == _saddle_ctrl_meta[\"Q_HI\"])\n",
    "print(N_GROUPS == _saddle_ctrl_meta[\"N_GROUPS\"])\n",
    "print(binsize == _saddle_ctrl_meta[\"cis_binsize\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-load pre-calculated EV1s and coolers - for whatever resolution ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telo_cis_evs = {}\n",
    "for k, _fname in telo_dict.items():\n",
    "    # derive output name\n",
    "    _fname = f\"ev_bedraph/{k}.{binsize//1_000}kb.bed\"\n",
    "    print(f\"reading {_fname} ...\")\n",
    "    telo_cis_evs[k] = bioframe.read_table(_fname, schema=\"bedGraph\", header=0)\n",
    "\n",
    "# cooler files that we'll work on :\n",
    "telo_clrs = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize}\") for _k, _path in telo_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check how digitization goes here ...\n",
    "from cooltools.api.saddle import align_track_with_cooler, digitize\n",
    "from cooltools.api.saddle import saddle_stack\n",
    "\n",
    "print(f\"we use {Q_LO=} {Q_HI=} and split the rest in {N_GROUPS=} ...\")\n",
    "\n",
    "n_bins = int(N_GROUPS)\n",
    "qrange=(Q_LO,Q_HI)\n",
    "\n",
    "_sample = \"m5hR1R2\"\n",
    "_mean_ev_bins = {}\n",
    "for _sample in [\"m5hR1R2\", \"p5hR1R2\"]+[\"N93m5\", \"N93p5\"]:\n",
    "    _track_sample = track_sample_map[_sample]\n",
    "    # track and contact map ...\n",
    "    _ev_track = telo_cis_evs[_track_sample]\n",
    "    _clr = telo_clrs[_sample]\n",
    "    # align track to cooler - whatever that means\n",
    "    track = align_track_with_cooler(\n",
    "        _ev_track,\n",
    "        _clr,\n",
    "        view_df=hg38_arms,\n",
    "        clr_weight_name=\"weight\",\n",
    "        mask_clr_bad_bins=True,\n",
    "        drop_track_na=False,  # this adds check for chromosomes that have all missing values\n",
    "    )\n",
    "    # digitize continous track into N_GROUPS ...\n",
    "    digitized_track, binedges = digitize(\n",
    "        track.iloc[:, :4],\n",
    "        n_bins,\n",
    "        qrange=qrange,\n",
    "        digitized_suffix=\".d\",\n",
    "    )\n",
    "    # grouping \"track\" with \"digitized_track\" - since their index matches\n",
    "    _mean_ev_bins[_sample] = track.groupby(digitized_track[\"value.d\"])[\"value\"].mean()\n",
    "\n",
    "\n",
    "for _sample, _color, _label in zip(\n",
    "    [\"m5hR1R2\", \"p5hR1R2\"]+[\"N93m5\", \"N93p5\"],\n",
    "    [\"blue\",\"red\"]+[\"green\",\"black\"],\n",
    "    [\"ctrl@5h\",\"depletion@5h\"]+[\"ctrlN@5h\",\"depletionN@5h\"],\n",
    "):\n",
    "    _mean_ev_bins[_sample].plot(\n",
    "        kind=\"bar\",\n",
    "        width=1,\n",
    "        color=_color,\n",
    "        label=_label,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "ax = plt.gca()\n",
    "ax.axhline(0, color=\"grey\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def saddle_strength(k, sums_stack, counts_stack, dist_range=None):\n",
    "    \"\"\"\n",
    "    saddle strength aka contrast calculation ...\n",
    "    \"\"\"\n",
    "    if dist_range is not None:\n",
    "        S = np.nansum(sums_stack[dist_range], axis=0)\n",
    "        C = np.nansum(counts_stack[dist_range], axis=0)\n",
    "    else:\n",
    "        S = np.nansum(sums_stack, axis=0)\n",
    "        C = np.nansum(counts_stack, axis=0)\n",
    "\n",
    "    # exclude extremes - the outliers\n",
    "    S = S[1:-1,1:-1]\n",
    "    C = C[1:-1,1:-1]\n",
    "\n",
    "    m, n = S.shape\n",
    "    if m != n:\n",
    "        raise ValueError(\"`saddledata` should be square.\")\n",
    "\n",
    "    # _b corner indices ...\n",
    "    _b = slice(0, k)\n",
    "    # _a corner indices ...\n",
    "    _a = slice(n-k, n)\n",
    "\n",
    "    # make sure corners are equally sized ...\n",
    "    assert (_b.stop - _b.start) == (_a.stop - _a.start)\n",
    "\n",
    "    intra_BB = np.nansum(S[_b, _b]) / np.nansum(C[_b, _b])\n",
    "    intra_AA = np.nansum(S[_a, _a]) / np.nansum(C[_a, _a])\n",
    "    intra_AA_BB = (\n",
    "        (np.nansum(S[_b, _b]) + np.nansum(S[_a, _a])) /\n",
    "        (np.nansum(C[_b, _b]) + np.nansum(C[_a, _a]))\n",
    "    )\n",
    "    inter_AB_BA = (\n",
    "        (np.nansum(S[_b, _a]) + np.nansum(S[_a, _b])) /\n",
    "        (np.nansum(C[_b, _a]) + np.nansum(C[_a, _b]))\n",
    "    )\n",
    "    # ...\n",
    "    # ...\n",
    "    return {\"AA\" : intra_AA/inter_AB_BA, \"BB\" : intra_BB/inter_AB_BA, \"AA_BB\": intra_AA_BB/inter_AB_BA}\n",
    "\n",
    "# # https://stackoverflow.com/questions/48625475/python-shifted-logarithmic-colorbar-white-color-offset-to-center\n",
    "# class MidPointLogNorm(LogNorm):\n",
    "#     def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "#         LogNorm.__init__(self,vmin=vmin, vmax=vmax, clip=clip)\n",
    "#         self.midpoint=midpoint\n",
    "#     def __call__(self, value, clip=None):\n",
    "#         # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "#         # simple example...\n",
    "#         x, y = [np.log(self.vmin), np.log(self.midpoint), np.log(self.vmax)], [0, 0.5, 1]\n",
    "#         return np.ma.masked_array(np.interp(np.log(value), x, y))\n",
    "\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/48625475/python-shifted-logarithmic-colorbar-white-color-offset-to-center\n",
    "class MidPointLogNorm(LogNorm):\n",
    "    # to do introduce clipping ...\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        LogNorm.__init__(self,vmin=vmin, vmax=vmax, clip=clip)\n",
    "        self.midpoint=midpoint\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        vmin, midpoint, vmax = self.vmin, self.midpoint, self.vmax\n",
    "        x, y = [np.log(vmin), np.log(midpoint), np.log(vmax)], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(np.log(value), x, y))\n",
    "\n",
    "    def inverse(self, value):\n",
    "        if not self.scaled():\n",
    "            raise ValueError(\"Not invertible until scaled\")\n",
    "        # t_vmin, t_midpoint, t_vmax = np.log(self.vmin), np.log(self.midpoint), np.log(self.vmax)\n",
    "        vmin, midpoint, vmax = self.vmin, self.midpoint, self.vmax\n",
    "\n",
    "        x, y = [0, 0.5, 1], [np.log(vmin), np.log(midpoint), np.log(vmax)]\n",
    "        # # return np.ma.masked_array(np.interp(np.log(value), x, y))\n",
    "        # if np.iterable(value):\n",
    "        #     val = np.ma.asarray(value)\n",
    "        #     return np.ma.power(val, 1. / gamma) * (vmax - vmin) + vmin\n",
    "        # else:\n",
    "        # return pow(value, 1. / gamma) * (vmax - vmin) + vmin\n",
    "        return np.exp(np.interp(value, x, y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_saddle_data(sample, dist_name, dist_range=None):\n",
    "    \"\"\"\n",
    "    little convenience func - to turn local interaction_sums and interaction_counts\n",
    "    into saddle data ...\n",
    "    \"\"\"\n",
    "    # if dist_name == \"trans\":\n",
    "    #     _sum = np.nansum(interaction_sums_trans[sample], axis=0)\n",
    "    #     _count = np.nansum(interaction_counts_trans[sample], axis=0)\n",
    "    if dist_name == \"trans\":\n",
    "        _sum = np.nansum(interaction_sums[sample], axis=0)\n",
    "        _count = np.nansum(interaction_counts[sample], axis=0)\n",
    "    else:\n",
    "        if dist_range is not None:\n",
    "            _sum = np.nansum(interaction_sums[sample][dist_range], axis=0)\n",
    "            _count = np.nansum(interaction_counts[sample][dist_range], axis=0)\n",
    "        else:\n",
    "            _sum = np.nansum(interaction_sums[sample], axis=0)\n",
    "            _count = np.nansum(interaction_counts[sample], axis=0)\n",
    "    return _sum / _count\n",
    "\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        # norm=LogNorm(vmin=1/5, vmax=5),\n",
    "        norm=MidPointLogNorm(vmin=1/5, vmax=3, midpoint=1),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"nearest\",\n",
    ")\n",
    "\n",
    "\n",
    "# cbarw = 0.7*matw\n",
    "margin = 0.2\n",
    "matw = 0.75\n",
    "cbarh = 0.1\n",
    "\n",
    "# distances = {\n",
    "#     \"all-cis\": slice(None),\n",
    "#     \"trans\": slice(None),\n",
    "# }\n",
    "distances = {\n",
    "    \"all-cis\": slice(None),\n",
    "    # \"trans\": slice(None),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h = [\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(0.5*cbarh),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw), #ctrl\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),  # depletion\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(cbarh),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "\n",
    "# goes from bottom to the top ...\n",
    "v = [\n",
    "    # single color bar at the vewry bottom\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(0.5*cbarh),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(2.5*cbarh),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "_stickingout_bit = sum(_h.fixed_size for _h in h[-3:])\n",
    "print(f\"{_stickingout_bit=}\")\n",
    "\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "\n",
    "samples = [\"m5hR1R2\", \"p5hR1R2\"]\n",
    "mev_colors = [\"tab:blue\", \"tab:red\"]\n",
    "\n",
    "axs = {}\n",
    "axq_hor = {}\n",
    "axm = {}\n",
    "for i, _sample in enumerate(samples):\n",
    "    _nx = 2*(i+1)+1\n",
    "    _ny = 3\n",
    "    axs[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny))\n",
    "    axq_hor[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny-2))\n",
    "    axm[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny+2))\n",
    "axlow = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, nx1=6, ny=0))\n",
    "axq_ver = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=_ny))\n",
    "# colorbar ...\n",
    "cbar_ax = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx+2, ny=_ny))\n",
    "\n",
    "# traverse nested dict to access the axes ...\n",
    "for _ax in (\n",
    "    list(axs.values()) + list(axq_hor.values()) + list(axm.values()) + [axq_ver, cbar_ax]\n",
    "):\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "\n",
    "for _sample, _mcolor in zip(samples, mev_colors):\n",
    "    for _dist_key, _dist in distances.items():\n",
    "        if _dist_key != \"trans\":\n",
    "            C = np.nanmean(interaction_sums[_sample][_dist], axis=0) / np.nanmean(interaction_counts[_sample][_dist], axis=0)\n",
    "            _strength_dict = saddle_strength(11, interaction_sums[_sample], interaction_counts[_sample], dist_range=_dist)\n",
    "        elif _dist_key == \"trans\":\n",
    "            C = np.nanmean(interaction_sums_trans[_sample][_dist], axis=0) / np.nanmean(interaction_counts_trans[_sample][_dist], axis=0)\n",
    "            _strength_dict = saddle_strength(11, interaction_sums_trans[_sample], interaction_counts_trans[_sample], dist_range=_dist)\n",
    "        else:\n",
    "            pass\n",
    "        _h = axs[_sample].imshow(C[1:-1,1:-1], **imshow_kwargs)\n",
    "        _h.cmap.set_over(\"#300000\")\n",
    "        _h.cmap.set_under(\"black\")\n",
    "        _sa = _strength_dict[\"AA\"]\n",
    "        _sb = _strength_dict[\"BB\"]\n",
    "        _bx = 1\n",
    "        _ax = C.shape[0]-2-1\n",
    "        axs[_sample].text(_bx, _bx, f\"{_sb:.2f}\", fontsize=8, ha=\"left\", va=\"top\")\n",
    "        axs[_sample].text(_ax, _ax, f\"{_sa:.2f}\", fontsize=8, ha=\"right\", va=\"bottom\")\n",
    "        # ...\n",
    "    data = _mean_ev_bins[_sample].loc[1:n_bins]\n",
    "    assert len(data) == n_bins\n",
    "    axm[_sample].fill_between(data.index, data, 0, color=_mcolor, ec=\"grey\", step=\"mid\", linewidth=0.25)\n",
    "    axm[_sample].set_ylim(-1.2,1.2)\n",
    "    axm[_sample].set_xlim(1-0.1,n_bins+0.1)\n",
    "    axm[_sample].spines[:].set_visible(False)\n",
    "    axm[_sample].axhline(0,color=\"grey\",lw=0.5)\n",
    "    axm[_sample].spines[\"left\"].set_visible(True)\n",
    "    _track_sample = track_sample_map[_sample].rstrip(\"R1R2\")\n",
    "    axm[_sample].set_title(f\"{_sample}@{_track_sample}\", fontsize=6, pad=0)\n",
    "    # ev quantiles ...\n",
    "    axq_hor[_sample].fill_between(data.index, np.asarray(data.index), 0, color=\"grey\", ec=\"grey\", step=\"mid\", linewidth=0.5)\n",
    "    axq_hor[_sample].set_ylim(0, n_bins+1)\n",
    "    axq_hor[_sample].set_xlim(1-0.1,n_bins+0.1)\n",
    "    axq_hor[_sample].spines[:].set_visible(False)\n",
    "    axq_hor[_sample].invert_yaxis()\n",
    "    # axm[_sample].axhline(0,color=\"grey\",lw=0.5)\n",
    "    # # axm[_sample].spines[\"right\"].set_visible(True)\n",
    "    # axm[_sample].spines[\"left\"].set_visible(True)\n",
    "axq_ver.fill_betweenx(data.index, np.asarray(data.index), 0, color=\"grey\", ec=\"grey\", step=\"mid\", linewidth=0.5)\n",
    "axq_ver.set_xlim(0, n_bins+1)\n",
    "axq_ver.set_ylim(1-0.1,n_bins+0.1)\n",
    "axq_ver.spines[:].set_visible(False)\n",
    "axq_ver.invert_yaxis()\n",
    "axq_ver.invert_xaxis()\n",
    "axq_ver.set_ylabel(\n",
    "    \"EV1 quantiles\",\n",
    "    fontsize=6,\n",
    "    labelpad=0,\n",
    ")\n",
    "\n",
    "axlow.text(\n",
    "    0.5, 0.9,\n",
    "    \"EV1 quantiles\",\n",
    "    ha='center', va='top',\n",
    "    transform = axlow.transAxes,\n",
    "    fontsize=6,\n",
    ")\n",
    "axlow.axis(\"off\")\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"vertical\",\n",
    ")\n",
    "_vmin = imshow_kwargs[\"norm\"].vmin\n",
    "_midpoint = imshow_kwargs[\"norm\"].midpoint\n",
    "_vmax = imshow_kwargs[\"norm\"].vmax\n",
    "cbar_ax.set_yticks(\n",
    "    [_vmin, _midpoint, _vmax],\n",
    "    labels=[f\"{v:.1f}\" for v in [_vmin, _midpoint, _vmax]],\n",
    "    fontsize=6,\n",
    ")\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.0, pad=1)\n",
    "for _tidx, tick in enumerate(cbar_ax.yaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_verticalalignment(\"bottom\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_verticalalignment(\"top\")\n",
    "    else:\n",
    "        tick.set_verticalalignment(\"center\")\n",
    "\n",
    "fig.savefig(\"Fig6B.svg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h = [\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(0.5*cbarh),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw), #ctrl\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),  # depletion\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(cbarh),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "\n",
    "# goes from bottom to the top ...\n",
    "v = [\n",
    "    # single color bar at the vewry bottom\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(0.5*cbarh),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(2.5*cbarh),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "_stickingout_bit = sum(_h.fixed_size for _h in h[-3:])\n",
    "print(f\"{_stickingout_bit=}\")\n",
    "\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "\n",
    "samples = [\"N93m5\", \"N93p5\"]\n",
    "mev_colors = [\"tab:blue\", \"tab:red\"]\n",
    "\n",
    "axs = {}\n",
    "axq_hor = {}\n",
    "axm = {}\n",
    "for i, _sample in enumerate(samples):\n",
    "    _nx = 2*(i+1)+1\n",
    "    _ny = 3\n",
    "    axs[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny))\n",
    "    axq_hor[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny-2))\n",
    "    axm[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny+2))\n",
    "axlow = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, nx1=6, ny=0))\n",
    "axq_ver = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=_ny))\n",
    "# colorbar ...\n",
    "cbar_ax = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx+2, ny=_ny))\n",
    "\n",
    "# traverse nested dict to access the axes ...\n",
    "for _ax in (\n",
    "    list(axs.values()) + list(axq_hor.values()) + list(axm.values()) + [axq_ver, cbar_ax]\n",
    "):\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "\n",
    "\n",
    "for _sample, _mcolor in zip(samples, mev_colors):\n",
    "    for _dist_key, _dist in distances.items():\n",
    "        if _dist_key != \"trans\":\n",
    "            C = np.nanmean(interaction_sums[_sample][_dist], axis=0) / np.nanmean(interaction_counts[_sample][_dist], axis=0)\n",
    "            _strength_dict = saddle_strength(11, interaction_sums[_sample], interaction_counts[_sample], dist_range=_dist)\n",
    "        elif _dist_key == \"trans\":\n",
    "            C = np.nanmean(interaction_sums_trans[_sample][_dist], axis=0) / np.nanmean(interaction_counts_trans[_sample][_dist], axis=0)\n",
    "            _strength_dict = saddle_strength(11, interaction_sums_trans[_sample], interaction_counts_trans[_sample], dist_range=_dist)\n",
    "        else:\n",
    "            pass\n",
    "        _h = axs[_sample].imshow(C[1:-1,1:-1], **imshow_kwargs)\n",
    "        _h.cmap.set_over(\"#300000\")\n",
    "        _h.cmap.set_under(\"black\")\n",
    "        _sa = _strength_dict[\"AA\"]\n",
    "        _sb = _strength_dict[\"BB\"]\n",
    "        _bx = 1\n",
    "        _ax = C.shape[0]-2-1\n",
    "        axs[_sample].text(_bx, _bx, f\"{_sb:.2f}\", fontsize=8, ha=\"left\", va=\"top\")\n",
    "        axs[_sample].text(_ax, _ax, f\"{_sa:.2f}\", fontsize=8, ha=\"right\", va=\"bottom\")\n",
    "        # ...\n",
    "    data = _mean_ev_bins[_sample].loc[1:n_bins]\n",
    "    assert len(data) == n_bins\n",
    "    axm[_sample].fill_between(data.index, data, 0, color=_mcolor, ec=\"grey\", step=\"mid\", linewidth=0.25)\n",
    "    axm[_sample].set_ylim(-1.2,1.2)\n",
    "    axm[_sample].set_xlim(1-0.1,n_bins+0.1)\n",
    "    axm[_sample].spines[:].set_visible(False)\n",
    "    axm[_sample].axhline(0,color=\"grey\",lw=0.5)\n",
    "    axm[_sample].spines[\"left\"].set_visible(True)\n",
    "    _track_sample = track_sample_map[_sample].rstrip(\"R1R2\")\n",
    "    axm[_sample].set_title(f\"{_sample}@{_track_sample}\", fontsize=6, pad=0)\n",
    "    # ev quantiles ...\n",
    "    axq_hor[_sample].fill_between(data.index, np.asarray(data.index), 0, color=\"grey\", ec=\"grey\", step=\"mid\", linewidth=0.5)\n",
    "    axq_hor[_sample].set_ylim(0, n_bins+1)\n",
    "    axq_hor[_sample].set_xlim(1-0.1,n_bins+0.1)\n",
    "    axq_hor[_sample].spines[:].set_visible(False)\n",
    "    axq_hor[_sample].invert_yaxis()\n",
    "    # axm[_sample].axhline(0,color=\"grey\",lw=0.5)\n",
    "    # # axm[_sample].spines[\"right\"].set_visible(True)\n",
    "    # axm[_sample].spines[\"left\"].set_visible(True)\n",
    "axq_ver.fill_betweenx(data.index, np.asarray(data.index), 0, color=\"grey\", ec=\"grey\", step=\"mid\", linewidth=0.5)\n",
    "axq_ver.set_xlim(0, n_bins+1)\n",
    "axq_ver.set_ylim(1-0.1,n_bins+0.1)\n",
    "axq_ver.spines[:].set_visible(False)\n",
    "axq_ver.invert_yaxis()\n",
    "axq_ver.invert_xaxis()\n",
    "axq_ver.set_ylabel(\n",
    "    \"EV1 quantiles\",\n",
    "    fontsize=6,\n",
    "    labelpad=0,\n",
    ")\n",
    "\n",
    "axlow.text(\n",
    "    0.5, 0.9,\n",
    "    \"EV1 quantiles\",\n",
    "    ha='center', va='top',\n",
    "    transform = axlow.transAxes,\n",
    "    fontsize=6,\n",
    ")\n",
    "axlow.axis(\"off\")\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"vertical\",\n",
    ")\n",
    "_vmin = imshow_kwargs[\"norm\"].vmin\n",
    "_midpoint = imshow_kwargs[\"norm\"].midpoint\n",
    "_vmax = imshow_kwargs[\"norm\"].vmax\n",
    "cbar_ax.set_yticks(\n",
    "    [_vmin, _midpoint, _vmax],\n",
    "    labels=[f\"{v:.1f}\" for v in [_vmin, _midpoint, _vmax]],\n",
    "    fontsize=6,\n",
    ")\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.0, pad=1)\n",
    "for _tidx, tick in enumerate(cbar_ax.yaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_verticalalignment(\"bottom\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_verticalalignment(\"top\")\n",
    "    else:\n",
    "        tick.set_verticalalignment(\"center\")\n",
    "\n",
    "fig.savefig(\"FigExt76C_nup.svg\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h = [\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(0.5*cbarh),\n",
    "    # Size.Fixed(0.2*margin),\n",
    "    # Size.Fixed(matw), #ctrl\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),  # depletion\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(cbarh),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "\n",
    "# goes from bottom to the top ...\n",
    "v = [\n",
    "    # single color bar at the vewry bottom\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(0.5*cbarh),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(2.5*cbarh),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "_stickingout_bit = sum(_h.fixed_size for _h in h[-3:])\n",
    "print(f\"{_stickingout_bit=}\")\n",
    "\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "\n",
    "# samples = [\"N93m5\", \"N93p5\"]\n",
    "# mev_colors = [\"tab:blue\", \"tab:red\"]\n",
    "samples = [\"N93p5\",]\n",
    "mev_colors = [\"tab:blue\",]\n",
    "\n",
    "axs = {}\n",
    "axq_hor = {}\n",
    "axm = {}\n",
    "for i, _sample in enumerate(samples):\n",
    "    _nx = 2*(i+1)+1\n",
    "    _ny = 3\n",
    "    axs[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny))\n",
    "    axq_hor[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny-2))\n",
    "    axm[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny+2))\n",
    "axlow = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=3, nx1=6, ny=0))\n",
    "axq_ver = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=1, ny=_ny))\n",
    "# colorbar ...\n",
    "cbar_ax = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx+2, ny=_ny))\n",
    "\n",
    "# traverse nested dict to access the axes ...\n",
    "for _ax in (\n",
    "    list(axs.values()) + list(axq_hor.values()) + list(axm.values()) + [axq_ver, cbar_ax]\n",
    "):\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "\n",
    "\n",
    "for _sample, _mcolor in zip(samples, mev_colors):\n",
    "    for _dist_key, _dist in distances.items():\n",
    "        if _dist_key != \"trans\":\n",
    "            C = np.nanmean(interaction_ctrl_sums[_sample][_dist], axis=0) / np.nanmean(interaction_ctrl_counts[_sample][_dist], axis=0)\n",
    "            _strength_dict = saddle_strength(11, interaction_ctrl_sums[_sample], interaction_ctrl_counts[_sample], dist_range=_dist)\n",
    "        elif _dist_key == \"trans\":\n",
    "            C = np.nanmean(interaction_ctrl_sums_trans[_sample][_dist], axis=0) / np.nanmean(interaction_ctrl_counts_trans[_sample][_dist], axis=0)\n",
    "            _strength_dict = saddle_strength(11, interaction_ctrl_sums_trans[_sample], interaction_ctrl_counts_trans[_sample], dist_range=_dist)\n",
    "        else:\n",
    "            pass\n",
    "        _h = axs[_sample].imshow(C[1:-1,1:-1], **imshow_kwargs)\n",
    "        _h.cmap.set_over(\"#300000\")\n",
    "        _h.cmap.set_under(\"black\")\n",
    "        _sa = _strength_dict[\"AA\"]\n",
    "        _sb = _strength_dict[\"BB\"]\n",
    "        _bx = 1\n",
    "        _ax = C.shape[0]-2-1\n",
    "        axs[_sample].text(_bx, _bx, f\"{_sb:.2f}\", fontsize=8, ha=\"left\", va=\"top\")\n",
    "        axs[_sample].text(_ax, _ax, f\"{_sa:.2f}\", fontsize=8, ha=\"right\", va=\"bottom\")\n",
    "        # ...\n",
    "    _track_sample = track_ctrl_sample_map[_sample]\n",
    "    _track_sample_text = _track_sample.rstrip(\"R1R2\")\n",
    "    data = _mean_ev_bins[_track_sample].loc[1:n_bins]\n",
    "    assert len(data) == n_bins\n",
    "    axm[_sample].fill_between(data.index, data, 0, color=_mcolor, ec=\"grey\", step=\"mid\", linewidth=0.25)\n",
    "    axm[_sample].set_ylim(-1.2,1.2)\n",
    "    axm[_sample].set_xlim(1-0.1,n_bins+0.1)\n",
    "    axm[_sample].spines[:].set_visible(False)\n",
    "    axm[_sample].axhline(0,color=\"grey\",lw=0.5)\n",
    "    axm[_sample].spines[\"left\"].set_visible(True)\n",
    "    _track_sample = track_ctrl_sample_map[_sample].rstrip(\"R1R2\")\n",
    "    axm[_sample].set_title(f\"{_sample}@{_track_sample_text}\", fontsize=6, pad=0)\n",
    "    # ev quantiles ...\n",
    "    axq_hor[_sample].fill_between(data.index, np.asarray(data.index), 0, color=\"grey\", ec=\"grey\", step=\"mid\", linewidth=0.5)\n",
    "    axq_hor[_sample].set_ylim(0, n_bins+1)\n",
    "    axq_hor[_sample].set_xlim(1-0.1,n_bins+0.1)\n",
    "    axq_hor[_sample].spines[:].set_visible(False)\n",
    "    axq_hor[_sample].invert_yaxis()\n",
    "    # axm[_sample].axhline(0,color=\"grey\",lw=0.5)\n",
    "    # # axm[_sample].spines[\"right\"].set_visible(True)\n",
    "    # axm[_sample].spines[\"left\"].set_visible(True)\n",
    "axq_ver.fill_betweenx(data.index, np.asarray(data.index), 0, color=\"grey\", ec=\"grey\", step=\"mid\", linewidth=0.5)\n",
    "axq_ver.set_xlim(0, n_bins+1)\n",
    "axq_ver.set_ylim(1-0.1,n_bins+0.1)\n",
    "axq_ver.spines[:].set_visible(False)\n",
    "axq_ver.invert_yaxis()\n",
    "axq_ver.invert_xaxis()\n",
    "axq_ver.set_ylabel(\n",
    "    \"EV1 quantiles\",\n",
    "    fontsize=6,\n",
    "    labelpad=0,\n",
    ")\n",
    "\n",
    "axlow.text(\n",
    "    0.5, 0.9,\n",
    "    \"EV1 quantiles\",\n",
    "    ha='center', va='top',\n",
    "    transform = axlow.transAxes,\n",
    "    fontsize=6,\n",
    ")\n",
    "axlow.axis(\"off\")\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"vertical\",\n",
    ")\n",
    "_vmin = imshow_kwargs[\"norm\"].vmin\n",
    "_midpoint = imshow_kwargs[\"norm\"].midpoint\n",
    "_vmax = imshow_kwargs[\"norm\"].vmax\n",
    "cbar_ax.set_yticks(\n",
    "    [_vmin, _midpoint, _vmax],\n",
    "    labels=[f\"{v:.1f}\" for v in [_vmin, _midpoint, _vmax]],\n",
    "    fontsize=6,\n",
    ")\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.0, pad=1)\n",
    "for _tidx, tick in enumerate(cbar_ax.yaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_verticalalignment(\"bottom\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_verticalalignment(\"top\")\n",
    "    else:\n",
    "        tick.set_verticalalignment(\"center\")\n",
    "\n",
    "fig.savefig(\"FigExt76D_nup_ctrl.svg\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy plotting ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples_m = [\n",
    "    \"mMito\",\n",
    "    \"mTelo\",\n",
    "    \"mCyto\",\n",
    "    \"m5hR1R2\",\n",
    "    \"m10hR1R2\",\n",
    "]\n",
    "sub_samples_p = [\n",
    "    \"pMito\",\n",
    "    \"pTelo\",\n",
    "    \"pCyto\",\n",
    "    \"p5hR1R2\",\n",
    "    \"p10hR1R2\",\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples_m),\n",
    "    ncols=2*len(distances),\n",
    "    figsize=(4*len(distances),2*len(sub_samples_m)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "for sample_m, sample_p, (i, _axs) in zip(sub_samples_m, sub_samples_p, enumerate(axs)):\n",
    "    for jj, (_dist_name, _dist) in enumerate(distances.items()):\n",
    "        axm, axp = _axs[jj], _axs[len(distances) + jj]\n",
    "        Cm = get_saddle_data(sample_m, _dist_name, _dist)\n",
    "        Cp = get_saddle_data(sample_p, _dist_name, _dist)\n",
    "        axm.imshow(Cm[1:-1,1:-1], **imshow_kwargs)\n",
    "        axp.imshow(Cp[1:-1,1:-1], **imshow_kwargs)\n",
    "\n",
    "# annotate labels and titles ...\n",
    "for jj, _dist_name in enumerate(distances):\n",
    "    # m ...\n",
    "    axs[0, jj].set_title(f\"m-{_dist_name}\")\n",
    "    # p ...\n",
    "    axs[0, len(distances) + jj].set_title(f\"p-{_dist_name}\")\n",
    "for ii, _sample in enumerate(sub_samples_m):\n",
    "    axs[ii,0].set_ylabel(_sample.lstrip(\"m\"))\n",
    "    axs[ii,0].set_yticks([])\n",
    "    axs[ii,0].set_xticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples_m = [\n",
    "    \"mCyto\",\n",
    "    \"m5hR1R2\",\n",
    "]\n",
    "sub_samples_p = [\n",
    "    \"pCyto\",\n",
    "    \"p5hR1R2\",\n",
    "]\n",
    "\n",
    "# introduce distance ranges\n",
    "distances = {\n",
    "    \"cis\": slice(None),\n",
    "    \"trans\": slice(None),\n",
    "}\n",
    "\n",
    "\n",
    "# cbarw = 0.7*matw\n",
    "margin = 0.2\n",
    "matw = 0.75\n",
    "cbarh = 0.1\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/3, vmax=3),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"nearest\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create legends ......\n",
    "IPG_cmap = {\n",
    "    3: \"cornflowerblue\",  # B\n",
    "    2: \"#ffee99\",  # V+VI\n",
    "    1: \"orangered\",  # A2\n",
    "    0: \"maroon\",  # A1\n",
    "    # 0: \"#D9E2EF\",  #\"none\"\n",
    "}\n",
    "ticklabels_ipg=[\"B\",\"VVI\",\"A2\",\"A1\"]\n",
    "\n",
    "\n",
    "IPGwID_cmap = {\n",
    "    6: \"cornflowerblue\",  # B\n",
    "    5: \"#ffee99\",  # V+VI\n",
    "    4: \"#ffee99\",  # V+VI-ID\n",
    "    3: \"orangered\",  # A2\n",
    "    2: \"orangered\",  # A2-ID\n",
    "    1: \"maroon\",  # A1\n",
    "    0: \"maroon\",  # A1-ID\n",
    "    # 0: \"#D9E2EF\",  #\"none\"\n",
    "}\n",
    "ticklabels_ipgid=[\"B\",\"VVI\",\"VVI-ID\",\"A2\",\"A2-ID\",\"A1\",\"A1-ID\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw actual figures with the semi-manual custom layout ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h = [\n",
    "    Size.Fixed(margin),\n",
    "    # Cyto\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(margin),\n",
    "    # 5hr\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    # bar ...\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(cbarh),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "\n",
    "# goes from bottom to the top ...\n",
    "v = [\n",
    "    # single color bar at the vewry bottom\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(0.5*cbarh),\n",
    "    # bottom - with IDs\n",
    "    Size.Fixed(0.5*margin),\n",
    "    Size.Fixed(cbarh),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    # upper - as is ...\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(cbarh),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "_stickingout_bit = sum(_h.fixed_size for _h in h[-3:])\n",
    "print(f\"{_stickingout_bit=}\")\n",
    "\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "\n",
    "\n",
    "axs = {}\n",
    "for i, _sample in enumerate(sub_samples_m + sub_samples_p):\n",
    "    axs[_sample] = {}\n",
    "    _nx_i = 2*i+1\n",
    "    axs[_sample][\"bottom_legend\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=1+2))\n",
    "    axs[_sample][\"trans_ID_saddle\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=3+2))\n",
    "    axs[_sample][\"cis_ID_saddle\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=5+2))\n",
    "    axs[_sample][\"upper_legend\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=7+2))\n",
    "    axs[_sample][\"trans_IPG_saddle\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=9+2))\n",
    "    axs[_sample][\"cis_IPG_saddle\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=11+2))\n",
    "# colorbar ...\n",
    "cbar_ax = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=1))\n",
    "# very last column with legends ....\n",
    "_nx_i = 2*(i+1)+1\n",
    "axs[\"bottom_right_legend\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=3+2))\n",
    "axs[\"bottom_right_legend2\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=5+2))\n",
    "axs[\"upper_right_legend\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=9+2))\n",
    "axs[\"upper_right_legend2\"] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx_i, ny=11+2))\n",
    "\n",
    "# traverse nested dict to access the axes ...\n",
    "for _ax in sum([ [v for v in axs[s].values()] for s in (sub_samples_m+sub_samples_p) ], start=[]):\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "# do the remaining ones (not nested one as well) ...\n",
    "for _ax in [ v for k,v in axs.items() if k not in (sub_samples_m+sub_samples_p) ]:\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "cbar_ax.set_xticks([])\n",
    "cbar_ax.set_yticks([])\n",
    "\n",
    "# reorder for the ones with IDs ...\n",
    "_reidxs = [0,3,1,4,2,5,6]\n",
    "\n",
    "\n",
    "for _sample in (sub_samples_m+sub_samples_p):\n",
    "    for _dist_key, _dist in distances.items():\n",
    "        # IPG saddles As is ...\n",
    "        if _dist_key != \"trans\":\n",
    "            C = np.nanmean(interaction_sums_asis[_sample][_dist], axis=0) / np.nanmean(interaction_counts_asis[_sample][_dist], axis=0)\n",
    "        elif _dist_key == \"trans\":\n",
    "            C = np.nanmean(interaction_sums_trans_asis[_sample][_dist], axis=0) / np.nanmean(interaction_counts_trans_asis[_sample][_dist], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        _h = axs[_sample][f\"{_dist_key}_IPG_saddle\"].imshow(C[1:,1:], **imshow_kwargs)\n",
    "        _h.cmap.set_over(\"#300000\")\n",
    "        # extract size ...\n",
    "        _num_ipg_colors, _ = C[1:,1:].shape\n",
    "        # IPG saddles with IDs ...\n",
    "        if _dist_key != \"trans\":\n",
    "            C = np.nanmean(interaction_sums_wids[_sample][_dist], axis=0) / np.nanmean(interaction_counts_wids[_sample][_dist], axis=0)\n",
    "        elif _dist_key == \"trans\":\n",
    "            C = np.nanmean(interaction_sums_trans_wids[_sample][_dist], axis=0) / np.nanmean(interaction_counts_trans_wids[_sample][_dist], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        _h = axs[_sample][f\"{_dist_key}_ID_saddle\"].imshow(C[1:,1:][_reidxs][:,_reidxs], **imshow_kwargs)\n",
    "        _h.cmap.set_over(\"#300000\")\n",
    "        # extract size ...\n",
    "        _num_ipg_wIDs_colors, _ = C[1:,1:].shape\n",
    "\n",
    "# create a \"fake\" legend for IPGs - for now ...\n",
    "_fdata = np.reshape(np.arange(_num_ipg_colors), (-1,1))\n",
    "_fcmap = plt.cm.gray\n",
    "_fnorm = plt.Normalize()\n",
    "_frgba = _fcmap(_fnorm(_fdata))\n",
    "_frgbaT = _fcmap(_fnorm(_fdata.T))\n",
    "# ...\n",
    "for i in range(_num_ipg_colors):\n",
    "    _frgba[i,0] = list(mpl.colors.to_rgb(IPG_cmap[i]))+[1]\n",
    "    _frgbaT[0,i] = list(mpl.colors.to_rgb(IPG_cmap[i]))+[1]\n",
    "\n",
    "for _sample in (sub_samples_m+sub_samples_p):\n",
    "    axs[_sample][\"upper_legend\"].imshow(_frgbaT, aspect=\"auto\")\n",
    "    for _ in range(max(IPG_cmap.keys())):\n",
    "        axs[_sample][\"upper_legend\"].axvline(_+.5,color=\"black\",lw=0.5)\n",
    "axs[\"upper_right_legend\"].imshow(_frgba, aspect=\"auto\")\n",
    "axs[\"upper_right_legend2\"].imshow(_frgba, aspect=\"auto\")\n",
    "for _ in range(max(IPG_cmap.keys())):\n",
    "    axs[\"upper_right_legend\"].axhline(_+.5,color=\"black\",lw=0.5)\n",
    "    axs[\"upper_right_legend2\"].axhline(_+.5,color=\"black\",lw=0.5)\n",
    "# try adding labels to the right ...\n",
    "axs[\"upper_right_legend\"].yaxis.tick_right()\n",
    "axs[\"upper_right_legend\"].set_yticks(\n",
    "    list(IPG_cmap.keys()),\n",
    "    labels=ticklabels_ipg,\n",
    "    fontsize=6,\n",
    ")\n",
    "axs[\"upper_right_legend\"].tick_params(length=1.5, pad=1)\n",
    "\n",
    "# create a \"fake\" legend for IPGs - for now ...\n",
    "_fdata = np.reshape(np.arange(_num_ipg_wIDs_colors), (-1,1))\n",
    "_frgba = _fcmap(_fnorm(_fdata))\n",
    "_frgbaT = _fcmap(_fnorm(_fdata.T))\n",
    "# ...\n",
    "for i in range(_num_ipg_wIDs_colors):\n",
    "    _frgba[i,0] = list(mpl.colors.to_rgb(IPGwID_cmap[i]))+[1]\n",
    "    _frgbaT[0,i] = list(mpl.colors.to_rgb(IPGwID_cmap[i]))+[1]\n",
    "\n",
    "for _sample in (sub_samples_m+sub_samples_p):\n",
    "    axs[_sample][\"bottom_legend\"].imshow(_frgbaT, aspect=\"auto\")\n",
    "    for _ in range(max(IPGwID_cmap.keys())):\n",
    "        axs[_sample][\"bottom_legend\"].axvline(_+.5,color=\"black\",lw=0.5)\n",
    "axs[\"bottom_right_legend\"].imshow(_frgba, aspect=\"auto\")\n",
    "axs[\"bottom_right_legend2\"].imshow(_frgba, aspect=\"auto\")\n",
    "for _ in range(max(IPGwID_cmap.keys())):\n",
    "    axs[\"bottom_right_legend\"].axhline(_+.5,color=\"black\",lw=0.5)\n",
    "    axs[\"bottom_right_legend2\"].axhline(_+.5,color=\"black\",lw=0.5)\n",
    "# try adding labels to the right ...\n",
    "axs[\"bottom_right_legend\"].yaxis.tick_right()\n",
    "axs[\"bottom_right_legend\"].set_yticks(\n",
    "    list(IPGwID_cmap.keys()),\n",
    "    labels=ticklabels_ipgid,\n",
    "    fontsize=6,\n",
    ")\n",
    "axs[\"bottom_right_legend\"].tick_params(length=1.5, pad=1)\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "_vmin = imshow_kwargs[\"norm\"].vmin\n",
    "_vmax = imshow_kwargs[\"norm\"].vmax\n",
    "cbar_ax.set_xticks([_vmin, 1, _vmax])\n",
    "cbar_ax.set_xticklabels([f\"{_vmin:.2f}\", 1, _vmax], fontsize=6)\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.5, pad=1)#,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "for _tidx, tick in enumerate(cbar_ax.xaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_horizontalalignment(\"left\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_horizontalalignment(\"right\")\n",
    "    else:\n",
    "        tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "fig.savefig(\"Fig6D.pdf\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h = [\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(matw), #ctrl\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),  # nup93\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(cbarh),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "\n",
    "# goes from bottom to the top ...\n",
    "v = [\n",
    "    # single color bar at the vewry bottom\n",
    "    Size.Fixed(margin),\n",
    "    Size.Fixed(0.5*cbarh),\n",
    "    Size.Fixed(0.33*margin),\n",
    "    Size.Fixed(cbarh),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(0.2*margin),\n",
    "    Size.Fixed(matw),\n",
    "    Size.Fixed(margin),\n",
    "]\n",
    "_stickingout_bit = sum(_h.fixed_size for _h in h[-3:])\n",
    "print(f\"{_stickingout_bit=}\")\n",
    "\n",
    "# set figsize based on the tiling provided ...\n",
    "fig_width = sum(_h.fixed_size for _h in h)\n",
    "fig_height = sum(_v.fixed_size for _v in v)\n",
    "fig = plt.figure(\n",
    "    figsize=(fig_width, fig_height),\n",
    "    # facecolor='lightblue'\n",
    ")\n",
    "print(f\"figure size {fig_width=} {fig_height=}\")\n",
    "# ...\n",
    "divider = Divider(fig, (0, 0, 1, 1), h, v, aspect=False)\n",
    "\n",
    "\n",
    "nup_samples = [\"N93m5\",\"N93p5\"]\n",
    "\n",
    "axs = {}\n",
    "axl = {}\n",
    "axv = {}\n",
    "for i, _sample in enumerate(nup_samples):\n",
    "    _nx = 2*i+1\n",
    "    axs[_sample] = {}\n",
    "    axl[_sample] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=3))\n",
    "    for j, _dist_key in enumerate(reversed(distances)):\n",
    "        _ny = 2*j+5\n",
    "        axs[_sample][_dist_key] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=_ny))\n",
    "        if _sample == nup_samples[-1]:\n",
    "            axv[_dist_key] = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx+2, ny=_ny))\n",
    "# colorbar ...\n",
    "cbar_ax = fig.add_axes(divider.get_position(), axes_locator=divider.new_locator(nx=_nx, ny=1))\n",
    "\n",
    "# traverse nested dict to access the axes ...\n",
    "for _ax in (\n",
    "    sum([ [v for v in axs[s].values()] for s in nup_samples ], start=[]) +\n",
    "    list(axl.values()) + list(axv.values()) + [cbar_ax]\n",
    "):\n",
    "    _ax.set_xticks([])\n",
    "    _ax.set_yticks([])\n",
    "\n",
    "# reorder for the ones with IDs ...\n",
    "_reidxs = [0,3,1,4,2,5,6]\n",
    "for _sample in nup_samples:\n",
    "    for _dist_key, _dist in distances.items():\n",
    "        # IPG saddles w IDs ....\n",
    "        if _dist_key != \"trans\":\n",
    "            C = np.nanmean(interaction_sums_wids[_sample][_dist], axis=0) / np.nanmean(interaction_counts_wids[_sample][_dist], axis=0)\n",
    "        elif _dist_key == \"trans\":\n",
    "            C = np.nanmean(interaction_sums_trans_wids[_sample][_dist], axis=0) / np.nanmean(interaction_counts_trans_wids[_sample][_dist], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        _h = axs[_sample][_dist_key].imshow(C[1:,1:][_reidxs][:,_reidxs], **imshow_kwargs)\n",
    "        _h.cmap.set_over(\"#300000\")\n",
    "        # ...\n",
    "        if _sample == nup_samples[0]:\n",
    "            axs[_sample][_dist_key].set_ylabel(_dist_key, fontsize=8, labelpad=1)\n",
    "        if _dist_key == \"cis\":\n",
    "            axs[_sample][_dist_key].set_title(_sample, fontsize=8, pad=1)\n",
    "        # extract size ...\n",
    "        _num_ipg_wIDs_colors, _ = C[1:,1:].shape\n",
    "\n",
    "# create a \"fake\" legend for IPGs - for now ...\n",
    "_fdata = np.reshape(np.arange(_num_ipg_wIDs_colors), (-1,1))\n",
    "_fcmap = plt.cm.gray\n",
    "_fnorm = plt.Normalize()\n",
    "_frgba = _fcmap(_fnorm(_fdata))\n",
    "_frgbaT = _fcmap(_fnorm(_fdata.T))\n",
    "# ...\n",
    "for i in range(_num_ipg_wIDs_colors):\n",
    "    _frgba[i,0] = list(mpl.colors.to_rgb(IPGwID_cmap[i]))+[1]\n",
    "    _frgbaT[0,i] = list(mpl.colors.to_rgb(IPGwID_cmap[i]))+[1]\n",
    "\n",
    "\n",
    "for _sample in nup_samples:\n",
    "    axl[_sample].imshow(_frgbaT, aspect=\"auto\")\n",
    "    for _ in range(max(IPGwID_cmap.keys())):\n",
    "        axl[_sample].axvline(_+.5,color=\"black\",lw=0.5)\n",
    "\n",
    "for _dist_key in distances:\n",
    "    axv[_dist_key].imshow(_frgba, aspect=\"auto\")\n",
    "    for _ in range(max(IPGwID_cmap.keys())):\n",
    "        axv[_dist_key].axhline(_+.5,color=\"black\",lw=0.5)\n",
    "\n",
    "# try adding labels to the right ...\n",
    "axv[\"trans\"].yaxis.tick_right()\n",
    "axv[\"trans\"].set_yticks(\n",
    "    list(IPGwID_cmap.keys()),\n",
    "    labels=ticklabels_ipgid,\n",
    "    fontsize=6,\n",
    ")\n",
    "axv[\"trans\"].tick_params(length=1.5, pad=1)\n",
    "\n",
    "\n",
    "# add a single colorbar ...\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "_vmin = imshow_kwargs[\"norm\"].vmin\n",
    "_vmax = imshow_kwargs[\"norm\"].vmax\n",
    "cbar_ax.set_xticks([_vmin, 1, _vmax])\n",
    "cbar_ax.set_xticklabels([f\"{_vmin:.2f}\", 1, _vmax], fontsize=6)\n",
    "cbar_ax.minorticks_off()\n",
    "cbar_ax.tick_params(length=1.5, pad=1)#,direction='out', length=6, width=2, colors='r', grid_color='r', grid_alpha=0.5)\n",
    "for _tidx, tick in enumerate(cbar_ax.xaxis.get_majorticklabels()):\n",
    "    if _tidx == 0:\n",
    "        tick.set_horizontalalignment(\"left\")\n",
    "    elif _tidx == 2:\n",
    "        tick.set_horizontalalignment(\"right\")\n",
    "    else:\n",
    "        tick.set_horizontalalignment(\"center\")\n",
    "\n",
    "fig.savefig(\"FigExt76E.pdf\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Older stuff that isn't publication ready ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples_m),\n",
    "    ncols=2*len(distances),\n",
    "    figsize=(4*len(distances),2*len(sub_samples_m)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2, vmax=2),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"none\",\n",
    ")\n",
    "\n",
    "for sample_m, sample_p, (i, axs) in zip(sub_samples_m, sub_samples_p, enumerate(axs)):\n",
    "    for jj, (_dist_name, _dist) in enumerate(distances.items()):\n",
    "        axm, axp = axs[jj], axs[len(distances) + jj]\n",
    "        if _dist_name != \"trans\":\n",
    "            Cm = np.nanmean(interaction_sums[sample_m][_dist], axis=0) / np.nanmean(interaction_counts[sample_m][_dist], axis=0)\n",
    "            Cp = np.nanmean(interaction_sums[sample_p][_dist], axis=0) / np.nanmean(interaction_counts[sample_p][_dist], axis=0)\n",
    "        elif _dist_name == \"trans\":\n",
    "            # pass\n",
    "            Cm = np.nanmean(interaction_sums_trans[sample_m][_dist], axis=0) / np.nanmean(interaction_counts_trans[sample_m][_dist], axis=0)\n",
    "            Cp = np.nanmean(interaction_sums_trans[sample_p][_dist], axis=0) / np.nanmean(interaction_counts_trans[sample_p][_dist], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        axm.imshow(Cm, **imshow_kwargs)\n",
    "        axp.imshow(Cp, **imshow_kwargs)\n",
    "        for _ax in [axp, axm]:\n",
    "            _ax.set_xticks([])\n",
    "            _ax.set_yticks([])\n",
    "        if i == 0:\n",
    "            axm.set_title(f\"m-{_dist_name}\")\n",
    "            axp.set_title(f\"p-{_dist_name}\")\n",
    "        if i == len(sub_samples_m)-1:\n",
    "            for _ax in [axm, axp]:\n",
    "                _ax.set_xticks(np.arange(len(ticklabels)))\n",
    "                _ax.set_xticklabels(np.asarray(ticklabels[::-1]), rotation=\"vertical\")\n",
    "        if jj == 0:\n",
    "            axm.set_ylabel(sample_m.lstrip(\"m\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples_m),\n",
    "    ncols=2*len(distances),\n",
    "    figsize=(4*len(distances),2*len(sub_samples_m)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.25, vmax=2.25),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"none\",\n",
    ")\n",
    "\n",
    "for sample_m, sample_p, (i, axs) in zip(sub_samples_m, sub_samples_p, enumerate(axs)):\n",
    "    for jj, (_dist_name, _dist) in enumerate(distances.items()):\n",
    "        axm, axp = axs[jj], axs[len(distances) + jj]\n",
    "        if _dist_name != \"trans\":\n",
    "            Cm = np.nanmean(interaction_sums[sample_m][_dist], axis=0) / np.nanmean(interaction_counts[sample_m][_dist], axis=0)\n",
    "            Cp = np.nanmean(interaction_sums[sample_p][_dist], axis=0) / np.nanmean(interaction_counts[sample_p][_dist], axis=0)\n",
    "        elif _dist_name == \"trans\":\n",
    "            # pass\n",
    "            Cm = np.nanmean(interaction_sums_trans[sample_m][_dist], axis=0) / np.nanmean(interaction_counts_trans[sample_m][_dist], axis=0)\n",
    "            Cp = np.nanmean(interaction_sums_trans[sample_p][_dist], axis=0) / np.nanmean(interaction_counts_trans[sample_p][_dist], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        axm.imshow(Cm, **imshow_kwargs)\n",
    "        axp.imshow(Cp, **imshow_kwargs)\n",
    "        for _ax in [axp, axm]:\n",
    "            _ax.set_xticks([])\n",
    "            _ax.set_yticks([])\n",
    "        if i == 0:\n",
    "            axm.set_title(f\"m-{_dist_name}\")\n",
    "            axp.set_title(f\"p-{_dist_name}\")\n",
    "        if i == len(sub_samples_m)-1:\n",
    "            for _ax in [axm, axp]:\n",
    "                _ax.set_xticks(np.arange(len(ticklabels)))\n",
    "                _ax.set_xticklabels(np.asarray(ticklabels[::-1]), rotation=\"vertical\")\n",
    "        if jj == 0:\n",
    "            axm.set_ylabel(sample_m.lstrip(\"m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # the mix one - mp\n",
    "sub_samples_m = [\n",
    "    \"N93m5\",\n",
    "    \"N93m10\",\n",
    "]\n",
    "# p ...\n",
    "sub_samples_p = [\n",
    "    \"N93p5\",\n",
    "    \"N93p10\",\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples_m),\n",
    "    ncols=2*len(distances),\n",
    "    figsize=(4*len(distances),2*len(sub_samples_m)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"none\",\n",
    ")\n",
    "\n",
    "for sample_m, sample_p, (i, axs) in zip(sub_samples_m, sub_samples_p, enumerate(axs)):\n",
    "    for jj, (_dist_name, _dist) in enumerate(distances.items()):\n",
    "        axm, axp = axs[jj], axs[len(distances) + jj]\n",
    "        if _dist_name != \"trans\":\n",
    "            Cm = np.nanmean(interaction_sums[sample_m][_dist], axis=0) / np.nanmean(interaction_counts[sample_m][_dist], axis=0)\n",
    "            Cp = np.nanmean(interaction_sums[sample_p][_dist], axis=0) / np.nanmean(interaction_counts[sample_p][_dist], axis=0)\n",
    "        elif _dist_name == \"trans\":\n",
    "            Cm = np.nanmean(interaction_sums_trans[sample_m][_dist], axis=0) / np.nanmean(interaction_counts_trans[sample_m][_dist], axis=0)\n",
    "            Cp = np.nanmean(interaction_sums_trans[sample_p][_dist], axis=0) / np.nanmean(interaction_counts_trans[sample_p][_dist], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        axm.imshow(Cm, **imshow_kwargs)\n",
    "        axp.imshow(Cp, **imshow_kwargs)\n",
    "        for _ax in [axp, axm]:\n",
    "            _ax.set_xticks([])\n",
    "            _ax.set_yticks([])\n",
    "        if i == 0:\n",
    "            axm.set_title(f\"m-{_dist_name}\")\n",
    "            axp.set_title(f\"p-{_dist_name}\")\n",
    "        if i == len(sub_samples_m)-1:\n",
    "            for _ax in [axm, axp]:\n",
    "                _ax.set_xticks(np.arange(len(ticklabels)))\n",
    "                _ax.set_xticklabels(np.asarray(ticklabels[::-1]), rotation=\"vertical\")\n",
    "        if jj == 0:\n",
    "            axm.set_ylabel(sample_m.lstrip(\"m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples_m =[\n",
    "        \"m10hR1R2\",\n",
    "        \"p10hR1R2\",\n",
    "        \"mp10hR1R2\",\n",
    "    ]\n",
    "sub_samples_p = [\n",
    "        \"N93m10\",\n",
    "        \"N93p10\",\n",
    "        \"N93mp10\",\n",
    "    ]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(sub_samples_m),\n",
    "    ncols=2*len(distances),\n",
    "    figsize=(4*len(distances),2*len(sub_samples_m)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "        norm=LogNorm(vmin=1/2.5, vmax=2.5),\n",
    "        cmap=\"RdBu_r\",\n",
    "        interpolation=\"none\",\n",
    ")\n",
    "\n",
    "for sample_m, sample_p, (i, axs) in zip(sub_samples_m, sub_samples_p, enumerate(axs)):\n",
    "    for jj, (_dist_name, _dist) in enumerate(distances.items()):\n",
    "        axm, axp = axs[jj], axs[len(distances) + jj]\n",
    "        if _dist_name != \"trans\":\n",
    "            Cm = np.nanmean(interaction_sums[sample_m][_dist], axis=0) / np.nanmean(interaction_counts[sample_m][_dist], axis=0)\n",
    "            Cp = np.nanmean(interaction_sums[sample_p][_dist], axis=0) / np.nanmean(interaction_counts[sample_p][_dist], axis=0)\n",
    "        elif _dist_name == \"trans\":\n",
    "            Cm = np.nanmean(interaction_sums_trans[sample_m][_dist], axis=0) / np.nanmean(interaction_counts_trans[sample_m][_dist], axis=0)\n",
    "            Cp = np.nanmean(interaction_sums_trans[sample_p][_dist], axis=0) / np.nanmean(interaction_counts_trans[sample_p][_dist], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        axm.imshow(Cm, **imshow_kwargs)\n",
    "        axp.imshow(Cp, **imshow_kwargs)\n",
    "        for _ax in [axp, axm]:\n",
    "            _ax.set_xticks([])\n",
    "            _ax.set_yticks([])\n",
    "        if i == 0:\n",
    "            axm.set_title(f\"m-{_dist_name}\")\n",
    "            axp.set_title(f\"p-{_dist_name}\")\n",
    "        if i == len(sub_samples_m)-1:\n",
    "            for _ax in [axm, axp]:\n",
    "                _ax.set_xticks(np.arange(len(ticklabels)))\n",
    "                _ax.set_xticklabels(np.asarray(ticklabels[::-1]), rotation=\"vertical\")\n",
    "        if jj == 0:\n",
    "            axm.set_ylabel(sample_m)\n",
    "\n",
    "\n",
    "\n",
    "# try adding an axes manually ...\n",
    "cax = fig.add_axes([0.88,0.001,0.1,0.02])\n",
    "fig.colorbar(\n",
    "    cm.ScalarMappable(norm=imshow_kwargs[\"norm\"], cmap=imshow_kwargs[\"cmap\"]),\n",
    "    cax=cax,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "cax.set_xticks([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cax.set_xticklabels([imshow_kwargs[\"norm\"].vmin, 1, imshow_kwargs[\"norm\"].vmax])\n",
    "cax.minorticks_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
