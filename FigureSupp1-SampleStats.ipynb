{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620019d-f056-49c9-9320-f47b80775248",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install textalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7f794-7864-4022-8299-cf41af0300ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install adjustText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc3a7c-df0d-4509-ae7a-ccaa4d21f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! scp -r newhpc:/home/sergeyv.venev-umw/projects/map_ranger_v034/mqc ./mqc_stats_v034\n",
    "# ! ls -la ./mqc_stats_v034/multiqc_data\n",
    "# ! head -100 ./mqc_stats_v034/multiqc_data/multiqc_general_stats.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ffe720-602d-485e-9bad-5f7c0f6e71e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44001e5e-8d58-4692-b9d6-fd43a4036518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ssh newhpc ls /home/sergeyv.venev-umw/projects/map_ranger_v034\n",
    "# ! scp newhpc:/home/sergeyv.venev-umw/projects/map_ranger_v034/ranger.yml ./\n",
    "# ! scp newhpc:/home/sergeyv.venev-umw/projects/map_ranger_v034/ranger_fastq.csv ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5f0196-d068-4e69-a985-3e9ba46ad6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('ranger.yml', 'r') as file:\n",
    "    _ranger = yaml.safe_load(file)\n",
    "\n",
    "# print(prime_service['prime_numbers'][0])\n",
    "# print(prime_service['rest']['url'])\n",
    "\n",
    "sample_catalog = []\n",
    "for sample, lanes_dict in _ranger[\"input\"][\"raw_reads_paths\"].items():\n",
    "    for fastq_PE in lanes_dict.values():\n",
    "        sample_catalog.append((sample, fastq_PE[0]))\n",
    "\n",
    "sample_df = pd.DataFrame(sample_dict, columns=[\"sample\", \"fastq\"])\n",
    "\n",
    "rlen_df = pd.read_csv(\"ranger_fastq.csv\", names=[\"rlen\", \"fastq\"])[[\"fastq\",\"rlen\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec432b-459b-4350-aece-75f6957c661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprehensive panel of rlengths per sample ...\n",
    "sample_df.merge(\n",
    "    rlen_df,\n",
    "    on=\"fastq\"\n",
    ").groupby(\"sample\")[\"rlen\"].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f30580-0682-4fa1-837c-b48f63608883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48315e-72d6-4342-a8d8-8f762f698796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef06618-ee93-4b5d-b83e-a2f72bfdb829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91a44c-deef-4a3f-9916-af4602c86139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90bdae3-7b7b-4f2a-84c6-af722944f007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f648f-c2ff-4d02-b63c-aae8058cd5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58826716-62ab-44b2-adfc-7fcd540fb252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34573d-3475-4eb5-988f-f93686298546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # download test data\n",
    "# # this file is 145 Mb, and may take a few seconds to download\n",
    "# import cooltools\n",
    "# from cooltools import insulation\n",
    "\n",
    "import bioframe\n",
    "from matplotlib.colors import LogNorm\n",
    "# from helper_func import saddleplot\n",
    "from data_catalog import bws, bws_vlim, telo_dict, telo_reps_dict\n",
    "# from helper_func import get_stack, show_stacks\n",
    "\n",
    "import cooler\n",
    "import cooltools.lib.plotting\n",
    "\n",
    "from sklearn import decomposition\n",
    "# unused but required import for doing 3d projections with matplotlib < 3.2\n",
    "import mpl_toolkits.mplot3d  # noqa: F401\n",
    "\n",
    "import textalloc as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815310a9-434f-4cf9-aafe-19d71e713b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define genomic view that will be used to call dots and pre-compute expected\n",
    "# ...\n",
    "# Use bioframe to fetch the genomic features from the UCSC.\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "hg38_arms_full = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "# # remove \"bad\" chromosomes and near-empty arms ...\n",
    "# excluded_arms = [\"chr13_p\", \"chr14_p\", \"chr15_p\", \"chr21_p\", \"chr22_p\", \"chrM_p\", \"chrY_p\", \"chrY_q\", \"chrX_p\", \"chrX_q\"]\n",
    "# hg38_arms = hg38_arms_full[~hg38_arms_full[\"name\"].isin(excluded_arms)].reset_index(drop=True)\n",
    "# ...\n",
    "# # can do 1 chromosome (or arm) as well ..\n",
    "# included_arms = [\"chr1_q\", \"chr2_p\", \"chr4_q\", \"chr6_q\"]\n",
    "included_arms = hg38_arms_full[\"name\"].to_list()[:44] # all autosomal ones ...\n",
    "hg38_arms = hg38_arms_full[hg38_arms_full[\"name\"].isin(included_arms)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5d03a-555e-4e82-83b0-3dd8b85f0227",
   "metadata": {},
   "source": [
    "# Load multiQC stats for visualizing ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742193b-3168-4c58-8fba-a8b36d04813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./mqc_stats_v034/multiqc_data/multiqc_general_stats.txt\",sep=\"\\t\")\n",
    "df[\"Sample\"] = df[\"Sample\"].str.removesuffix(\".hg38\")\n",
    "df = df.set_index(\"Sample\")\n",
    "df.columns = df.columns.str.replace(\"pairtools_mqc-generalstats-pairtools-\", \"\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59535986-e94b-4283-a433-b2c3fb87532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timecourse samples - control\n",
    "_m_samples_pooled = [\n",
    "    \"ranGAP1-0-Ms-R1R2\",\n",
    "    \"ranGAP1-0-Telo-R2\",\n",
    "    \"ranGAP1-0-Cyto-R1\",\n",
    "    \"ranGAP1-0-G1s-R1R2\",\n",
    "]\n",
    "# timecourse samples rangap depletion\n",
    "_p_samples_pooled = [\n",
    "    \"ranGAP1-2-Ms-R1R2\",\n",
    "    \"ranGAP1-4-Cyto-R1\",\n",
    "    \"ranGAP1-4-Telo-R2\",\n",
    "    \"ranGAP1-7-G1s-R1R2\",\n",
    "]\n",
    "\n",
    "# Nup 93 samples - control\n",
    "_n93_m_samples_pooled = [\n",
    "    \"N93-0-G1s-R1R2\",\n",
    "]\n",
    "# Nup 93 samples - depletion\n",
    "_n93_p_samples_pooled = [\n",
    "    \"N93-7-G1s-R1R2\",\n",
    "]\n",
    "\n",
    "# additional samples mp experiment\n",
    "_mp_samples_pooled = [\n",
    "    \"ranGAP1-0-10hR-R1R3\",\n",
    "    \"ranGAP1-12-10hR-R1R3\",\n",
    "    \"ranGAP1-7-10hR-R1R3\",\n",
    "]\n",
    "\n",
    "_pooled_idx = (\n",
    "    _m_samples_pooled+\n",
    "    _p_samples_pooled+\n",
    "    _n93_m_samples_pooled+\n",
    "    _n93_p_samples_pooled+\n",
    "    _mp_samples_pooled\n",
    ")\n",
    "df.loc[_pooled_idx].to_csv(\"pooled-hic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10baf91-acf9-4509-b703-f3dc34039f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "! readlink -f pooled-hic.csv\n",
    "! readlink -f separate-hic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada62d3-fa33-4204-8985-9444900a3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_idx = (\n",
    "    _m_samples+\n",
    "    _p_samples+\n",
    "    _n93_m_samples+\n",
    "    _n93_p_samples+\n",
    "    _mp_samples\n",
    ")\n",
    "df.loc[_idx].to_csv(\"separate-hic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b2a9e-332c-4165-ba72-c4c6aeec9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in df[\"Sample\"]:\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5aa69a-cf2a-42de-aba2-17be37bc2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timecourse samples - control\n",
    "_m_samples = [\n",
    "    \"ranGAP1-0-Ms-R1\",\n",
    "    \"ranGAP1-0-Ms-R2\",\n",
    "    \"ranGAP1-0-Telo-R2\",\n",
    "    \"ranGAP1-0-Cyto-R1\",\n",
    "    \"ranGAP1-0-G1s-R1\",\n",
    "    \"ranGAP1-0-G1s-R2\",\n",
    "]\n",
    "# timecourse samples rangap depletion\n",
    "_p_samples = [\n",
    "    \"ranGAP1-2-Ms-R1\",\n",
    "    \"ranGAP1-2-Ms-R2\",\n",
    "    \"ranGAP1-4-Cyto-R1\",\n",
    "    \"ranGAP1-4-Telo-R2\",\n",
    "    \"ranGAP1-7-G1s-R1\",\n",
    "    \"ranGAP1-7-G1s-R2\",\n",
    "]\n",
    "\n",
    "# Nup 93 samples - control\n",
    "_n93_m_samples = [\n",
    "    \"N93-0-G1s-R1\",\n",
    "    \"N93-0-G1s-R2\",\n",
    "]\n",
    "# Nup 93 samples - depletion\n",
    "_n93_p_samples = [\n",
    "    \"N93-7-G1s-R1\",\n",
    "    \"N93-7-G1s-R2\",\n",
    "]\n",
    "\n",
    "\n",
    "# additional samples mp experiment\n",
    "_mp_samples = [\n",
    "    \"ranGAP1-0-10hR-R1\",\n",
    "    \"ranGAP1-0-10hR-R3\",\n",
    "    \"ranGAP1-12-10hR-R1\",\n",
    "    \"ranGAP1-12-10hR-R3\",\n",
    "    \"ranGAP1-7-10hR-R1\",\n",
    "    \"ranGAP1-7-10hR-R3\",\n",
    "]\n",
    "\n",
    "# Nup 10 hrs thing is excluded ...\n",
    "# ...\n",
    "# # Nup 93 samples - mp experiment - are we going to use these at all ?\n",
    "# _n93_mp_samples = [\n",
    "#     \"N93-0-10hR-G1s-R3\",\n",
    "#     \"N93-0-10hR-G1s-R4\",\n",
    "#     \"N93-12-10hR-G1s-R3\",\n",
    "#     \"N93-12-10hR-G1s-R4\",\n",
    "#     \"N93-7-10hR-G1s-R3\",\n",
    "#     \"N93-7-10hR-G1s-R4\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# entire 10 hours and mp thing for Nup93 are excluded ...\n",
    "excluded_samples = [\n",
    "    'N93p10_R1',\n",
    "    'N93p10_R2',\n",
    "    'N93mp10_R1',\n",
    "    'N93mp10_R2',\n",
    "    'N93m10_R1',\n",
    "    'N93m10_R2',\n",
    "    'N93m10',\n",
    "    'N93p10',\n",
    "    'N93mp10',\n",
    "]\n",
    "\n",
    "\n",
    "# map to sapmples used in the paper ...\n",
    "smap = {\n",
    "    \"ranGAP1-0-Ms-R1\" : \"cMito\",\n",
    "    \"ranGAP1-0-Ms-R2\" : \"cMito\",\n",
    "    \"ranGAP1-0-Telo-R2\" : \"cTelo\",\n",
    "    \"ranGAP1-0-Cyto-R1\" : \"cCyto\",\n",
    "    \"ranGAP1-0-G1s-R1\" : \"c5h\",\n",
    "    \"ranGAP1-0-G1s-R2\" : \"c5h\",\n",
    "    \"ranGAP1-2-Ms-R1\" : \"$\\\\Delta$Mito\",\n",
    "    \"ranGAP1-2-Ms-R2\" : \"$\\\\Delta$Mito\",\n",
    "    \"ranGAP1-4-Cyto-R1\" : \"$\\\\Delta$Cyto\",\n",
    "    \"ranGAP1-4-Telo-R2\" : \"$\\\\Delta$Telo\",\n",
    "    \"ranGAP1-7-G1s-R1\" : \"$\\\\Delta$5h\",\n",
    "    \"ranGAP1-7-G1s-R2\" : \"$\\\\Delta$5h\",\n",
    "    \"N93-0-G1s-R1\" : \"c5h_Nup93\",\n",
    "    \"N93-0-G1s-R2\" : \"c5h_Nup93\",\n",
    "    \"N93-7-G1s-R1\" : \"$\\\\Delta$5h_Nup93\",\n",
    "    \"N93-7-G1s-R2\" : \"$\\\\Delta$5h_Nup93\",\n",
    "    \"ranGAP1-0-10hR-R1\" : \"c10h\",\n",
    "    \"ranGAP1-0-10hR-R3\" : \"c10h\",\n",
    "    \"ranGAP1-12-10hR-R1\" : \"c5h+$\\\\Delta$10h\",\n",
    "    \"ranGAP1-12-10hR-R3\" : \"c5h+$\\\\Delta$10h\",\n",
    "    \"ranGAP1-7-10hR-R1\" : \"$\\\\Delta$10h\",\n",
    "    \"ranGAP1-7-10hR-R3\" : \"$\\\\Delta$10h\",\n",
    "}\n",
    "\n",
    "\n",
    "# map to sapmples used in the paper ...\n",
    "smap2 = {\n",
    "    \"mMito\": \"cMito\",\n",
    "    \"mTelo\": \"cTelo\",\n",
    "    \"mCyto\": \"cCyto\",\n",
    "    \"m5hR1R2\": \"c5h\",\n",
    "    \"pMito\": \"$\\\\Delta$Mito\",\n",
    "    \"pTelo\": \"$\\\\Delta$Telo\",\n",
    "    \"pCyto\": \"$\\\\Delta$Cyto\",\n",
    "    \"p5hR1R2\": \"$\\\\Delta$5h\",\n",
    "    \"m10hR1R2\": \"c10h\",\n",
    "    \"p10hR1R2\": \"$\\\\Delta$10h\",\n",
    "    \"mp10hR1R2\": \"c5h+$\\\\Delta$10h\",\n",
    "    \"N93m5\": \"c5h_Nup93\",\n",
    "    \"N93p5\": \"$\\\\Delta$5h_Nup93\",\n",
    "}\n",
    "\n",
    "\n",
    "smap2_reps = {\n",
    "    'mMito_R1': 'cMito-R1',\n",
    "    'mMito_R2': 'cMito-R2',\n",
    "    'mTelo': 'cTelo-R1',\n",
    "    'mCyto': 'cCyto-R1',\n",
    "    'm5h_R1': 'c5h-R1',\n",
    "    'm5h_R2': 'c5h-R2',\n",
    "    'm10h_R1': 'c10h-R1',\n",
    "    'm10h_R2': 'c10h-R2',\n",
    "    'pMito_R1': '$\\\\Delta$Mito-R1',\n",
    "    'pMito_R2': '$\\\\Delta$Mito-R2',\n",
    "    'pTelo': '$\\\\Delta$T-R1',\n",
    "    'pCyto': '$\\\\Delta$C-R1',\n",
    "    'p5h_R1': '$\\\\Delta$5h-R1',\n",
    "    'p5h_R2': '$\\\\Delta$5h-R2',\n",
    "    'p10h_R1': '$\\\\Delta$10h-R1',\n",
    "    'p10h_R2': '$\\\\Delta$10h-R2',\n",
    "    'mp10h_R1': 'c5h+$\\\\Delta$10h-R1',\n",
    "    'mp10h_R2': 'c5h+$\\\\Delta$10h-R2',\n",
    "    'N93m5_R1': 'c5h_Nup93-R1',\n",
    "    'N93m5_R2': 'c5h_Nup93-R2',\n",
    "    'N93p5_R1': '$\\\\Delta$5h_Nup93-R1',\n",
    "    'N93p5_R2': '$\\\\Delta$5h_Nup93-R2',\n",
    "}\n",
    "\n",
    "# combine smap ...\n",
    "smap_combo = {\n",
    "    \"mMito\": \"cMito\",\n",
    "    \"mTelo\": \"cTelo\",\n",
    "    \"mCyto\": \"cCyto\",\n",
    "    \"m5hR1R2\": \"c5h\",\n",
    "    \"pMito\": \"$\\\\Delta$Mito\",\n",
    "    \"pTelo\": \"$\\\\Delta$Telo\",\n",
    "    \"pCyto\": \"$\\\\Delta$Cyto\",\n",
    "    \"p5hR1R2\": \"$\\\\Delta$5h\",\n",
    "    \"m10hR1R2\": \"c10h\",\n",
    "    \"p10hR1R2\": \"$\\\\Delta$10h\",\n",
    "    \"mp10hR1R2\": \"c5h+$\\\\Delta$10h\",\n",
    "    \"N93m5\": \"c5h_Nup93\",\n",
    "    \"N93p5\": \"$\\\\Delta$5h_Nup93\",\n",
    "    'mMito_R1': 'cMito-R1',\n",
    "    'mMito_R2': 'cMito-R2',\n",
    "    'm5h_R1': 'c5h-R1',\n",
    "    'm5h_R2': 'c5h-R2',\n",
    "    'm10h_R1': 'c10h-R1',\n",
    "    'm10h_R2': 'c10h-R2',\n",
    "    'pMito_R1': '$\\\\Delta$Mito-R1',\n",
    "    'pMito_R2': '$\\\\Delta$Mito-R2',\n",
    "    'p5h_R1': '$\\\\Delta$5h-R1',\n",
    "    'p5h_R2': '$\\\\Delta$5h-R2',\n",
    "    'p10h_R1': '$\\\\Delta$10h-R1',\n",
    "    'p10h_R2': '$\\\\Delta$10h-R2',\n",
    "    'mp10h_R1': 'c5h+$\\\\Delta$10h-R1',\n",
    "    'mp10h_R2': 'c5h+$\\\\Delta$10h-R2',\n",
    "    'N93m5_R1': 'c5h_Nup93-R1',\n",
    "    'N93m5_R2': 'c5h_Nup93-R2',\n",
    "    'N93p5_R1': '$\\\\Delta$5h_Nup93-R1',\n",
    "    'N93p5_R2': '$\\\\Delta$5h_Nup93-R2',\n",
    "}\n",
    "\n",
    "\n",
    "repeated_samples = [\"mTelo\", \"mCyto\", \"pTelo\", \"pCyto\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38431865-918a-4940-9a2d-158e2e33a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_height = 0.8\n",
    "\n",
    "# the groups we're actually going to show\n",
    "_sample_groups = [\n",
    "    _m_samples,\n",
    "    _p_samples,\n",
    "    _n93_m_samples,\n",
    "    _n93_p_samples,\n",
    "    _mp_samples,\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(_sample_groups),\n",
    "    ncols=4,\n",
    "    sharex=\"col\",\n",
    "    sharey=\"row\",\n",
    "    height_ratios=[ len(g)+2*_height for g in _sample_groups ],\n",
    "    figsize=(8,7)\n",
    ")\n",
    "\n",
    "barh_kwargs = dict(\n",
    "    align=\"center\",\n",
    "    height=_height,\n",
    ")\n",
    "\n",
    "# total reads go first\n",
    "for i, _samples in enumerate(_sample_groups):\n",
    "    ax = axs[i,0]\n",
    "    ax.barh(\n",
    "        np.arange(len(_samples)),\n",
    "        df.loc[_samples, \"total\"]/1_000_000_000,\n",
    "        **barh_kwargs,\n",
    "    )\n",
    "    ax.set_yticks(np.arange(len(_samples)), labels=_samples)\n",
    "    ax.set_ylim(0-_height,len(_samples)-1+_height)\n",
    "\n",
    "ax.set_xticks([0,1,2,3])\n",
    "ax.set_xlabel(\"sequenced\\nPE reads, billions\", fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "# percetn usable reads\n",
    "for i, _samples in enumerate(_sample_groups):\n",
    "    ax = axs[i,1]\n",
    "    ax.barh(\n",
    "        np.arange(len(_samples)),\n",
    "        100.*(df.loc[_samples, \"total_nodups\"]/df.loc[_samples, \"total\"]),\n",
    "        **barh_kwargs,\n",
    "    )\n",
    "    ax.set_yticks(np.arange(len(_samples)), labels=_samples)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_ylim(0-_height,len(_samples)-1+_height)\n",
    "ax.set_xlabel(\"unique interactions\\naka usable pairs, %\", fontsize=10)\n",
    "\n",
    "\n",
    "# cis trans ...\n",
    "for i, _samples in enumerate(_sample_groups):\n",
    "    ax = axs[i,2]\n",
    "    ax.barh(\n",
    "        np.arange(len(_samples)),\n",
    "        df.loc[_samples, \"frac_cis\"],\n",
    "        left=[0]*len(_samples),\n",
    "        color=\"tab:blue\",\n",
    "        **barh_kwargs,\n",
    "    )\n",
    "    ax.barh(\n",
    "        np.arange(len(_samples)),\n",
    "        100. - df.loc[_samples, \"frac_cis\"],\n",
    "        left=df.loc[_samples, \"frac_cis\"],\n",
    "        color=\"tab:brown\",\n",
    "        **barh_kwargs,\n",
    "    )\n",
    "    ax.set_ylim(0-_height,len(_samples)-1+_height)\n",
    "    ax.invert_yaxis()\n",
    "ax.set_xlabel(\"cis + trans, %\", fontsize=10);\n",
    "\n",
    "\n",
    "\n",
    "# total reads go first\n",
    "for i, _samples in enumerate(_sample_groups):\n",
    "    ax = axs[i,3]\n",
    "    for t,s in enumerate(_samples):\n",
    "        ax.text(0.033,t+0.25,smap[s])\n",
    "    # ax.set_yticks(np.arange(len(_samples)), labels=_samples)\n",
    "    ax.set_ylim(0-_height,len(_samples)-1+_height)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "ax.set_xlabel(\"pooled\\nsample names\", fontsize=10,labelpad=20)\n",
    "\n",
    "fig.savefig(\"SuppFig1_samples.svg\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77fe8a-2f45-497b-968b-327ddbb762d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0]*len(_samples)\n",
    "\n",
    "# ! ls ins*\n",
    "# ! ls ev*\n",
    "\n",
    "# ev_bedraph\n",
    "# ev_r1r2_bedraph\n",
    "# ins_bedgraph\n",
    "# ins_r1r2_bedgraph\n",
    "\n",
    "# telo_dict,\n",
    "# telo_reps_dict\n",
    "# telo_reps_cis_eigs_gene[binsize][sample_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf43452-a798-4680-a539-469e6fd86ed3",
   "metadata": {},
   "source": [
    "## Pre-load pre-calculated EV1s and coolers - for whatever resolution ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22711f-3b25-4670-908b-fb04c2f75ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize25 = 25_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062cf17-9eaf-4b4a-b1b6-cdf71e4681e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "telo_cis_evs = {}\n",
    "for k, _fname in telo_dict.items():\n",
    "    # derive output name\n",
    "    _fname = f\"ev_bedraph/{k}.{binsize25//1_000}kb.bed\"\n",
    "    print(f\"reading {_fname} ...\")\n",
    "    telo_cis_evs[k] = bioframe.read_table(_fname, schema=\"bedGraph\", header=0)\n",
    "# #\n",
    "# # cooler files that we'll work on :\n",
    "# telo_clrs = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize25}\") for _k, _path in telo_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535f4bd-317c-4c26-8601-79a11e0796f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "telo_reps_cis_evs = {}\n",
    "for k, _fname in telo_reps_dict.items():\n",
    "    # derive output name\n",
    "    _fname = f\"ev_r1r2_bedraph/{k}.{binsize25//1_000}kb.bed\"\n",
    "    print(f\"reading {_fname} ...\")\n",
    "    telo_reps_cis_evs[k] = bioframe.read_table(_fname, schema=\"bedGraph\", header=0)\n",
    "# #\n",
    "# # cooler files that we'll work on :\n",
    "# telo_clrs = { _k: cooler.Cooler(f\"{_path}::/resolutions/{binsize25}\") for _k, _path in telo_dict.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43188ce5-dce9-432f-a72f-ec88ae77674e",
   "metadata": {},
   "source": [
    "# Read Insulation tracks - only relevant 4 columns - aka bedGraph ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf64053-cb34-478b-b54a-852a0cf195ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize10 = 10_000\n",
    "diamond_size = 10*binsize10\n",
    "ins_value_col = f\"log2_insulation_score_{diamond_size}\"\n",
    "cols = [\"chrom\", \"start\", \"end\", value_colname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd078918-0381-4c0d-b470-c1ce6337ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "telo_ins = {}\n",
    "for k, _fname in telo_dict.items():\n",
    "    # derive output name\n",
    "    in_fname = f\"ins_bedgraph/{k}.{binsize10//1_000}kb.bed\"\n",
    "    telo_ins[k] = pd.read_csv(in_fname, sep=\"\\t\")[cols]\n",
    "    print(f\"read {in_fname} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b6b651-9dbc-4c06-a01d-c9220d429ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "telo_reps_ins = {}\n",
    "for k, _fname in telo_reps_dict.items():\n",
    "    # derive output name\n",
    "    in_fname = f\"ins_r1r2_bedgraph/{k}.{binsize10//1_000}kb.bed\"\n",
    "    telo_reps_ins[k] = pd.read_csv(in_fname, sep=\"\\t\")[cols]\n",
    "    print(f\"read {in_fname} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eac67d-86e4-4a00-a84f-25a78c688c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa58ff04-c3d8-4479-a108-3f4d5836574a",
   "metadata": {},
   "source": [
    "# Cluster/PCA our samples to show which ones are more similar (insulations first)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2373b76-fb5f-4bed-aaeb-d7eadcf2820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pca_samples = [\n",
    "    \"m5h_R1\",\n",
    "    \"m5h_R2\",\n",
    "    \"p5h_R1\",\n",
    "    \"p5h_R2\",\n",
    "    \"N93m5_R1\",\n",
    "    \"N93m5_R2\",\n",
    "    \"N93p5_R1\",\n",
    "    \"N93p5_R2\",\n",
    "]\n",
    "_rest_samples = [_sample for _sample in _all_samples if (_sample not in _pca_samples)and(_sample not in excluded_samples)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21bf02c-efb9-4825-814a-728105566c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_value_col = \"value\"\n",
    "_common_evs_df = pd.concat(\n",
    "    [ _df[_value_col].rename(_sample) for _sample, _df in telo_reps_cis_evs.items() ],\n",
    "    axis=1,\n",
    ")\n",
    "# ...\n",
    "# combine pooled and separated ...\n",
    "_good_bins_common = ~_common_evs_df.isna().any(axis=1).to_numpy()\n",
    "# #\n",
    "# # ...\n",
    "# #\n",
    "_all_samples = [_sample for _sample in telo_reps_cis_evs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4621f0-6c1a-45fd-911e-b02eb0080e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = _common_evs_df[_pca_samples].to_numpy()[_good_bins_common].T\n",
    "X_rest = _common_evs_df[_rest_samples].to_numpy()[_good_bins_common].T\n",
    "\n",
    "# do PCA on X ...\n",
    "pcaX = decomposition.PCA(n_components=3)\n",
    "print(f\"running PCA on {_pca_samples=} ...\")\n",
    "pcaX.fit(X)\n",
    "\n",
    "# project X and X_rest onto PCs ...\n",
    "X_trans = pcaX.transform(X)\n",
    "X_rest_trans = pcaX.transform(X_rest)\n",
    "\n",
    "print(pcaX.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a4c52-c61a-4996-8f71-ee81856d4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "_x, _y, _ = X_trans.T\n",
    "_x_rest, _y_rest, _ = X_rest_trans.T\n",
    "\n",
    "text_list = []\n",
    "for txt in _pca_samples:\n",
    "    text_list.append(smap_combo[txt])\n",
    "for txt in _rest_samples:\n",
    "    text_list.append(smap_combo[txt])\n",
    "\n",
    "ax.scatter(_x, _y, s=100, color=\"tab:red\", alpha=0.9, edgecolors=\"dimgray\")\n",
    "ax.scatter(_x_rest, _y_rest, s=100, color=\"tab:blue\", alpha=0.9, edgecolors=\"dimgray\")\n",
    "\n",
    "# texts = [ax.text(_x[i], _y[i], smap_combo[txt], ha='center', va='center') for i, txt in enumerate(_pca_samples)]\n",
    "# texts += [ax.text(_x_rest[i], _y_rest[i], smap_combo[txt], ha='center', va='center') for i, txt in enumerate(_rest_samples)]\n",
    "texts = [ax.text(_x[i], _y[i], txt, ha='center', va='center') for i, txt in enumerate(_pca_samples)]\n",
    "texts += [ax.text(_x_rest[i], _y_rest[i], txt, ha='center', va='center') for i, txt in enumerate(_rest_samples)]\n",
    "\n",
    "# adjust_text(texts);\n",
    "adjust_text(\n",
    "    texts,\n",
    "    expand=(1.5, 2.5), # expand text bounding boxes by 1.2 fold in x direction and 2 fold in y direction\n",
    "    arrowprops=dict(arrowstyle='->', color='gray') # ensure the labeling is clear by adding arrows\n",
    ");\n",
    "\n",
    "# ...\n",
    "# plt.scatter(_x, _y, s=50, color=\"blue\")\n",
    "# for i, txt in enumerate(_rest_samples):\n",
    "#     ax.annotate(smap_combo[txt], (_x[i], _y[i]), fontsize=9)\n",
    "\n",
    "_1, _2, _3 = pca.explained_variance_ratio_[:3]\n",
    "ax.set_xlabel(f\"PC1: {_1:.2f}\", fontsize=13)\n",
    "ax.set_ylabel(f\"PC2: {_2:.2f}\", fontsize=13)\n",
    "\n",
    "\n",
    "fig.savefig(\"SuppFig1_evclust.svg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985ccc4-bef9-434f-ba1f-844481aa4fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f3bdb-ebd8-4bca-8bc1-b5df1dd204e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd3fd2-c775-4e61-839b-634a9903fa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760eca63-bb94-4ea0-8f01-eca7d626ef5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd7edd-e12f-4708-b6dd-8501161c362f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43b76b39-436f-4902-8b73-c078d3fa16ab",
   "metadata": {},
   "source": [
    "# Cluster/PCA our samples to show which ones are more similar (Insulation second)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97662f-41c1-4ae9-ac44-1529a4d0b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_value_col = ins_value_col\n",
    "_common_ins_df = pd.concat(\n",
    "    [ _df[_value_col].rename(_sample) for _sample, _df in telo_reps_ins.items() ],\n",
    "    axis=1,\n",
    ")\n",
    "# ...\n",
    "# combine pooled and separated ...\n",
    "_good_bins_common = ~_common_ins_df.isna().any(axis=1).to_numpy()\n",
    "# #\n",
    "# # ...\n",
    "# #\n",
    "_all_samples = [_sample for _sample in telo_reps_ins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b8a50-2987-4485-b3a1-5b3858bfbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = _common_ins_df[_pca_samples].to_numpy()[_good_bins_common].T\n",
    "X_rest = _common_ins_df[_rest_samples].to_numpy()[_good_bins_common].T\n",
    "\n",
    "# do PCA on X ...\n",
    "pcaX = decomposition.PCA(n_components=3)\n",
    "print(f\"running PCA on {_pca_samples=} ...\")\n",
    "pcaX.fit(X)\n",
    "\n",
    "# project X and X_rest onto PCs ...\n",
    "X_trans = pcaX.transform(X)\n",
    "X_rest_trans = pcaX.transform(X_rest)\n",
    "\n",
    "print(pcaX.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5888f61-b51c-4c3a-bd54-78fb1b773362",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "_x, _y, _ = X_trans.T\n",
    "_x_rest, _y_rest, _ = X_rest_trans.T\n",
    "\n",
    "text_list = []\n",
    "for txt in _pca_samples:\n",
    "    text_list.append(smap_combo[txt])\n",
    "for txt in _rest_samples:\n",
    "    text_list.append(smap_combo[txt])\n",
    "\n",
    "ax.scatter(_x, _y, s=100, color=\"tab:red\", alpha=0.9, edgecolors=\"dimgray\")\n",
    "ax.scatter(_x_rest, _y_rest, s=100, color=\"tab:blue\", alpha=0.9, edgecolors=\"dimgray\")\n",
    "\n",
    "# texts = [ax.text(_x[i], _y[i], smap_combo[txt], ha='center', va='center') for i, txt in enumerate(_pca_samples)]\n",
    "# texts += [ax.text(_x_rest[i], _y_rest[i], smap_combo[txt], ha='center', va='center') for i, txt in enumerate(_rest_samples)]\n",
    "texts = [ax.text(_x[i], _y[i], txt, ha='center', va='center') for i, txt in enumerate(_pca_samples)]\n",
    "texts += [ax.text(_x_rest[i], _y_rest[i], txt, ha='center', va='center') for i, txt in enumerate(_rest_samples)]\n",
    "\n",
    "# adjust_text(texts);\n",
    "adjust_text(\n",
    "    texts,\n",
    "    expand=(1.5, 2.5), # expand text bounding boxes by 1.2 fold in x direction and 2 fold in y direction\n",
    "    arrowprops=dict(arrowstyle='->', color='gray') # ensure the labeling is clear by adding arrows\n",
    ");\n",
    "\n",
    "# ...\n",
    "# plt.scatter(_x, _y, s=50, color=\"blue\")\n",
    "# for i, txt in enumerate(_rest_samples):\n",
    "#     ax.annotate(smap_combo[txt], (_x[i], _y[i]), fontsize=9)\n",
    "\n",
    "_1, _2, _3 = pca.explained_variance_ratio_[:3]\n",
    "ax.set_xlabel(f\"PC1: {_1:.2f}\", fontsize=13)\n",
    "ax.set_ylabel(f\"PC2: {_2:.2f}\", fontsize=13)\n",
    "\n",
    "fig.savefig(\"SuppFig1_insclust.svg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e7c62-a1fa-49cc-8bbf-ac168f79c896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ec1f9-45d8-45f9-a589-a504da794649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a95f1-2c95-4f5a-8d36-63ed3af0d587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffdb3b4-3b16-4da5-931a-cdfb4e32abb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76597f40-3d0e-4d71-9afb-76ac73ee2c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76220e95-bd8b-46ea-b3f7-c5fa5d1a07c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32692a0-118a-4ab4-a59d-a19e8df89399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4ee40-f4ad-4f88-8bde-74f9af07a53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c3ede-4b72-456b-af9c-323fe46a816e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b9555-7f46-4549-a5f5-16d56dc34359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c7675-080f-431c-b231-b2a1204cabba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948cbde-50f0-4d33-8431-8848f1043f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2541b5a6-b31b-4b33-965a-9c09066e849f",
   "metadata": {},
   "source": [
    "# OLD STUFF - don't worry about it ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cab27-b607-4d57-b745-7681b437c46e",
   "metadata": {},
   "source": [
    "# Cluster/PCA our samples to show which ones are more similar (EVs first)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6914bbe-09cb-4351-8c6e-eba34285b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_value_col = \"value\"\n",
    "_common_evs_df = pd.concat(\n",
    "    (\n",
    "        [_df[_value_col].rename(_sample) for _sample, _df in telo_cis_evs.items()] +\n",
    "        [_df[_value_col].rename(_sample) for _sample, _df in telo_reps_cis_evs.items() if _sample not in repeated_samples]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "# ...\n",
    "# combine pooled and separated ...\n",
    "_good_bins_common = ~_common_evs_df.isna().any(axis=1).to_numpy()\n",
    "#\n",
    "# ...\n",
    "#\n",
    "_all_samples = (\n",
    "    [_sample for _sample in telo_cis_evs] +\n",
    "    [_sample for _sample in telo_reps_cis_evs if _sample not in repeated_samples]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d1f6f-10e1-4291-9aaf-ea014dd7892c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c16d2b16-74e6-41ff-b3e5-75b12d8bfed2",
   "metadata": {},
   "source": [
    "# Cluster/PCA our samples to show which ones are more similar (EVs first)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c17a37-7a49-4eb4-a733-2434552c200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_value_col = \"value\"\n",
    "_common_evs_df = pd.concat(\n",
    "    (\n",
    "        [_df[_value_col].rename(_sample) for _sample, _df in telo_cis_evs.items()] +\n",
    "        [_df[_value_col].rename(_sample) for _sample, _df in telo_reps_cis_evs.items() if _sample not in repeated_samples]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "# ...\n",
    "# combine pooled and separated ...\n",
    "_good_bins_common = ~_common_evs_df.isna().any(axis=1).to_numpy()\n",
    "#\n",
    "# ...\n",
    "#\n",
    "_all_samples = (\n",
    "    [_sample for _sample in telo_cis_evs] +\n",
    "    [_sample for _sample in telo_reps_cis_evs if _sample not in repeated_samples]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8515a-45b2-4de9-8f37-cf71a66cc038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3cd9d6-88cd-4f8c-95d7-3b50555fa958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _common_evs_df.columns\n",
    "# len([_df[_value_col].rename(_sample) for _sample, _df in telo_cis_evs.items()])\n",
    "# len([_df[_value_col].rename(_sample) for _sample, _df in telo_reps_cis_evs.items() if _sample not in repeated_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b5c78-235d-4988-8b26-45c2ec752da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da1ad3-cebc-4db5-8754-5e314d226e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6c6df-20d8-4489-82fc-55a77a4c05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pca_samples = [\n",
    "    # 'mTelo',\n",
    "    # 'mCyto',\n",
    "    'm5hR1R2',\n",
    "    'm10hR1R2',\n",
    "    # 'pTelo',\n",
    "    # 'pCyto',\n",
    "    'p5hR1R2',\n",
    "    'p10hR1R2',\n",
    "    # 'mp10hR1R2',\n",
    "    'N93m5',\n",
    "    'N93p5',\n",
    "]\n",
    "\n",
    "_rest_samples = [_sample for _sample in _all_samples if (_sample not in _pca_samples)and(_sample not in excluded_samples)]\n",
    "\n",
    "X = _common_evs_df[_pca_samples].to_numpy()[_good_bins_common].T\n",
    "X_rest = _common_evs_df[_rest_samples].to_numpy()[_good_bins_common].T\n",
    "\n",
    "# do PCA on X ...\n",
    "pcaX = decomposition.PCA(n_components=3)\n",
    "print(f\"running PCA on {_pca_samples=} ...\")\n",
    "pcaX.fit(X)\n",
    "\n",
    "# project X and X_rest onto PCs ...\n",
    "X_trans = pcaX.transform(X)\n",
    "X_rest_trans = pcaX.transform(X_rest)\n",
    "\n",
    "print(pcaX.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea53cde-c9d1-4347-b16e-1375104eb3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "_x, _y, _ = X_trans.T\n",
    "_x_rest, _y_rest, _ = X_rest_trans.T\n",
    "\n",
    "text_list = []\n",
    "for txt in _pca_samples:\n",
    "    text_list.append(smap_combo[txt])\n",
    "for txt in _rest_samples:\n",
    "    text_list.append(smap_combo[txt])\n",
    "\n",
    "_xx = np.r_[_x, _x_rest]\n",
    "_yy = np.r_[_y, _y_rest]\n",
    "\n",
    "ax.scatter(_x, _y, s=60, color=\"tab:red\", alpha=0.8)\n",
    "ax.scatter(_x_rest, _y_rest, s=60, color=\"tab:blue\", alpha=0.8)\n",
    "\n",
    "ta.allocate(\n",
    "    ax,\n",
    "    _xx,\n",
    "    _yy,\n",
    "    text_list,\n",
    "    # x_scatter=_xx,\n",
    "    # y_scatter=_yy,\n",
    "    linecolor=\"black\",\n",
    "    textsize=9\n",
    ")\n",
    "# ...\n",
    "# plt.scatter(_x, _y, s=50, color=\"blue\")\n",
    "# for i, txt in enumerate(_rest_samples):\n",
    "#     ax.annotate(smap_combo[txt], (_x[i], _y[i]), fontsize=9)\n",
    "\n",
    "_1, _2, _3 = pca.explained_variance_ratio_[:3]\n",
    "ax.set_xlabel(f\"PC1: {_1:.2f}\")\n",
    "ax.set_ylabel(f\"PC2: {_2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a647a23-1834-4faa-a53d-2073ab4148ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ta.allocate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c1ac5-37b7-440c-aadd-a24cc3293b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee102f-a7e3-415b-8f62-7e7b95440aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4eaf0-d007-4315-83ca-02c9bcce8341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d013f-5465-46a1-a58e-d827ff448b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "_value_col = \"value\"\n",
    "\n",
    "\n",
    "_common_mask = pd.concat(\n",
    "    [_df[_value_col].rename(_sample) for _sample, _df in telo_reps_cis_evs.items()],\n",
    "    axis=1,\n",
    ").isna().any(axis=1).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_pca_samples = [\n",
    "    # 'mMito_R1',\n",
    "    # 'mMito_R2',\n",
    "    # 'mTelo',\n",
    "    # 'mCyto',\n",
    "    'm5h_R1',\n",
    "    'm5h_R2',\n",
    "    'm10h_R1',\n",
    "    'm10h_R2',\n",
    "    # 'pMito_R1',\n",
    "    # 'pMito_R2',\n",
    "    # 'pTelo',\n",
    "    # 'pCyto',\n",
    "    'p5h_R1',\n",
    "    'p5h_R2',\n",
    "    'p10h_R1',\n",
    "    'p10h_R2',\n",
    "    # 'mp10h_R1',\n",
    "    # 'mp10h_R2',\n",
    "    'N93m5_R1',\n",
    "    'N93m5_R2',\n",
    "    'N93m10_R1',\n",
    "    'N93m10_R2',\n",
    "    'N93p5_R1',\n",
    "    'N93p5_R2',\n",
    "    'N93p10_R1',\n",
    "    'N93p10_R2',\n",
    "    # 'N93mp10_R1',\n",
    "    # 'N93mp10_R2',\n",
    "]\n",
    "\n",
    "# _pca_samples = [\n",
    "#     # 'mTelo',\n",
    "#     # 'mCyto',\n",
    "#     'm5hR1R2',\n",
    "#     # 'm10hR1R2',\n",
    "#     # 'pTelo',\n",
    "#     # 'pCyto',\n",
    "#     'p5hR1R2',\n",
    "#     # 'p10hR1R2',\n",
    "#     # 'mp10hR1R2',\n",
    "#     'N93m5',\n",
    "#     # 'N93m10',\n",
    "#     # 'N93p5',\n",
    "#     'N93p10',\n",
    "#     # 'N93mp10',\n",
    "# ]\n",
    "\n",
    "_rest_samples = [_sample for _sample in telo_reps_cis_evs if (_sample not in _pca_samples)]\n",
    "\n",
    "\n",
    "X = pd.concat(\n",
    "    [telo_reps_cis_evs[_sample][_value_col].rename(_sample) for _sample in _pca_samples],\n",
    "    axis=1,\n",
    ").to_numpy()[~_common_mask].T\n",
    "\n",
    "\n",
    "\n",
    "X_rest = pd.concat(\n",
    "    [telo_reps_cis_evs[_sample][_value_col].rename(_sample) for _sample in _rest_samples],\n",
    "    axis=1,\n",
    ").to_numpy()[~_common_mask].T\n",
    "\n",
    "\n",
    "\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "print(\"running PCA ...\")\n",
    "pca.fit(X)\n",
    "X_trans = pca.transform(X)\n",
    "X_rest_trans = pca.transform(X_rest)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a132ba-61f5-49ea-9f9a-2dd84c0755f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5277a-936b-405c-b03d-e7b0f58838bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_x, _y, _z = X_trans[:,0], X_trans[:,1], X_trans[:,2]\n",
    "plt.scatter(_x, _y, s=50, color=\"red\")\n",
    "ax = plt.gca()\n",
    "# for i, txt in enumerate(_pca_samples):\n",
    "#     ax.annotate(txt, (_x[i]+1, _y[i]+1), fontsize=9)\n",
    "\n",
    "texts = [ax.text(_x[i], _y[i], txt, ha='center', va='center') for i, txt in enumerate(_pca_samples)]\n",
    "\n",
    "\n",
    "_x, _y, _z = X_rest_trans[:,0], X_rest_trans[:,1], X_rest_trans[:,2]\n",
    "plt.scatter(_x, _y, s=50, color=\"blue\")\n",
    "# for i, txt in enumerate(_rest_samples):\n",
    "#     ax.annotate(txt, (_x[i]+1, _y[i]+1), fontsize=9)\n",
    "texts += [ax.text(_x[i], _y[i], txt, ha='center', va='center') for i, txt in enumerate(_rest_samples)]\n",
    "\n",
    "\n",
    "# adjust_text(texts);\n",
    "adjust_text(\n",
    "    texts,\n",
    "    expand=(1.2, 2), # expand text bounding boxes by 1.2 fold in x direction and 2 fold in y direction\n",
    "    arrowprops=dict(arrowstyle='->', color='grey') # ensure the labeling is clear by adding arrows\n",
    ");\n",
    "\n",
    "_1, _2, _3 = pca.explained_variance_ratio_[:3]\n",
    "ax.set_xlabel(f\"PC1: {_1:.2f}\")\n",
    "ax.set_ylabel(f\"PC2: {_2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba31809-b002-4e95-a628-2ec1ed9db247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1c3ca-5ac6-409b-9cd0-5b4361ba6357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a76b4e-7956-4302-adc3-42006bee8d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4790b-bf69-47ff-b56d-b6506518e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_samples_m = [\n",
    "    \"mMito\",\n",
    "    \"mTelo\",\n",
    "    \"mCyto\",\n",
    "    \"m5hR1R2\",\n",
    "    # \"m10hR1R2\",\n",
    "]\n",
    "sub_samples_p = [\n",
    "    \"pMito\",\n",
    "    \"pTelo\",\n",
    "    \"pCyto\",\n",
    "    \"p5hR1R2\",\n",
    "    # \"p10hR1R2\",\n",
    "]\n",
    "\n",
    "\n",
    "ddd = {}\n",
    "for sample in sub_samples_m+sub_samples_p:\n",
    "    ins = telo_ins[sample]\n",
    "    # ddd[sample] = bioframe.select(ins, the_region)[value_col]\n",
    "    ddd[sample] = ins[value_col]\n",
    "\n",
    "sns.heatmap(pd.DataFrame(ddd).corr(method='pearson'), annot=True, cmap=\"Reds\",vmin=0.5,vmax=0.99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f701ba-7bb2-480f-9f0e-24ae7d6bb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ord_samples = [\n",
    "    \"mMito\",\n",
    "    \"pMito\",\n",
    "    \"mTelo\",\n",
    "    \"pTelo\",\n",
    "    \"mCyto\",\n",
    "    \"pCyto\",\n",
    "    \"m5hR1R2\",\n",
    "    \"p5hR1R2\",\n",
    "    # \"m10hR1R2\",\n",
    "    # \"p10hR1R2\",\n",
    "]\n",
    "\n",
    "ddd = {}\n",
    "for sample in ord_samples:\n",
    "    ins = telo_ins[sample]\n",
    "    # ddd[sample] = bioframe.select(ins, the_region)[value_col]\n",
    "    ddd[sample] = ins[value_col]\n",
    "\n",
    "sns.heatmap(pd.DataFrame(ddd).corr(method='pearson'), annot=True, cmap=\"Reds\",vmin=0.5,vmax=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f677ac-8d39-4e8d-b56a-a4903f388fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples_m = [\n",
    "    \"mMito_R1\",\n",
    "    \"mMito_R2\",\n",
    "    \"mTelo\",\n",
    "    \"mCyto\",\n",
    "    \"m5h_R1\",\n",
    "    \"m5h_R2\",\n",
    "    \"m10h_R1\",\n",
    "    \"m10h_R2\",\n",
    "]\n",
    "# sub_samples_p = [\n",
    "#     \"pMito_R1\",\n",
    "#     \"pMito_R2\",\n",
    "#     \"pTelo\",\n",
    "#     \"pCyto\",\n",
    "#     \"p5h_R1\",\n",
    "#     \"p5h_R2\",\n",
    "#     \"p10h_R1\",\n",
    "#     \"p10h_R2\",\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "ddd = {}\n",
    "for sample in sub_samples_m:\n",
    "    ins = telo_reps_ins[sample]\n",
    "    # ddd[sample] = bioframe.select(ins, the_region)[value_col]\n",
    "    ddd[sample] = ins[value_col]\n",
    "\n",
    "sns.heatmap(pd.DataFrame(ddd).corr(method='pearson'), annot=True, cmap=\"Reds\",vmin=0.3,vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574010d-f8b5-4f9f-85a2-e0741b416489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_samples_m = [\n",
    "#     \"mMito_R1\",\n",
    "#     \"mMito_R2\",\n",
    "#     \"mTelo\",\n",
    "#     \"mCyto\",\n",
    "#     \"m5h_R1\",\n",
    "#     \"m5h_R2\",\n",
    "#     \"m10h_R1\",\n",
    "#     \"m10h_R2\",\n",
    "# ]\n",
    "sub_samples_p = [\n",
    "    \"pMito_R1\",\n",
    "    \"pMito_R2\",\n",
    "    \"pTelo\",\n",
    "    \"pCyto\",\n",
    "    \"p5h_R1\",\n",
    "    \"p5h_R2\",\n",
    "    \"p10h_R1\",\n",
    "    \"p10h_R2\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "ddd = {}\n",
    "for sample in sub_samples_p:\n",
    "    ins = telo_reps_ins[sample]\n",
    "    # ddd[sample] = bioframe.select(ins, the_region)[value_col]\n",
    "    ddd[sample] = ins[value_col]\n",
    "\n",
    "sns.heatmap(pd.DataFrame(ddd).corr(method='pearson'), annot=True, cmap=\"Reds\",vmin=0.3,vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307278d-1cfe-4049-891a-49eead6cad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samples_m = [\n",
    "    \"mMito_R1\",\n",
    "    \"mMito_R2\",\n",
    "    \"mTelo\",\n",
    "    \"mCyto\",\n",
    "    \"m5h_R1\",\n",
    "    \"m5h_R2\",\n",
    "    \"m10h_R1\",\n",
    "    \"m10h_R2\",\n",
    "]\n",
    "sub_samples_p = [\n",
    "    \"pMito_R1\",\n",
    "    \"pMito_R2\",\n",
    "    \"pTelo\",\n",
    "    \"pCyto\",\n",
    "    \"p5h_R1\",\n",
    "    \"p5h_R2\",\n",
    "    \"p10h_R1\",\n",
    "    \"p10h_R2\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "ddd = {}\n",
    "for sample in sub_samples_m+sub_samples_p:\n",
    "    ins = telo_reps_ins[sample]\n",
    "    # ddd[sample] = bioframe.select(ins, the_region)[value_col]\n",
    "    ddd[sample] = ins[value_col]\n",
    "\n",
    "sns.heatmap(pd.DataFrame(ddd).corr(method='pearson'), annot=True, cmap=\"Reds\",vmin=0.3,vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3511b-2a86-4ce0-a75b-7f174878a356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
